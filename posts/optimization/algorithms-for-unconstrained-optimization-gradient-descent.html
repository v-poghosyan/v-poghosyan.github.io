<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vahram Poghosyan">
<meta name="dcterms.date" content="2022-01-23">

<title>Algorithms for Unconstrained Optimization â€“ v-poghosyan.github.io</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-KLCX05QFPN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-KLCX05QFPN', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">v-poghosyan.github.io</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Algorithms for Unconstrained Optimization</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Optimization</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Vahram Poghosyan </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 23, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-gradient-descent-algorithm" id="toc-the-gradient-descent-algorithm" class="nav-link" data-scroll-target="#the-gradient-descent-algorithm">The Gradient Descent Algorithm</a>
  <ul class="collapse">
  <li><a href="#idea-1---greedy-choice-of-direction" id="toc-idea-1---greedy-choice-of-direction" class="nav-link" data-scroll-target="#idea-1---greedy-choice-of-direction">Idea 1 - Greedy Choice of Direction</a></li>
  <li><a href="#idea-2---greedy-choice-of-next-iterate" id="toc-idea-2---greedy-choice-of-next-iterate" class="nav-link" data-scroll-target="#idea-2---greedy-choice-of-next-iterate">Idea 2 - Greedy Choice of Next Iterate</a></li>
  </ul></li>
  <li><a href="#important-questions-in-analysis" id="toc-important-questions-in-analysis" class="nav-link" data-scroll-target="#important-questions-in-analysis">Important Questions in Analysis</a>
  <ul class="collapse">
  <li><a href="#initialization" id="toc-initialization" class="nav-link" data-scroll-target="#initialization">Initialization</a></li>
  <li><a href="#fixed-step-size-gd" id="toc-fixed-step-size-gd" class="nav-link" data-scroll-target="#fixed-step-size-gd">Fixed Step-Size GD</a>
  <ul class="collapse">
  <li><a href="#simple-analysis-of-fixed-step-size-gd" id="toc-simple-analysis-of-fixed-step-size-gd" class="nav-link" data-scroll-target="#simple-analysis-of-fixed-step-size-gd">Simple Analysis of Fixed Step-Size GD</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#smoothness-and-strong-convexity" id="toc-smoothness-and-strong-convexity" class="nav-link" data-scroll-target="#smoothness-and-strong-convexity">Smoothness and Strong Convexity</a>
  <ul class="collapse">
  <li><a href="#self-tuning-property" id="toc-self-tuning-property" class="nav-link" data-scroll-target="#self-tuning-property">Self-Tuning Property</a></li>
  <li><a href="#quadratic-bounds" id="toc-quadratic-bounds" class="nav-link" data-scroll-target="#quadratic-bounds">Quadratic Bounds</a></li>
  <li><a href="#the-optimal-fixed-step-size" id="toc-the-optimal-fixed-step-size" class="nav-link" data-scroll-target="#the-optimal-fixed-step-size">The Optimal Fixed Step-Size</a></li>
  <li><a href="#convergence-rate" id="toc-convergence-rate" class="nav-link" data-scroll-target="#convergence-rate">Convergence Rate</a>
  <ul class="collapse">
  <li><a href="#m-smooth-objectives" id="toc-m-smooth-objectives" class="nav-link" data-scroll-target="#m-smooth-objectives"><span class="math inline">\(M\)</span>-Smooth Objectives</a></li>
  <li><a href="#m-smooth-and-m-strongly-convex-objectives" id="toc-m-smooth-and-m-strongly-convex-objectives" class="nav-link" data-scroll-target="#m-smooth-and-m-strongly-convex-objectives"><span class="math inline">\(M\)</span>-Smooth and <span class="math inline">\(m\)</span>-Strongly-Convex Objectives</a></li>
  <li><a href="#affine-invariance" id="toc-affine-invariance" class="nav-link" data-scroll-target="#affine-invariance">Affine Invariance</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#variable-step-size-gd" id="toc-variable-step-size-gd" class="nav-link" data-scroll-target="#variable-step-size-gd">Variable Step-Size GD</a>
  <ul class="collapse">
  <li><a href="#exact-line-search-els" id="toc-exact-line-search-els" class="nav-link" data-scroll-target="#exact-line-search-els">Exact Line Search (ELS)</a></li>
  <li><a href="#backtracking-line-search-btls" id="toc-backtracking-line-search-btls" class="nav-link" data-scroll-target="#backtracking-line-search-btls">Backtracking Line Search (BTLS)</a>
  <ul class="collapse">
  <li><a href="#the-btls-subroutine" id="toc-the-btls-subroutine" class="nav-link" data-scroll-target="#the-btls-subroutine">The BTLS Subroutine</a></li>
  <li><a href="#convergence-guarantees-of-gd-with-btls" id="toc-convergence-guarantees-of-gd-with-btls" class="nav-link" data-scroll-target="#convergence-guarantees-of-gd-with-btls">Convergence Guarantees of GD with BTLS</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#theoretical-error-bounds-on-first-order-oracles" id="toc-theoretical-error-bounds-on-first-order-oracles" class="nav-link" data-scroll-target="#theoretical-error-bounds-on-first-order-oracles">Theoretical Error Bounds on First Order Oracles</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p><strong><em>Gradient Descent (GD)</em></strong> is a powerful, yet incredibly simple, iterative optimization algorithm. We can think of it as a <strong><em>greedy algorithm</em></strong> in the setting of continuous optimization. That is, one step of GD is our best attempt at local optimization given limited information about the objective <span class="math inline">\(f(x)\)</span>, and having limited computational power at our disposal.</p>
<p>We can further qualify what we mean by <em>â€˜limited informationâ€™</em> about the objective by introducing a categorization on optimization algorithms â€“ the <strong><em>Oracle Access Model (OAM)</em></strong>. In this model, the objective is abstracted into a black box. For each input <span class="math inline">\(x\)</span>, the black box gives the algorithm access to the value of the objective, <span class="math inline">\(f(x)\)</span>, and, optionally, global information in the form of higher order behavior such as <span class="math inline">\(\nabla f(x)\)</span>, <span class="math inline">\(\nabla^2 f(x)\)</span>, etc. GD is whatâ€™s known as a <strong><em>first-order oracle</em></strong> because itâ€™s only allowed access to <span class="math inline">\(f(x)\)</span> and first-order information in the form of <span class="math inline">\(\nabla f(x)\)</span>.</p>
<p>Itâ€™s important to note that the OAM is not all-inclusive, there are a number of optimization algorithms, such as <strong><em>composite optimization</em></strong> algorithms, that utilize structural information about the objective that goes beyond <span class="math inline">\(n\)</span>-th order behavior. An example of such an algorithm is <strong><em>Proximal Gradient Descent (PGD)</em></strong> which, in addition to <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(\nabla f(x)\)</span>, also has access to the <strong><em>prox operator</em></strong>: <span class="math inline">\(Prox_{h,\eta}(x)\)</span>.</p>
<p>We will cover these composite optimization algorithms in later posts. Many of the composite optimization algorithms, such as PGD, are simple modifications of vanilla GD. The modification done in PGD, for example, make it suitable for constrained optimization. For now, however, we focus on the case of unconstrained optimization with oracles, particularly on Gradient Descent, in order to develop the key algorithmic intuition.</p>
</section>
<section id="the-gradient-descent-algorithm" class="level1">
<h1>The Gradient Descent Algorithm</h1>
<p>In this section, we will explore two ideas that give rise to the GD algorithm. As all iterative algorithms, gradient descent relies on an <strong><em>initialization step</em></strong> and an <strong><em>update step</em></strong>.</p>
<section id="idea-1---greedy-choice-of-direction" class="level2">
<h2 class="anchored" data-anchor-id="idea-1---greedy-choice-of-direction">Idea 1 - Greedy Choice of Direction</h2>
<p>Let <span class="math inline">\(x\)</span> be the initial iterate, and let the update be given by:</p>
<p><span class="math display">\[x^+ = x + \eta d\]</span></p>
<p>for some directional unit-vector <span class="math inline">\(d\)</span> and <strong><em>step-size</em></strong> parameter <span class="math inline">\(\eta &gt; 0\)</span>.</p>
<p>We base the algorithm on the assumption that the linear approximation of the objective at a the next iterate <span class="math inline">\(x^+\)</span> is a good-enough estimate of its true value at <span class="math inline">\(x^+\)</span>.</p>
<p>That is:</p>
<p><span class="math display">\[f(x^+) = f(x + \eta d) \approx f(x) + \eta \nabla f(x)^T d \ \ \forall d \tag{1.1}\]</span></p>
<p>Immediately, a locally optimal choice presents itself to us. Since we wish to minimize <span class="math inline">\(f(x)\)</span>, it would be wise to insist that the objective at <span class="math inline">\(x^+\)</span> improves or, at least, does not worsen.</p>
<p>That is, we insist:</p>
<p><span class="math display">\[f(x^+) \approx f(x) + \eta \nabla f(x)^T d \leq f(x) \tag{1.3}\]</span></p>
<p>And, since we are greedy in our approach, we wish to make <span class="math inline">\(f(x^+)\)</span> as small as possible. Since, on the RHS, <span class="math inline">\(f(x)\)</span> is fixed and <span class="math inline">\(\eta &gt; 0\)</span>, this amounts to minimizing the scaled inner-product <span class="math inline">\(\nabla f(x)^Td\)</span>. To that end, we choose <span class="math inline">\(d\)</span> opposite and parallel to the gradient, i.e.&nbsp;<span class="math inline">\(d = - \frac{\nabla f(x)}{||\nabla f(x)||_2}\)</span>.</p>
<p>The update step becomes:</p>
<p><span class="math display">\[x^+ = x - \eta \frac{\nabla f(x)}{||\nabla f(x)||_2}\]</span></p>
<p>By re-labeling, <span class="math inline">\(\eta\)</span> can absorb the normalization constant. This obtains the gradient descent update step as itâ€™s often introduced in the textbooks â€“ a step in the negative gradient direction:</p>
<p><span class="math display">\[x^+ = x - \eta \nabla f(x) \tag{1.4}\]</span></p>
<p>This makes intuitive sense because the negative gradient direction is the direction in which the objective decreases most. So, itâ€™s only natural that the update should take us in this most enticing direction.</p>
</section>
<section id="idea-2---greedy-choice-of-next-iterate" class="level2">
<h2 class="anchored" data-anchor-id="idea-2---greedy-choice-of-next-iterate">Idea 2 - Greedy Choice of Next Iterate</h2>
<p>Instead of defining the update step <span class="math inline">\(x^+ = x + \eta d\)</span> and then choosing the locally optimal direction <span class="math inline">\(d\)</span> greedily, we can choose the update step and the direction, both, in one fell swoop.</p>
<p>Starting from the linear approximation:</p>
<p><span class="math display">\[
f(y) \approx f(x) + \nabla f(x)^T(y - x) \ \ \forall y \tag{2.1}
\]</span></p>
<p>We can now insist, in a greedy fashion, that the next iterate <span class="math inline">\(x^+\)</span> be the minimizer of the linear approximation. That is, we insist:</p>
<p><span class="math display">\[
x^+ = \arg \min_y f(x) + \nabla f(x)^T(y - x) \tag{2.2}
\]</span></p>
<p>But the linear approximation is only local, so it would be wise to distrust it for points far away from the current iterate. In this case, since the linear approximation is, in fact, unbounded below, <span class="math inline">\((2.2)\)</span> would obtain <span class="math inline">\(x^+ = \pm \infty\)</span>. To avoid this problem, we introduce a parametrized penalty term that prevents <span class="math inline">\(x^+\)</span> from venturing too far from the current iterate <span class="math inline">\(x\)</span>. That is:</p>
<p><span class="math display">\[
x^+ = \arg \min_y f(x) + \nabla f(x)^T(y - x) + \eta ||y - x||_2^2 \tag{2.3}
\]</span></p>
<p>Now, since the RHS is a a simple quadratic in <span class="math inline">\(y\)</span>, it has a unique minimizer which can be found by using the unconstrained optimality condition. This just boils down to taking the gradient of the RHS w.r.t. the optimization variable <span class="math inline">\(y\)</span>, setting it to zero, and then solving for the unique root. This procedure obtains:</p>
<p><span class="math display">\[x^+ = x - \frac{1}{2 \eta} \nabla f(x)\]</span></p>
<p>By re-labeling, we, once again, get the canonical form of the GD update step as in <span class="math inline">\((1.3)\)</span> â€“ a step in the negative gradient direction.</p>
</section>
</section>
<section id="important-questions-in-analysis" class="level1">
<h1>Important Questions in Analysis</h1>
<p>Given the ease with which we came up with the algorithm, we should ask ourselves the following questions:</p>
<ol type="1">
<li>Is GD sensitive to initialization?</li>
<li>Is GD guaranteed to converge for all step-sizes?</li>
<li>How should we choose a step-size that guarantees convergence?</li>
<li>Whatâ€™s the rate of convergence of GD? Does the rate depend on step-size? Does it depend on properties of the objective function?</li>
<li>How should we choose a step-size that maximizes convergence rate?</li>
</ol>
<p>We will shortly explore each of these questions and more. However, before doing so, itâ€™s worth taking a birdâ€™s eye look at the problem of convex optimization itself. Perhaps the most important question to ask ourselves is this: does gradient descentâ€™s convergence rate, for an optimally chosen step-size, give a taxonomy of easier-to-harder problems within the field of convex optimization? The answer, as it turns out, is <em>yes</em>.</p>
<section id="initialization" class="level2">
<h2 class="anchored" data-anchor-id="initialization">Initialization</h2>
<p>From this point on, we will limit our discussion to convex objectives in order to eliminate the possibility of strictly <strong><em>local optimizers</em></strong> (i.e.&nbsp;<strong><em>non-global optimizers</em></strong>) and <strong><em>inflection points</em></strong>, both of which GD gets stuck at if initialized poorly. This ensures the only <strong><em>stationary points</em></strong>, points at which <span class="math inline">\(\nabla f(x) = 0\)</span> and the GD update makes no further progress, are global minimizers. On such convex functions, as we will soon discover, GD has a convergence guarantee for all step-sizes independently of initialization.</p>
</section>
<section id="fixed-step-size-gd" class="level2">
<h2 class="anchored" data-anchor-id="fixed-step-size-gd">Fixed Step-Size GD</h2>
<p>To kickstart our analysis of GD, we consider the fixed step-size algorithm first. Letâ€™s take two quintessential convex problems in <span class="math inline">\(\mathbb{R}\)</span>, <span class="math inline">\(f(x) = x^2\)</span> and <span class="math inline">\(h(x) = |x|\)</span>, and analyze GDâ€™s performance on them.</p>
<section id="simple-analysis-of-fixed-step-size-gd" class="level3">
<h3 class="anchored" data-anchor-id="simple-analysis-of-fixed-step-size-gd">Simple Analysis of Fixed Step-Size GD</h3>
<hr>
<p>First, letâ€™s run the algorithm on <span class="math inline">\(h(x) = |x|\)</span> for <span class="math inline">\(x \in \mathbb{R}\)</span>:</p>
<p>Since <span class="math inline">\(|x|\)</span> is non-differentiable at <span class="math inline">\(x = 0\)</span>, the gradient has a discontinuity at <span class="math inline">\(x = 0\)</span>. Non-differentiability, such as this, will eventually force us to introduce the notion of <strong><em>sub-gradients</em></strong>, but for now we can get away with it simply by avoiding the gradientâ€™s behavior at <span class="math inline">\(0\)</span>. So:</p>
<p><span class="math display">\[
h'(x) =
\begin{cases}
\begin{aligned}
-1 \ &amp;\textrm{if $x &lt; 0$} \\
1 \ &amp;\textrm{if $x &gt; 0$}
\end{aligned}
\end{cases}
\]</span></p>
<p>Then, for a fixed <span class="math inline">\(\eta &gt; 0\)</span>, the update step is:</p>
<p><span class="math display">\[x^+ = x \pm \eta\]</span></p>
<p>where the sign of <span class="math inline">\(\eta\)</span> depends on where the previous iterate, <span class="math inline">\(x\)</span>, falls within the domain <span class="math inline">\((-\infty, 0) \cup (0, \infty)\)</span>.</p>
<hr>
<p>Now, consider <span class="math inline">\(f(x) = x^2\)</span> for <span class="math inline">\(x \in \mathbb{R}\)</span>:</p>
<p>The gradient of <span class="math inline">\(f(x) = x^2\)</span> is <span class="math inline">\(f'(x) = 2x\)</span>, which means the fixed step-size update is:</p>
<p><span class="math display">\[x^+ = x - 2\eta x\]</span></p>
<hr>
<p>Note that <span class="math inline">\(x^* = 0\)</span> is the unique optimizer of both <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(h(x)\)</span>. With this in mind, there are two key observations to make.</p>
<p>The first is that, for <span class="math inline">\(x\)</span> far away from <span class="math inline">\(x^* = 0\)</span>, the update, <span class="math inline">\(2\eta x\)</span>, is large (in magnitude). So, if the iterate is far from the optimizer, GD makes fast progress towards it.</p>
<p>The second observation is that, as <span class="math inline">\(x \rightarrow x^*\)</span>, the update becomes small in magnitude. So, as the iterate comes close to the optimizer, GD takes smaller and smaller steps which converge to <span class="math inline">\(0\)</span> in a summable way. This means, we can get the sub-optimality <span class="math inline">\(f(x) - f(x^*)\)</span> to be <span class="math inline">\(\epsilon\)</span>-arbitrarily small for <em>any</em> fixed step-size <span class="math inline">\(\eta\)</span>.</p>
<p>Neither of these observations hold for GD on <span class="math inline">\(h(x) = |x|\)</span> since the update <span class="math inline">\(\eta\)</span> is fixed regardless of the Euclidean distance between <span class="math inline">\(x\)</span> and <span class="math inline">\(x^* = 0\)</span>. In particular, this means GD is <em>not</em> fast for <span class="math inline">\(x\)</span> far away from <span class="math inline">\(x^*\)</span> and <em>does not</em> slow down as <span class="math inline">\(x\)</span> nears <span class="math inline">\(x^*\)</span>. Arbitrary accuracy is impossible with a fixed step-size, since the iterates eventually cycle between <span class="math inline">\(x^T - \eta\)</span> and <span class="math inline">\(x^T + \eta\)</span> where <span class="math inline">\(x^T\)</span> is the last unique iterate â€“ that is <span class="math inline">\(x^T \in (-\eta, \eta)\)</span>. The sub-optimality, consequently, also cycles between two values which depend on the choice of <span class="math inline">\(\eta\)</span>. This is to say that the sub-optimality cannot be <span class="math inline">\(\epsilon\)</span>-arbitrary small for a fixed choice of <span class="math inline">\(\eta\)</span>. To be clear, there is still convergence but itâ€™s slow and not arbitrarily accurate. Arbitrary accuracy for such problems as this can only be achieved by choosing a sequence of diminishing step-sizes <span class="math inline">\(\{ \eta_t \}_{t=1}^T\)</span> which reduce magnitude of the update since the gradient, itself, is constant. Of course, this sequence must be chosen with care since itâ€™s possible to <em>â€˜run out of steamâ€™</em>, so to speak, before reaching the optimizer. The precise criterion is <span class="math inline">\(\eta_t \rightarrow 0\)</span> as <span class="math inline">\(t \rightarrow \infty\)</span> s.t. <span class="math inline">\(\sum_t^\infty \eta_t = \infty\)</span>.</p>
<p>We say GD on <span class="math inline">\(f(x) = x^2\)</span> enjoys the <strong><em>self-tuning property</em></strong>, whereas GD on <span class="math inline">\(h(x) = |x|\)</span> does not. This speaks to the fact that the self-tuning is a property of the objective functions, rather than GD itself.</p>
<p>As an overview of the theory we will soon develop, functions <em>like</em> <span class="math inline">\(x^2\)</span> (or, more generally, any quadratic in <span class="math inline">\(\mathbb{R}^n\)</span>) will all have the self-tuning property while functions <em>like</em> <span class="math inline">\(|x|\)</span> will not. This is what ends up introducing the taxonomy of easier-to-harder convex optimization problems mentioned in the previous section. What it means, precisely, to be <em>like</em> <span class="math inline">\(x^2\)</span> or <span class="math inline">\(|x|\)</span> will be made rigorous in the next few sections.</p>
</section>
</section>
</section>
<section id="smoothness-and-strong-convexity" class="level1">
<h1>Smoothness and Strong Convexity</h1>
<p>As we saw above, gradient descent with a fixed step-size behaved much better on <span class="math inline">\(f(x) = x^2\)</span> than on <span class="math inline">\(h(x) = |x|\)</span>. Since both of these problems are convex, <span class="math inline">\(x^2\)</span> must have additional properties not shared by <span class="math inline">\(|x|\)</span> that make it more amenable to optimization by GD. These properties turn out to be <strong><em>smoothness</em></strong> and <strong><em>strong convexity</em></strong>. We will see that these properties provide insight into choosing the best fixed-step size which guarantees faster convergence of GD.</p>
<p>We start by asking ourselves what makes the two quintessential functions <span class="math inline">\(f(x) = x^2\)</span> and <span class="math inline">\(h(x) = |x|\)</span> different from one another. Since the GD update step relies on the gradient, it helps thinking in terms of the differences of the gradients instead of the objective functions themselves.</p>
<p>The first difference of note is that <span class="math inline">\(|x|\)</span> has a discontinuity at <span class="math inline">\(x = 0\)</span> thatâ€™s not present in <span class="math inline">\(x^2\)</span>. At a point of discontinuity the gradient experiences an abrupt jump. So, in general, jumps in the gradient must pose a problem for GD.</p>
<p>The second difference of note is that <span class="math inline">\(|x|\)</span> is flat compared to <span class="math inline">\(x^2\)</span>. In flat regions, the gradient is constant. So, in general, constant regions in the gradient must pose a problem for GD.</p>
<p>Both of these scenarios can be ruled out with a <a href="https://en.wikipedia.org/wiki/Lipschitz_continuity"><strong><em>Lipschitz condition</em></strong></a> on the gradient. Lipschitz conditions are both regularity conditions, as well as, growth conditions. So, they can rule out abrupt jumps and ensure thereâ€™s, at least, some change in the gradient.</p>
<p>We are ready to define the two properties mentioned in the beginning of this section.</p>
<blockquote class="blockquote">
<p><strong>Smoothness:</strong> &nbsp; We say a function <span class="math inline">\(f(x)\)</span> is <strong><em>M-smooth</em></strong> if its gradient is <strong><em>M-Lipschitz</em></strong>. That is, if:</p>
<p><span class="math display">\[\exists M &gt; 0 \ \ s.t. \ \ ||\nabla f(x) - \nabla f(y)||_2 \leq M||x-y||_2 \ \ \forall x,y\]</span></p>
</blockquote>
<p>This is a universal upper-bound on the change in gradient which rules out jumps.</p>
<blockquote class="blockquote">
<p><strong>Strong Convexity:</strong> &nbsp; We say a function <span class="math inline">\(f(x)\)</span> is <strong><em>m-strongly-convex</em></strong> if:</p>
<p><span class="math display">\[\exists m &gt; 0 \ \ s.t. \ \ ||\nabla f(x) - \nabla f(y)||_2 \geq m||x-y||_2 \ \ \forall x,y\]</span></p>
</blockquote>
<p>This is a universal lower-bound on the change in gradient which rules out the possibility of a constant gradient.</p>
<p>In particular, an <span class="math inline">\(M\)</span>-smooth, and <span class="math inline">\(m\)</span>-strongly-convex function <span class="math inline">\(f(x)\)</span> satisfies:</p>
<p><span class="math display">\[m||x-y||_2 \leq ||\nabla f(x) - \nabla f(y)||_2 \leq M||x-y||_2 \ \ \forall x,y \tag{3.1}\]</span></p>
<p>For a twice-differentiable function, thereâ€™s a more compact way to express these properties using the hessian which makes use of an ordering on matrices introduced by matrix <a href="https://en.wikipedia.org/wiki/Definite_matrix"><strong><em>definiteness</em></strong></a>. After all, Lipschitzness of the gradient, which is nothing but a restriction on its growth, is a statement about the hessian.</p>
<p><span class="math display">\[||\nabla f(x) - \nabla f(y)||_2 \leq M||x-y||_2 \ \ \forall x,y\]</span> <span class="math display">\[\iff\]</span> <span class="math display">\[||\nabla^2 f(x)||_2 \leq M \ \ \forall x\]</span> <span class="math display">\[\iff\]</span> <span class="math display">\[\nabla^2 f(x) \preceq  MI \ \ \forall x \tag{4.1}\]</span></p>
<p>The first equivalence is by the <a href="https://en.wikipedia.org/wiki/Mean_value_theorem"><strong><em>Mean Value Theorem</em></strong></a> and the second follows from the definition of <strong><em>matrix norm</em></strong>.</p>
<p>Line <span class="math inline">\((3.1)\)</span> should be read as <em>â€˜the maximum eigenvalue of the hessian <span class="math inline">\(\nabla^2 f(x)\)</span> is <span class="math inline">\(M\)</span>â€™</em>.</p>
<p>By a symmetric argument, we also have:</p>
<p><span class="math display">\[\nabla^2 f(x) \succeq mI \ \ \forall x \tag{4.2}\]</span></p>
<p>Which should be read as <em>â€˜the minimum eigenvalue of the hessian <span class="math inline">\(\nabla^2 f(x)\)</span> is <span class="math inline">\(m\)</span>â€™</em>.</p>
<p>Together, <span class="math inline">\((4.1)\)</span> and <span class="math inline">\((4.2)\)</span> give the analog of <span class="math inline">\((3.1)\)</span> for twice-differentiable <span class="math inline">\(M\)</span>-smooth and <span class="math inline">\(m\)</span>-strongly-convex functions:</p>
<p><span class="math display">\[mI \preceq \nabla^2 f(x) \preceq MI \ \ \forall x \tag{3.2}\]</span></p>
<p>Since the hessian represents the curvature of the function, <span class="math inline">\((3.2)\)</span> is a two-sided bound on the curvature of <span class="math inline">\(f(x)\)</span>. So, we see that smoothness and strong convexity also regulate function shape itself. The lower-bound rules out flatness, while the upper-bound rules out discontinuities like corners and cusps.</p>
<section id="self-tuning-property" class="level2">
<h2 class="anchored" data-anchor-id="self-tuning-property">Self-Tuning Property</h2>
<p>For a convex function thatâ€™s <span class="math inline">\(M\)</span>-smooth and <span class="math inline">\(m\)</span>-strongly-convex we have <span class="math inline">\((3.1)\)</span> which, as a reminder, is:</p>
<p><span class="math display">\[m||x-y||_2 \leq ||\nabla f(x) - \nabla f(y)||_2 \leq M||x-y||_2 \ \ \forall x,y\]</span></p>
<p>Fixing iterate <span class="math inline">\(x\)</span>, and replacing <span class="math inline">\(y\)</span> with the optimizer <span class="math inline">\(x^*\)</span> we have:</p>
<p><span class="math display">\[m||x-x^*||_2 \leq ||\nabla f(x) - \nabla f(x^*)||_2 \leq M||x-x^*||_2\]</span></p>
<p>Since <span class="math inline">\(x^*\)</span> is an optimizer <span class="math inline">\(\nabla f(x^*) = 0\)</span>, so the above becomes:</p>
<p><span class="math display">\[m||x-x^*||_2 \leq ||\nabla f(x)||_2 \leq M||x-x^*||_2\]</span></p>
<p>The first inequality says that the magnitude of the gradient is <em>at least</em> a constant multiple of the distance from the optimizer. The second inequality says that the magnitude of the gradient is <em>at most</em> a constant multiple of the distance from the optimizer. So, the gradient is large for <span class="math inline">\(x\)</span> far from <span class="math inline">\(x^*\)</span> and gets smaller as <span class="math inline">\(x \rightarrow x^*\)</span>. Since the GD update depends on the magnitude of the gradient, this ensures GD has the self-tuning property. So, smoothness and strong-convexity were, indeed, the ideas needed to encapsulate the self-tuning property.</p>
</section>
<section id="quadratic-bounds" class="level2">
<h2 class="anchored" data-anchor-id="quadratic-bounds">Quadratic Bounds</h2>
<p>Smoothness and strong-convexity, should they hold for a given convex function, give a universal quadratic point-wise upper and lower-bound, respectively, on the function. This is what it means to say that the function is <em>like</em> a quadratic. In a sense, all weâ€™re saying is that a function is <em>tightly</em> asymptotically bounded by a quadratic at every point. That is, at any given point, the function should neither grow slower nor faster than quadratically.</p>
<p>To construct the upper and lower-bounds, we use the following two lemmas:</p>
<blockquote class="blockquote">
<p><strong>Lemma 1:</strong> &nbsp; If <span class="math inline">\(f\)</span> is convex and <span class="math inline">\(L\)</span>-Lipschitz then <span class="math inline">\(g(x) = \frac{L}{2}x^Tx - f(x)\)</span> is convex.</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Lemma 2:</strong> &nbsp; If <span class="math inline">\(f\)</span> is <span class="math inline">\(m\)</span>-strongly-convex then <span class="math inline">\(g(x) = f(x) - \frac{m}{2}x^Tx\)</span> is convex.</p>
</blockquote>
<p>Both lemmas are statements of comparative convexity in disguise. <strong><em>Lemma 1</em></strong> says that <span class="math inline">\(\frac{L}{2}x^Tx\)</span> is more convex than <span class="math inline">\(f\)</span>, whereas <strong><em>Lemma 2</em></strong> says that <span class="math inline">\(f\)</span> is more convex than <span class="math inline">\(\frac{m}{2}x^Tx\)</span>.</p>
<p>Itâ€™s not difficult to see how these lemmas can assist in sandwiching <span class="math inline">\(f\)</span> between an upper-bound thatâ€™s more convex and a lower-bound thatâ€™s less convex.</p>
<p>The bounds themselves come from the quadratic approximation of <span class="math inline">\(f\)</span> as:</p>
<p><span class="math display">\[f(y) \approx f(x) + \nabla f(x)^T(y-x) + \frac{1}{2}(y-x)^T\nabla^2 f(x)(y-x)\ \ \forall y\]</span></p>
<p>By replacing the hessian with its bounds <span class="math inline">\(mI\)</span> and <span class="math inline">\(MI\)</span> and using the above lemmas we obtain the two bounds as:</p>
<p><span class="math display">\[f(y) \geq f(x) + \nabla f(x)^T(y-x) + \frac{m}{2}||y-x||_2^2 \ \ \forall y\]</span> <span class="math display">\[\textrm{and} \tag {5.1}\]</span> <span class="math display">\[f(y) \leq f(x) + \nabla f(x)^T(y-x) + \frac{M}{2}||y-x||_2^2 \ \ \forall y\]</span></p>
</section>
<section id="the-optimal-fixed-step-size" class="level2">
<h2 class="anchored" data-anchor-id="the-optimal-fixed-step-size">The Optimal Fixed Step-Size</h2>
<p>We already showed that an <span class="math inline">\(M\)</span>-smooth and <span class="math inline">\(m\)</span>-strongly-convex function enjoys the advantage of self-tuning. But, without knowing how to choose the step-size, we can still cause GD to make slow progress or even diverge.</p>
<p>After all, gradient descent is based on a local linear approximation of the objective. If we take big steps, we are counting on the linear approximation to be a good-enough estimate far from the current iterate. This may be too optimistic, in which case GD will diverge. Being too pessimistic, however, is also not good. While taking small steps wonâ€™t cause GD to diverge, it will make GD painfully slowâ€¦ Slow to the point of making it worthless in practice.</p>
<p>Luckily, the quadratic upper-bound in <span class="math inline">\((5.1)\)</span> informs our choice of step-size both in terms of a convergence guarantee and in terms of optimality. First, letâ€™s develop the convergence guarantee.</p>
<p>By plugging the update step <span class="math inline">\(x^+ = x - \eta \nabla f(x)\)</span> as <span class="math inline">\(y\)</span> into the upper-bound in <span class="math inline">\((5.1)\)</span> we obtain:</p>
<p><span class="math display">\[f(x^+) \leq f(x) + \eta(1-\frac{M}{2}\eta)||\nabla f(x)||_2^2 \tag{5.2}\]</span></p>
<p>As before, it would be wise to insist <span class="math inline">\(f(x^+) \leq f(x)\)</span>, which gives the convergence interval as <span class="math inline">\(0 &lt; \eta &lt; \frac{2}{M}\)</span>.</p>
<p>Here, it helps to consider the simple example of quadratics.</p>
<hr>
<p><strong>Example 1:</strong></p>
<p>Consider the quadratic form in <span class="math inline">\(\mathbb{R}\)</span> given by <span class="math inline">\(f(x) = \frac{1}{2}M x^2\)</span> where <span class="math inline">\(x, M \in \mathbb{R}\)</span>. Here we can think of <span class="math inline">\(M\)</span> as the only, and therefore the largest, eigenvalue of the <span class="math inline">\(1 \times 1\)</span> matrix <span class="math inline">\([M]\)</span>.</p>
<p>Its GD update step looks like:</p>
<p><span class="math display">\[x^+ = x - \eta M x = (1 - \eta M)x\]</span></p>
<p>Which, by recursion from iteration <span class="math inline">\(T\)</span> down to the initial iteration, gives:</p>
<p><span class="math display">\[x^T = (1- \eta M)^Tx_0\]</span></p>
<p>Then, since <span class="math inline">\(x^* = 0\)</span>, convergence is guaranteed by ensuring <span class="math inline">\(|1 - \eta M| &lt; 1\)</span> or, equivalently, <span class="math inline">\(0 &lt; \eta &lt; \frac{2}{M}\)</span> as desired.</p>
<p>This generalizes to higher dimensions as we shall see in the following example.</p>
<hr>
<p><strong>Example 2:</strong></p>
<p>Consider the quadratic form in <span class="math inline">\(\mathbb{R}^n\)</span> given by <span class="math inline">\(f(x) = \frac{1}{2}x^TQx\)</span> where <span class="math inline">\(x \in \mathbb{R}^n\)</span> and <span class="math inline">\(Q \succeq 0\)</span>.</p>
<p>Its GD update step looks like:</p>
<p><span class="math display">\[x^+ = x - \eta Qx = (I - \eta Q)x\]</span></p>
<p>Which, by recursion from iteration <span class="math inline">\(T\)</span> down to the initial iteration, gives:</p>
<p><span class="math display">\[x^T = \underbrace{(I - \eta Q)\ldots(I - \eta Q)}_{\text{$T$ times}}x_0\]</span></p>
<p>The eigenvalues <span class="math inline">\(\tilde \lambda_i\)</span> of the matrix <span class="math inline">\(I - \eta Q\)</span> are related to the eigenvalues <span class="math inline">\(\lambda_i\)</span> of <span class="math inline">\(Q\)</span> according to:</p>
<p><span class="math display">\[\tilde \lambda_i = 1 - \eta \lambda_i\]</span></p>
<p>Hence, if <span class="math inline">\(\lambda_{min} = m\)</span> and <span class="math inline">\(\lambda_{max} = M\)</span>, then <span class="math inline">\(\tilde \lambda_{min} = 1 - \eta M\)</span> and <span class="math inline">\(\tilde \lambda_{max} =1 - \eta m\)</span>.</p>
<p>The eigenvalues of <span class="math inline">\(I - \eta Q\)</span> act on the current iterate by scaling it. So, in order to ensure convergence to <span class="math inline">\(0\)</span>, we need <span class="math inline">\(\tilde \lambda_i \in (-1,1) \ \ \forall i\)</span>. Or, equivalently:</p>
<p><span class="math display">\[\tilde \lambda_{min} &gt; -1\]</span> <span class="math display">\[\textrm{and}\]</span> <span class="math display">\[\tilde \lambda_{max} &lt; 1\]</span></p>
<p>Both of these together give us <span class="math inline">\(0 &lt; \eta &lt; \frac{2}{M}\)</span> as desired.</p>
<hr>
<p>But <span class="math inline">\(0 &lt; \eta &lt; \frac{2}{M}\)</span> is an interval, not a greedy choice. Itâ€™s just a condition that guarantees convergence. By making the greedy choice we can find the optimal step-size within this interval.</p>
<p>Since the RHS of <span class="math inline">\((5.2)\)</span> is strongly convex, the quadratic upper-bound is guaranteed to have a unique minimizer.</p>
<p>The idea is similar to other instances of making a greedy choice weâ€™ve seen so far. Since the function value is upper-bounded by this quadratic, minimizing this upper-bound gives the best guarantee of smallness for the function value available to us without access to higher order information about the objective. So, the greedy choice for the next iterate is:</p>
<p><span class="math display">\[
x^+ = \arg \min_y f(x) + \nabla f(x)^T(y-x) + \frac{M}{2}||y-x||_2^2
\]</span></p>
<p>As always, minimizing a quadratic is easy. After going through the motions we obtain:</p>
<p><span class="math display">\[x^+ = x - \frac{1}{M}\nabla f(x)\]</span></p>
<p>So, the optimal fixed step-size is <span class="math inline">\(\eta = \frac{1}{M}\)</span>.</p>
<p>We will see this idea of minimizing a quadratic approximation of the objective, instead of the objective itself, repeat itself when we get to <strong><em>Newtonâ€™s Method (NM)</em></strong>. However, NM is a second-oder oracle which has access to <span class="math inline">\(\nabla^2 f(x)\)</span>, and hence the quadratic approximation at all points in the domain of the objective is accessible to NM. The remarkable thing about <span class="math inline">\(M\)</span>-smoothness and <span class="math inline">\(m\)</span>-strong-convexity is that they give gradient descent, a first-order oracle, access to <em>universal</em> quadratic bounds which eliminates the need to know <span class="math inline">\(\nabla^2 f(x)\)</span>. These upper-bounds are, as we saw, what inform GDâ€™s choice of step-size which ends up guaranteeing convergence.</p>
</section>
<section id="convergence-rate" class="level2">
<h2 class="anchored" data-anchor-id="convergence-rate">Convergence Rate</h2>
<p>As shown above, the theoretical best fixed step-size for an <span class="math inline">\(M\)</span>-smooth objective <span class="math inline">\(f(x)\)</span> is <span class="math inline">\(\eta = \frac{1}{M}\)</span>. With this choice of step-size, we can derive convergence guarantees for GD as well as its convergence rate.</p>
<section id="m-smooth-objectives" class="level3">
<h3 class="anchored" data-anchor-id="m-smooth-objectives"><span class="math inline">\(M\)</span>-Smooth Objectives</h3>
<p>Fixing the current iterate as <span class="math inline">\(x\)</span>, and plugging in <span class="math inline">\(x^+ = x - \frac{1}{M} \nabla f(x)\)</span> into the upper-bound in <span class="math inline">\((5.1)\)</span>, we obtain the quadratic upper-bound on the next iterate in terms of the magnitude of the gradient:</p>
<p><span class="math display">\[f(x^+) \leq f(x) - \frac{1}{2M}||\nabla f(x)||_2^2 \tag{5.3}\]</span></p>
<p>Furthermore, since the underlying assumption throughout this post is that the objective is convex, we have a linear lower-bound <span class="math inline">\(\forall y\)</span>, and particularly at the optimizer <span class="math inline">\(y = x^*\)</span>, as:</p>
<p><span class="math display">\[f(x^*) \geq f(x) + \nabla f(x)^T(x^* - x) \tag{5.4}\]</span></p>
<p>By reversing <span class="math inline">\((5.4)\)</span> and adding it to <span class="math inline">\((5.3)\)</span> we get:</p>
<p><span class="math display">\[f(x^+) \leq f(x^*) + \nabla f(x)^T(x - x^*) - \frac{1}{2M}||\nabla f(x)||_2^2\]</span></p>
<p>With a bit of algebraic finessing, we can bring the above to the form:</p>
<p><span class="math display">\[f(x^+) \leq f(x^*) + \frac{M}{2}\left[ ||x-x^*||_2^2 - ||x - \frac{1}{M}\nabla f(x) - x^*||_2^2\right]\]</span></p>
<p>But <span class="math inline">\(x - \frac{1}{M}\nabla f(x) = x^+\)</span>, so we have:</p>
<p><span class="math display">\[f(x^+) - f(x^*) \leq \frac{M}{2}\left[ ||x-x^*||_2^2 - ||x^+ - x^*||_2^2\right]\]</span></p>
<p>We recognize, <span class="math inline">\(||x^+ - x^*||_2^2\)</span> as the sub-optimality of the next iterate, and <span class="math inline">\(||x - x^*||_2^2\)</span> as the sub-optimality of the previous iterate. When both sides are summed over <span class="math inline">\(T\)</span> iterations, the RHS sum telescopes and weâ€™re left with:</p>
<p><span class="math display">\[\sum_{t = 0}^{T-1} (f(x_{t+1}) - f(x_t)) \leq \frac{M}{2}||x_0 - x^*||_2^2\]</span></p>
<p>The LHS is the sum of sub-optimalities across all <span class="math inline">\(T\)</span> iterations, and the RHS is a quantity thatâ€™s proportional to the initial condition. Taking the average error across all iterations, we get:</p>
<p><span class="math display">\[\frac{1}{T} \sum_{t = 0}^{T-1} (f(x_{t+1}) - f(x_t)) \leq \frac{M}{2T}||x_0 - x^*||_2^2\]</span></p>
<p>But, we know that the algorithm with fixed step-size <span class="math inline">\(\eta = \frac{1}{M}\)</span> has the descent property since <span class="math inline">\(0 &lt; \frac{1}{M} &lt; \frac{2}{M}\)</span>. So, the last sub-optimality <span class="math inline">\(f(x_{T}) - f(x^*)\)</span> must be the smallest. In particular, it must be smaller than the average. So, we have:</p>
<p><span class="math display">\[f(x_{T}) - f(x^*) \leq \frac{M}{2T}||x_0 - x^*||_2^2 \tag{5.5}\]</span></p>
<p>So, the error gets better with more iterations and, conversely, gets worse the larger <span class="math inline">\(M\)</span>, a measure of how abruptly the gradient changes anywhere on its domain, is.</p>
<p>Note that <span class="math inline">\(M\)</span>, as well as <span class="math inline">\(||x_0 - x^*||_2^2\)</span> are fixed in <span class="math inline">\((5.5)\)</span>. So, the convergence rate of GD on an <span class="math inline">\(M\)</span>-smooth objective is <span class="math inline">\(O(\frac{1}{T})\)</span>.</p>
</section>
<section id="m-smooth-and-m-strongly-convex-objectives" class="level3">
<h3 class="anchored" data-anchor-id="m-smooth-and-m-strongly-convex-objectives"><span class="math inline">\(M\)</span>-Smooth and <span class="math inline">\(m\)</span>-Strongly-Convex Objectives</h3>
<p>The situation is drastically better if, in addition to <span class="math inline">\(M\)</span>-smoothness, we also have <span class="math inline">\(m\)</span>-strong-convexity. Not only do we get a much faster convergence rate, we also guarantee convergence in the iterates themselves. Note that, so far, weâ€™ve discussed sub-optimality in objective values only. That is, the only convergence guarantee weâ€™ve seen so far is <span class="math inline">\(f(x^T) \rightarrow f(x^*)\)</span> as <span class="math inline">\(T \rightarrow \infty\)</span>. Sometimes more is needed, we may actually want convergence of the iterates themselves. That is, we may want <span class="math inline">\(x^T \rightarrow x^*\)</span> as <span class="math inline">\(T \rightarrow \infty\)</span>? Since strong convexity guarantees the existence of a unique optimizer <span class="math inline">\(x^*\)</span>, we can discuss this type of sub-optimality for <span class="math inline">\(m\)</span>-strongly-convex objectives.</p>
<p>In this scenario, we have the analog of <span class="math inline">\((5.3)\)</span> for the quadratic lower-bound.</p>
<p>Just as <span class="math inline">\(x - \frac{1}{M} \nabla f(x)\)</span> minimized the quadratic upper-bound, <span class="math inline">\(x - \frac{1}{m} \nabla f(x)\)</span> minimizes the quadratic lower-bound. Plugging it into the lower-bound, we get <span class="math inline">\((5.3)\)</span>â€™s analog as:</p>
<p><span class="math display">\[f(y) \geq f(x) - \frac{1}{2m}||\nabla f(x)||_2^2 \ \ \forall y \tag{5.6}\]</span></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>This result is stronger than its analog <span class="math inline">\((5.3)\)</span> because it holds <span class="math inline">\(\forall y\)</span> as opposed to <span class="math inline">\((5.3)\)</span> which is only guaranteed to hold at the minimizer <span class="math inline">\(x^+ = x - \frac{1}{M}\nabla f(x)\)</span>. This is expected because <span class="math inline">\((5.6)\)</span> is the result of minimizing a universal lower-bound as opposed to <span class="math inline">\((5.3)\)</span> which is the result of minimizing a universal upper-bound.</p>
</div>
</div>
</div>
<p>Since <span class="math inline">\((5.6)\)</span> holds <span class="math inline">\(\forall y\)</span>, it holds, in particular, at the optimizer <span class="math inline">\(y=x^*\)</span>:</p>
<p><span class="math display">\[f(x^*) \geq f(x) - \frac{1}{2m}||\nabla f(x)||_2^2 \tag{5.7}\]</span></p>
<p>We can now solve for <span class="math inline">\(||\nabla f(x)||_2^2\)</span> in <span class="math inline">\((5.7)\)</span> and plug the result into <span class="math inline">\((5.3)\)</span>. From <span class="math inline">\((5.7)\)</span>, we get:</p>
<p><span class="math display">\[||\nabla f(x)||_2^2 \geq 2m(f(x)-f(x^*))\]</span></p>
<p>Which, when plugged into <span class="math inline">\((5.3)\)</span>, gives:</p>
<p><span class="math display">\[f(x^+) - f(x^*) \leq \left(1-\frac{m}{M}\right)(f(x)-f(x^*))\]</span></p>
<p>We recognize the LHS as the sub-optimality at the next iteration, and the RHS as the sub-optimality at the current iteration. Recursion from iteration <span class="math inline">\(T\)</span> down to the initial iteration, gives:</p>
<p><span class="math display">\[f(x_T) - f(x^*) \leq  \left(1-\frac{m}{M}\right)^T (f(x_0) - f(x^*)) \tag{5.8}\]</span></p>
<p>And, since <span class="math inline">\(m \leq M\)</span> and both strictly positive, <span class="math inline">\(0 &lt; \frac{m}{M} \leq 1\)</span> which guarantees convergence.</p>
<p>Note that <span class="math inline">\(m\)</span>, <span class="math inline">\(M\)</span>, and the initial sub-optimality <span class="math inline">\(f(x_0) - f(x^*)\)</span> are fixed quantities in <span class="math inline">\((5.8)\)</span>. So, the convergence rate of GD on a smooth and strongly-convex objective is <span class="math inline">\(O(c^{-T})\)</span> for the constant <span class="math inline">\(c^{-1} = 1 - \frac{m}{M}\)</span>. That is, the error decreases <em>exponentially</em> in the number of iterations. However, historically, mathematicians were concerned with the logarithm of the error, rather than the error itself, and hence this type of convergence is known as <strong><em>linear convergence</em></strong>.</p>
<p>As promised, we also have convergence of the iterates themselves. From the quadratic lower-bound in <span class="math inline">\((5.1)\)</span> we can derive an upper-bound on <span class="math inline">\(||x - x^*||_2\)</span> as follows. As before, letting <span class="math inline">\(y = x^*\)</span> in the quadratic lower-bound gives us:</p>
<p><span class="math display">\[f(x^*) \geq f(x) + \nabla f(x)^T(x^* - x) + \frac{m}{2}||x^* - x||_2^2\]</span></p>
<p>But, by the <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality"><strong><em>Cauchy-Schwarz Inequality</em></strong></a>, we further have:</p>
<p><span class="math display">\[f(x^*) \geq f(x) - ||\nabla f(x)||_2||(x^* - x)||_2 + \frac{m}{2}||x^* - x||_2^2\]</span></p>
<p>But, since <span class="math inline">\(f(x^*) \leq f(x)\)</span> by the optimality of <span class="math inline">\(x^*\)</span>, we must have:</p>
<p><span class="math display">\[- ||\nabla f(x)||_2||(x^* - x)||_2 + \frac{m}{2}||x^* - x||_2^2 \leq 0\]</span></p>
<p>From which it follows that:</p>
<p><span class="math display">\[||x - x^*||_2 \leq \frac{2}{m}||\nabla f(x)||_2 \tag{5.9}\]</span></p>
<p>As GD converges to <span class="math inline">\(f(x^*)\)</span>, <span class="math inline">\(\nabla f(x) \rightarrow \nabla f(x^*) = 0\)</span> where the last equality is by optimality of <span class="math inline">\(x^*\)</span>. So, <span class="math inline">\(x \rightarrow x^*\)</span>.</p>
</section>
<section id="affine-invariance" class="level3">
<h3 class="anchored" data-anchor-id="affine-invariance">Affine Invariance</h3>
<p>Not only does <span class="math inline">\((5.8)\)</span> give the rate of convergence of GD, it also predicts its performance on objectives with roughly spherical vs roughly elliptical level-sets. These are the level-sets of whatâ€™s referred to as <strong><em>badly</em></strong> and <strong><em>well conditioned</em></strong> objectives respectively.</p>
<p>To say that an objective is <span class="math inline">\(M\)</span>-smooth and <span class="math inline">\(m\)</span>-strongly convex is to say <span class="math inline">\((3.2)\)</span> which, as a reminder, is:</p>
<p><span class="math display">\[mI \preceq \nabla^2 f(x) \preceq MI \ \ \forall x\]</span></p>
<p>This implies that all the eigenvalues of the hessian are bounded between <span class="math inline">\(m\)</span> and <span class="math inline">\(M\)</span>. The eigenvalues of the hessian represent the stretch of the level sets in the principal directions. So, to say that <span class="math inline">\(\frac{m}{M} \approx 1\)</span> is to say that <span class="math inline">\(m \approx M\)</span>, which means that the level-sets are not more or less stretched in any particular direction. This implies that the level-sets are roughly spherical. As we can see from <span class="math inline">\((5.8)\)</span>, GD converges quite fast in such cases since <span class="math inline">\(\left( 1 - \frac{m}{M} \right)\)</span>, the factor of decrease, is small. The opposite is true in the case when the level sets are elongated.</p>
<p>This brings us to an important property called <strong><em>affine invariance</em></strong> which GD lacks. Simply put, an affine transformation of the input space (i.e.&nbsp;a mere change of coordinates/basis) may affect GDâ€™s performance drastically.</p>
<p>It helps to look at an example where the objective is a simple quadratic in <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<hr>
<p>Take the quadratic objective <span class="math inline">\(f(x) = \frac{1}{2}x^TQx\)</span> where <span class="math inline">\(x \in \mathbb{R}^n\)</span> is a coordinate vector in the standard basis. Now, consider the change of coordinates from the standard basis to a basis <span class="math inline">\(Z\)</span> given by <span class="math inline">\(Az = x\)</span> where <span class="math inline">\(A\)</span> is a matrix whose column vectors are the basis vectors in <span class="math inline">\(Z\)</span>.</p>
<p>The key observation is that we can choose <span class="math inline">\(A\)</span> in such a way as to make the objective in the new coordinate system have more or less elliptical level-sets which would affect GDâ€™s performance.</p>
<p>First, letâ€™s come up with the same quadratic in <span class="math inline">\(Z\)</span>-coordinates.</p>
<p><span class="math display">\[f(x) = f(Az) = \frac{1}{2}(Az)^TQAz = z^TA^TQAz\]</span></p>
<p>Let <span class="math inline">\(\tilde Q = A^TQA\)</span> and define the quadratic in <span class="math inline">\(Z\)</span>-coordinates as <span class="math inline">\(\tilde f(z) = \frac{1}{2}z^T \tilde Q z\)</span> so that <span class="math inline">\(\tilde f(z) = f(x)\)</span> for all <span class="math inline">\(z\)</span> in the <span class="math inline">\(Z\)</span>-coordinates corresponding to <span class="math inline">\(x\)</span> in the standard basis. In particular, optimizing in either coordinate system yields the same result in terms of an optimum, that is <span class="math inline">\(\tilde f(z^*) = f(x^*)\)</span>.</p>
<p>The GD factor of decrease on <span class="math inline">\(\tilde f\)</span> is <span class="math inline">\(\left(1 - \frac{\tilde m}{\tilde M} \right)\)</span>, where <span class="math inline">\(\tilde m = \lambda_{\min}(\tilde Q)\)</span> and <span class="math inline">\(\tilde M = \lambda_{\max}(\tilde Q)\)</span>. But <span class="math inline">\(\left(1 - \frac{\tilde m}{\tilde M} \right)\)</span> is under no obligation to be equal to <span class="math inline">\(\left(1 - \frac{m}{M} \right)\)</span>, the GD factor of decrease in the standard basis, proving that GD is <em>not</em> affine invariant.</p>
<p>Another perspective on affine invariance comes from comparing the GD update steps in both spaces.</p>
<p>The GD update in the standard basis is:</p>
<p><span class="math display">\[x^+ = x - \eta \nabla f(x) = x - \eta Qx\]</span></p>
<p>Whereas the GD update in <span class="math inline">\(Z\)</span>-coordinates is:</p>
<p><span class="math display">\[z^+ = z - \eta \nabla \tilde f(z) = z - \eta \tilde Qz\]</span></p>
<p>To go from <span class="math inline">\(Z\)</span>-coordinates back to the standard basis, we apply <span class="math inline">\(A\)</span> to the LHS which necessitates its application to the RHS as well. We obtain:</p>
<p><span class="math display">\[Az^+ = Az - \eta A\tilde Qz = x - \eta AA^TQx\]</span></p>
<p>Which is <em>not</em> the same as <span class="math inline">\(x - \eta Qx\)</span>. So, although <span class="math inline">\(Az = x\)</span> the linear relationship breaks down for the next iterates produced by GD (that is <span class="math inline">\(Az^+ \ne x^+\)</span>). So, doing a step of GD in the standard basis itâ€™s not the same as doing a step of GD in <span class="math inline">\(Z\)</span>-coordinates (up to a change of basis by <span class="math inline">\(A\)</span>). So, gradient descent is doing something radically different in the <span class="math inline">\(Z\)</span>-coordinates compared to what it does in the standard basis.</p>
<hr>
<section id="best-affine-transformation" class="level4">
<h4 class="anchored" data-anchor-id="best-affine-transformation">Best Affine Transformation</h4>
<p>A natural question to ask, at this point, is which choice of <span class="math inline">\(A\)</span> makes GD perform faster on a quadratic objective?</p>
<p>Algebraically, the best we can hope for is <span class="math inline">\(A\)</span> s.t. <span class="math inline">\(\tilde m \approx \tilde M\)</span>. One way we can accomplish this is by forcing <em>all</em> of the eigenvalues of <span class="math inline">\(\tilde Q\)</span> to be the same. Particularly, letting them all be <span class="math inline">\(1\)</span> by enforcing <span class="math inline">\(\tilde Q = A^TQA = I\)</span> works.</p>
<p>Since <span class="math inline">\(Q \succeq 0\)</span>, it has an eigendecomposition as <span class="math inline">\(Q = PDP^T\)</span> where <span class="math inline">\(D\)</span> is diagonal and <span class="math inline">\(P\)</span> is orthonormal. Then its matrix square root exists and is given by <span class="math inline">\(Q^{-1/2} = PD^{-1/2}P^T\)</span>. Letting <span class="math inline">\(A = Q^{-1/2}\)</span> we, indeed, have:</p>
<p><span class="math display">\[
\begin{aligned}
A^TQA &amp;= (PD^{-1/2}P^T)^TPDP^TPD^{-1/2}P^T \\
&amp;= PD^{-1/2}DD^{-1/2}P^T \\
&amp;= PP^T \\
&amp;= I \\
\end{aligned}\]</span></p>
<p>Where we have used the fact that <span class="math inline">\(P^TP = PP^T = I\)</span> since <span class="math inline">\(P\)</span> is orthonormal, and the fact that diagonal matrices are raised to a power simply by raising their diagonal entries to that power.</p>
<p>Geometrically, the choice of <span class="math inline">\(\tilde Q = I\)</span> forces the level-sets to be spherical. A level-set of <span class="math inline">\(f(x) = \frac{1}{2}x^TQx\)</span> in the standard coordinate system, i.e.&nbsp;an ellipse in <span class="math inline">\(\mathbb{R}^n\)</span>, is given by <span class="math inline">\(x^TQx = c\)</span> for some constant <span class="math inline">\(c\)</span> which has absorbed <span class="math inline">\(\frac{1}{2}\)</span>. In the <span class="math inline">\(Z\)</span>-coordinates, the same level-set is given by <span class="math inline">\(\tilde f(z) = z^T\tilde Qz = c\)</span>. If <span class="math inline">\(\tilde Q = I\)</span>, as is the case for the choice <span class="math inline">\(A = Q^{-1/2}\)</span>, then the level-set in the <span class="math inline">\(Z\)</span>-coordinates becomes <span class="math inline">\(z^Tz = c\)</span> which is, indeed, a sphere in <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<p>In conclusion, if the objective is quadratic, we can improve GDâ€™s convergence rate by applying the above change of basis. If the objective is not quadratic, we may still assume that itâ€™s locally quadratic. This allows us to apply the same idea to non-quadratic objectives, but, since it requires coming up with a different matrix <span class="math inline">\(A\)</span> at each iteration, the payoff from this procedure may not be worth it. So, we explore other ways of accelerating the performance of gradient descent on badly conditioned objectives by developing <strong><em>Accelerated Gradient Descent (AGD)</em></strong> which will be explained shortly.</p>
</section>
</section>
</section>
</section>
<section id="variable-step-size-gd" class="level1">
<h1>Variable Step-Size GD</h1>
<p>While smoothness gives the theoretical best step-size <span class="math inline">\(\eta = \frac{1}{M}\)</span>, for most problems it can be quite difficult, or impossible, to come up with the smoothness parameter <span class="math inline">\(M\)</span>. So, while informative, the discussion weâ€™ve had so far has been largely theoretical. In practice, there are subroutines such as <strong><em>Exact Line Search (ELS)</em></strong> or <strong><em>Backtracking Line Search (BTLS)</em></strong> which choose an appropriate step-size <span class="math inline">\(\eta_t\)</span> at each iteration. These subroutines can also be modified and used with other optimization algorithms. For example, BTLS is the state of the art way of choosing a step-size in Newtonâ€™s and <strong><em>Quasi-Newtonâ€™s Methods</em></strong>.</p>
<section id="exact-line-search-els" class="level2">
<h2 class="anchored" data-anchor-id="exact-line-search-els">Exact Line Search (ELS)</h2>
<p>Letâ€™s go back to the general iterative update step <span class="math inline">\(x^+ = x + \eta d\)</span>.</p>
<p>By restricting the objective in the direction of the update <span class="math inline">\(d\)</span> we can find the optimal step-size, <span class="math inline">\(\eta^*\)</span>, at each iteration by solving the following one-dimensional, unconstrained optimization problem in <span class="math inline">\(\eta\)</span>:</p>
<p><span class="math display">\[\eta^* = \arg \min_{\eta} f(x + \eta d) \tag{6.1}\]</span></p>
<p>We proceed with the optimization by defining the restriction of <span class="math inline">\(f\)</span> in the direction <span class="math inline">\(d\)</span> as <span class="math inline">\(\phi(\eta) := f(x + \eta d)\)</span>. Then, we can use the chain-rule to find the stationary point <span class="math inline">\(\eta^*\)</span> for which <span class="math inline">\(\nabla \phi(\eta^*) = 0\)</span>.</p>
<p>By chain-rule:</p>
<p><span class="math display">\[\nabla \phi(\eta) = \nabla f(x + \eta d)^T d \tag{6.2}\]</span></p>
<p>In the case of GD, <span class="math inline">\(d = -\nabla f(x)\)</span>, so we have:</p>
<p><span class="math display">\[\nabla \phi(\eta) = \nabla f(x - \eta \nabla f(x))^T (-\nabla f(x)) \tag{6.3}\]</span></p>
<p>An interesting geometric consequence of this is that GD with ELS takes perpendicular steps that end at a point of tangency with a level-set. Setting <span class="math inline">\(\nabla \phi(\eta) = 0\)</span> to find the optimal step-size obtains <span class="math inline">\(\eta^*\)</span> s.t. <span class="math inline">\(\nabla f(x - \eta^* \nabla f(x))\)</span> is perpendicular to <span class="math inline">\(- \nabla f(x)\)</span>. In other words, GD with ELS goes in the negative gradient direction until the gradient at <span class="math inline">\(x - \eta^* \nabla f(x)\)</span> is perpendicular to the gradient at the current iterate <span class="math inline">\(x\)</span>. At the next iteration, GD will take a step in the <span class="math inline">\(- \nabla f(x - \eta^* \nabla f(x))\)</span> direction which is still perpendicular to <span class="math inline">\(- \nabla f(x)\)</span>. This means, at each iteration, GD takes a step thatâ€™s perpendicular to the step it took in the previous iteration. Furthermore, since gradients are always perpendicular to level-sets, the new iterate <span class="math inline">\(x - \eta^* \nabla f(x)\)</span> is a point of tangency with the level-set at that point.</p>
<p>Although this subroutine is very natural, it may be infeasible to solve an optimization problem (even a one-dimensional one) at each iteration. Hence, we introduce backtracking line search.</p>
</section>
<section id="backtracking-line-search-btls" class="level2">
<h2 class="anchored" data-anchor-id="backtracking-line-search-btls">Backtracking Line Search (BTLS)</h2>
<p>As we know a convex objective <span class="math inline">\(f\)</span> is always lower-bounded by its linear approximation. That is:</p>
<p><span class="math display">\[f(y) \geq f(x) + \nabla f(x)^T(y - x) \ \ \forall y\]</span></p>
<p>Plugging <span class="math inline">\(x^+ = x + \eta d\)</span> into the above lower-bound obtains:</p>
<p><span class="math display">\[f(x^+) \geq f(x) + \eta \nabla f(x)^T d\]</span></p>
<p>So, the greatest possible reduction in value from <span class="math inline">\(f(x)\)</span> to <span class="math inline">\(f(x^+)\)</span> we can hope for is <span class="math inline">\(\eta \nabla f(x)^T d\)</span> which, recall, is non-positive by a choice of <span class="math inline">\(d\)</span> that guarantees descent (such as <span class="math inline">\(d = -\nabla f(x)\)</span> in gradient descent). Unless the objective is linear, in which case the above linear approximation holds with equality, we can not hope to achieve the full <span class="math inline">\(\eta \nabla f(x)^T d\)</span> reduction in value. This is just a consequence of convexity and is, therefore, also the case when using exact line search.</p>
<p>The idea behind backtracking line search is to ensure we achieve, at least, a fraction of this maximum reduction in value by introducing a parameter <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span>.</p>
<p>Since <span class="math inline">\(f(x) + \eta \nabla f(x)^T d\)</span>, the linear underestimate of <span class="math inline">\(f(x^+)\)</span>, is the tangent line to <span class="math inline">\(f\)</span> at <span class="math inline">\(x\)</span> in the direction <span class="math inline">\(d\)</span>, <span class="math inline">\(f(x) + \alpha \eta \nabla f(x)^T d\)</span> (for <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span>) is a secant line of <span class="math inline">\(f\)</span> at <span class="math inline">\(x\)</span> in the direction <span class="math inline">\(d\)</span>. Setting <span class="math inline">\(\alpha = \frac{1}{2}\)</span>, a typical choice in practice, and finding the <em>largest</em> <span class="math inline">\(\eta\)</span> s.t. <span class="math inline">\(f(x^+) = (x + \eta d)\)</span> is still below this secant line ensures we get approximately half of the maximum reduction in value <span class="math inline">\(\eta \nabla f(x)^T d\)</span>.</p>
<p>This is exactly what the BTLS subroutine, detailed below, tries to achieve:</p>
<section id="the-btls-subroutine" class="level3">
<h3 class="anchored" data-anchor-id="the-btls-subroutine">The BTLS Subroutine</h3>
<ol type="1">
<li><p>The BTLS subroutine takes as input <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span>, and <span class="math inline">\(0 &lt; \beta &lt; 1\)</span>.</p></li>
<li><p>While <span class="math inline">\(f(x + \eta d) &gt; f(x) + \alpha \eta \nabla f(x)^T d\)</span>, it reduces <span class="math inline">\(\eta\)</span> by the update <span class="math inline">\(\eta \leftarrow\)</span> <span class="math inline">\(\beta \eta\)</span>.</p></li>
</ol>
</section>
<section id="convergence-guarantees-of-gd-with-btls" class="level3">
<h3 class="anchored" data-anchor-id="convergence-guarantees-of-gd-with-btls">Convergence Guarantees of GD with BTLS</h3>
<p>Gradient descent with backtracking line search has a promising convergence guarantee for convex objectives that are also <span class="math inline">\(M\)</span>-smooth.</p>
<blockquote class="blockquote">
<p><strong>Convergence of GD with BTLS:</strong> &nbsp; If <span class="math inline">\(f\)</span> is <span class="math inline">\(M\)</span>-smooth and convex then the step-size given by BTLS is s.t.</p>
<p><span class="math inline">\(\eta_{BTLS} \geq \frac{\beta}{M}\)</span>. Furthermore, <span class="math inline">\(f(x^+) - f(x) \leq \frac{\alpha \beta}{M}||\nabla f(x)||_2^2\)</span></p>
</blockquote>
<p>So, compared to the theoretical best step-size <span class="math inline">\(\eta = \frac{1}{M}\)</span>, which may not be accessible to us, we have <span class="math inline">\(\frac{\beta}{M} \leq \eta_{BTLS} &lt; \frac{1}{M}\)</span>. So, <span class="math inline">\(\beta_{BTLS}\)</span> is less than the optimal step-size but, interestingly, it still keeps <span class="math inline">\(M\)</span> in view despite the latter being unknown to us.</p>
<p>Furthermore, for an <span class="math inline">\(M\)</span>-smooth objective, the final sub-optimality after <span class="math inline">\(T\)</span> iterations can be found as:</p>
<p><span class="math display">\[f(x_T) - f(x^*) \leq \frac{M}{2T \alpha \beta}||x_0 - x^*||_2^2 \tag{7.1}\]</span></p>
<p>Which is only a constant factor <span class="math inline">\(\alpha \beta\)</span> worse than GD with the theoretical best fixed step-size. So, itâ€™s still <span class="math inline">\(O(1/T)\)</span>.</p>
<p>For an <span class="math inline">\(M\)</span>-smooth objective thatâ€™s also <span class="math inline">\(m\)</span>-strongly convex, we have:</p>
<p><span class="math display">\[f(x_T) - f(x^*) \leq \left (1 - \min \left\{ 2m\alpha, \frac{2\alpha\beta m}{M} \right \} \right )^T||x_0 - x^*||_2^2 \tag{7.2}\]</span></p>
<p>Which is, again, comparable to GD with the theoretical best fixed step-size.</p>
</section>
</section>
</section>
<section id="theoretical-error-bounds-on-first-order-oracles" class="level1">
<h1>Theoretical Error Bounds on First Order Oracles</h1>
<p>As we saw the convergence rates of GD were upper-bounded by <span class="math inline">\(O\left (\frac{1}{T} \right )\)</span> and <span class="math inline">\(O\left (\left(1 - \frac{m}{M} \right)^T \right)\)</span> for <span class="math inline">\(M\)</span> and <span class="math inline">\(m\)</span> conditioned objectives. We also mentioned that GD can be accelerated, which begs the question: how much can we improve the error?</p>
<p>Turns out, there are asymptotic lower-bounds on the error produced by <em>any</em> first-order oracle. So, just as the error of GD cannot be worse that its asymptotic upper-bounds, it cannot be better than its asymptotic lower-bounds.</p>
<p>First, we define a first order oracle more generally as any iterative algorithm of the form:</p>
<p><span class="math display">\[x_{t+1} \in x_t + span \{ \nabla f(x_t), \nabla f(x_{t-1}), ..., \nabla f(x_0)\}\]</span></p>
<p>Note that GD falls in this category as it only uses <span class="math inline">\(\nabla f(x_t)\)</span> which is, indeed, in the span.</p>
<p>For any such algorithm, the lower-bounds on the error are given as the following two-part theorem.</p>
<blockquote class="blockquote">
<p><strong>First-Order Oracle Error Lower-Bounds:</strong> &nbsp; For any first-order Oracle:</p>
<ol type="1">
<li><span class="math inline">\(\exists\)</span> a convex, <span class="math inline">\(M\)</span>-smooth function <span class="math inline">\(f\)</span> for which the error is <span class="math inline">\(\Omega \left (\frac{1}{T^2} \right )\)</span></li>
<li><span class="math inline">\(\exists\)</span> an <span class="math inline">\(M\)</span>-smooth, <span class="math inline">\(m\)</span>-strongly-convex function <span class="math inline">\(f\)</span> for which the error is <span class="math inline">\(\Omega \left (\left (1-\sqrt{\frac{m}{M}} \right )^T \right )\)</span></li>
</ol>
</blockquote>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Since <span class="math inline">\(0 &lt; \frac{m}{M} \leq 1\)</span>, its square root is larger. Hence, <span class="math inline">\(1 - \sqrt{\frac{m}{M}}\)</span> is smaller than <span class="math inline">\(1 - \frac{m}{M}\)</span>. So <span class="math inline">\(\left (1-\sqrt{\frac{m}{M}} \right )^T\)</span>, the lower bound, indeed grows slower than <span class="math inline">\(\left ( 1 - \frac{m}{M} \right )^T\)</span>, the upper-bound.</p>
</div>
</div>
</div>
<p>Any first-order oracle, including Accelerated GD, cannot hope for error thatâ€™s asymptotically better than these lower-bounds. In fact, we shall see that AGD achieves these lower-bounds exactly, thereby closing the first-order oracle error gap.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/v-poghosyan\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="v-poghosyan/blog" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2021, Vahram Poghosyan</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.github.com/v-poghosyan">
      <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/vahrampoghosyan/">
      <i class="bi bi-linkedin" role="img" aria-label="GitHub">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script type="application/javascript" src="../../javascript/light-dark.js"></script>




</body></html>