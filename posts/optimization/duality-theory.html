<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vahram Poghosyan">
<meta name="dcterms.date" content="2022-01-23">

<title>Duality Theory – v-poghosyan.github.io</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-KLCX05QFPN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-KLCX05QFPN', { 'anonymize_ip': true});
</script>
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">v-poghosyan.github.io</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Duality Theory</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Optimization</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Vahram Poghosyan </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 23, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-dual-of-a-constrained-problem" id="toc-the-dual-of-a-constrained-problem" class="nav-link" data-scroll-target="#the-dual-of-a-constrained-problem">The Dual of a Constrained Problem</a>
  <ul class="collapse">
  <li><a href="#the-lagrangian-dual-variables-and-the-dual-function" id="toc-the-lagrangian-dual-variables-and-the-dual-function" class="nav-link" data-scroll-target="#the-lagrangian-dual-variables-and-the-dual-function">The Lagrangian, Dual Variables, and the Dual Function</a></li>
  <li><a href="#a-lagrangian-lower-bound" id="toc-a-lagrangian-lower-bound" class="nav-link" data-scroll-target="#a-lagrangian-lower-bound">A Lagrangian Lower-Bound</a></li>
  <li><a href="#the-lagrange-dual-problem" id="toc-the-lagrange-dual-problem" class="nav-link" data-scroll-target="#the-lagrange-dual-problem">The Lagrange Dual Problem</a></li>
  </ul></li>
  <li><a href="#weak-duality-and-interpretations" id="toc-weak-duality-and-interpretations" class="nav-link" data-scroll-target="#weak-duality-and-interpretations">Weak Duality and Interpretations</a>
  <ul class="collapse">
  <li><a href="#the-max-min-inequality" id="toc-the-max-min-inequality" class="nav-link" data-scroll-target="#the-max-min-inequality">The Max-Min Inequality</a>
  <ul class="collapse">
  <li><a href="#game-theoretic-interpretation" id="toc-game-theoretic-interpretation" class="nav-link" data-scroll-target="#game-theoretic-interpretation">Game-Theoretic Interpretation</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#strong-duality-and-interpretations" id="toc-strong-duality-and-interpretations" class="nav-link" data-scroll-target="#strong-duality-and-interpretations">Strong Duality and Interpretations</a>
  <ul class="collapse">
  <li><a href="#slaters-condition---sufficient-condition-for-strong-duality" id="toc-slaters-condition---sufficient-condition-for-strong-duality" class="nav-link" data-scroll-target="#slaters-condition---sufficient-condition-for-strong-duality">Slater’s Condition - Sufficient Condition for Strong Duality</a></li>
  <li><a href="#the-max-min-equality" id="toc-the-max-min-equality" class="nav-link" data-scroll-target="#the-max-min-equality">The Max-Min Equality</a>
  <ul class="collapse">
  <li><a href="#game-theoretic-interpretation-1" id="toc-game-theoretic-interpretation-1" class="nav-link" data-scroll-target="#game-theoretic-interpretation-1">Game-Theoretic Interpretation</a></li>
  </ul></li>
  <li><a href="#an-easier-dual-problem" id="toc-an-easier-dual-problem" class="nav-link" data-scroll-target="#an-easier-dual-problem">An Easier Dual Problem</a></li>
  </ul></li>
  <li><a href="#theorems-of-the-alternative" id="toc-theorems-of-the-alternative" class="nav-link" data-scroll-target="#theorems-of-the-alternative">Theorems of the Alternative</a>
  <ul class="collapse">
  <li><a href="#farkas-lemma" id="toc-farkas-lemma" class="nav-link" data-scroll-target="#farkas-lemma">Farkas’ Lemma</a></li>
  <li><a href="#proving-a-theorem-of-the-alternative" id="toc-proving-a-theorem-of-the-alternative" class="nav-link" data-scroll-target="#proving-a-theorem-of-the-alternative">Proving a Theorem of the Alternative</a>
  <ul class="collapse">
  <li><a href="#proof-using-a-separation-argument" id="toc-proof-using-a-separation-argument" class="nav-link" data-scroll-target="#proof-using-a-separation-argument">Proof using a Separation Argument</a></li>
  <li><a href="#proof-using-strong-duality" id="toc-proof-using-strong-duality" class="nav-link" data-scroll-target="#proof-using-strong-duality">Proof using Strong Duality</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#strong-duality---optimality-conditions" id="toc-strong-duality---optimality-conditions" class="nav-link" data-scroll-target="#strong-duality---optimality-conditions">Strong Duality - Optimality Conditions</a>
  <ul class="collapse">
  <li><a href="#stationarity-condition" id="toc-stationarity-condition" class="nav-link" data-scroll-target="#stationarity-condition">Stationarity Condition</a></li>
  <li><a href="#complementary-slackness" id="toc-complementary-slackness" class="nav-link" data-scroll-target="#complementary-slackness">Complementary Slackness</a></li>
  <li><a href="#karush-kuhn-tucker-kkt-conditions" id="toc-karush-kuhn-tucker-kkt-conditions" class="nav-link" data-scroll-target="#karush-kuhn-tucker-kkt-conditions">Karush-Kuhn-Tucker (KKT) Conditions</a>
  <ul class="collapse">
  <li><a href="#generalization-of-unconstrained-optimization" id="toc-generalization-of-unconstrained-optimization" class="nav-link" data-scroll-target="#generalization-of-unconstrained-optimization">Generalization of Unconstrained Optimization</a></li>
  <li><a href="#certificate-of-optimality" id="toc-certificate-of-optimality" class="nav-link" data-scroll-target="#certificate-of-optimality">Certificate of Optimality</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#strong-duality---linear-programs" id="toc-strong-duality---linear-programs" class="nav-link" data-scroll-target="#strong-duality---linear-programs">Strong Duality - Linear Programs</a>
  <ul class="collapse">
  <li><a href="#proof-of-strong-duality-in-lps" id="toc-proof-of-strong-duality-in-lps" class="nav-link" data-scroll-target="#proof-of-strong-duality-in-lps">Proof of Strong Duality in LP’s</a>
  <ul class="collapse">
  <li><a href="#prelude-1" id="toc-prelude-1" class="nav-link" data-scroll-target="#prelude-1">Prelude</a></li>
  <li><a href="#proof-1" id="toc-proof-1" class="nav-link" data-scroll-target="#proof-1">Proof</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#further-reading---duality-in-unconstrained-problems" id="toc-further-reading---duality-in-unconstrained-problems" class="nav-link" data-scroll-target="#further-reading---duality-in-unconstrained-problems">Further Reading - Duality in Unconstrained Problems</a>
  <ul class="collapse">
  <li><a href="#fl-transform---a-convex-operation" id="toc-fl-transform---a-convex-operation" class="nav-link" data-scroll-target="#fl-transform---a-convex-operation">FL Transform - a Convex Operation</a></li>
  <li><a href="#the-case-of-involution" id="toc-the-case-of-involution" class="nav-link" data-scroll-target="#the-case-of-involution">The Case of Involution</a></li>
  <li><a href="#inverse-gradients" id="toc-inverse-gradients" class="nav-link" data-scroll-target="#inverse-gradients">Inverse Gradients</a></li>
  <li><a href="#fl-duality" id="toc-fl-duality" class="nav-link" data-scroll-target="#fl-duality">FL Duality</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Every convex optimization problem, designated as the <strong><em>primal</em></strong>, has a related problem called its <strong><em>dual</em></strong> which can be colloquially thought of as its evil twin. The primal and the dual represent two different perspectives on the same problem.</p>
<p>In the most general case, if the primal is a minimization problem, its dual is a maximization problem. In the case of constrained optimization, if the primal is minimization in <span class="math inline">\(n\)</span> variables and <span class="math inline">\(m\)</span> constraints then its dual is a maximization in <span class="math inline">\(m\)</span> variables and <span class="math inline">\(n\)</span> constraints.</p>
<p>Furthermore, <em>any</em> feasible value of the dual is a lower-bound for <em>all</em> feasible values of the primal. In particular, should they both exist, the dual optimum is a lower bound for the primal optimum. This property, called <strong><em>weak duality</em></strong>, lies at the core of <strong><em>duality theory</em></strong>. The utility of formulating a problem whose solution obtains, at least, a lower-bound for the primal optimum and, in the special case, the primal optimum itself should be self-evident.</p>
<p>In the best case scenario a problem exhibits a property called <strong><em>strong duality</em></strong>, which guarantees that the primal and the dual optima agree. Such problems are called <strong><em>strongly dual problems</em></strong> and include, but are not limited to, all linear programs (LPs) and a category of convex non-linear optimization problems. For strongly dual problems, solving the dual guarantees that we’ve also solved the primal. Furthermore, as we shall see, taking the dual of the dual gives back the primal. So this relationship is true in the converse — if we’ve solved the primal then we’ve also solved its dual.</p>
<p>This is what makes duality theory so useful in practice. Having a related, usually easier, optimization problem gives applied scientists a huge computational advantage. However, even if the dual does not turn out to be any easier to solve and/or strong duality fails to hold, we still stand to gain structural insight about the primal problem itself.</p>
<p>In this post we show how the dual of a problem arises, we examine its relationship with the primal, and list all possible primal-dual outcomes. In doing so, we look at duality in the general case of constrained optimization, in the specific case of linear programs, and in a category of unconstrained problems.</p>
</section>
<section id="the-dual-of-a-constrained-problem" class="level1">
<h1>The Dual of a Constrained Problem</h1>
<p>First, let’s focus on deriving the dual of a constrained optimization problem. We shall see that, in a sense, constraints are what give rise to duality through the <a href="https://en.wikipedia.org/wiki/Lagrangian_relaxation">Lagrangian</a>. Certain types of unconstrained problems also have duals which arise either from introducing dummy constraints, or directly through the <a href="https://en.wikipedia.org/wiki/Convex_conjugate">Fenchel-Legendre Transform</a>.</p>
<p>Take the most general form of a convex, constrained problem with <span class="math inline">\(m\)</span> inequality and <span class="math inline">\(n\)</span> equality constraints. To make the discussion interesting, assume the problem is non-trivial (i.e.&nbsp;its constraint set is non-empty and contains more than one feasible point). Furthermore, so that we may have a solution to speak of, assume the problem is bounded with the finite optimum <span class="math inline">\(f_0(x^*)\)</span> for some optimizer <span class="math inline">\(x^*\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\min_x &amp;: f_0(x)
\\
s.t. &amp;: \begin{aligned} &amp;f_i(x) \leq 0 \ \ i = 1, ...,m
\\
&amp;h_i(x) = 0 \ \ i = 1, ... ,p
\end{aligned}
\end{aligned}
\]</span></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The <span class="math inline">\(f_i\)</span>’s and the <span class="math inline">\(h_i\)</span>’s in the constraints must necessarily be convex in order for their sublevel-sets, and hence the problem itself, to be convex. However, the equality constraints may be given as <span class="math inline">\(Ax = b\)</span> in some sources. These representations are practically almost equivalent. The <span class="math inline">\(0\)</span>-th level-set of <span class="math inline">\(Ax - b\)</span>, <span class="math inline">\(\{ x : Ax = b\}\)</span>, is indeed a convex set. However, <span class="math inline">\(h_i\)</span>’s in the equality constraints <span class="math inline">\(h_i(x) = 0\)</span> need not be linear for the <span class="math inline">\(0\)</span>-th level-set, <span class="math inline">\(\{ x : h_i(x) = 0 \}\)</span>, to be convex. For example, in <span class="math inline">\(\mathbb{R}\)</span>, <span class="math inline">\(x^2 = 0\)</span> does represent a convex level-set. Note, however, that <span class="math inline">\(x^2 = 0\)</span> can be reduced to <span class="math inline">\(x = 0\)</span> which is, indeed, linear. To be precise, the notion of <a href="https://en.wikipedia.org/wiki/Quasiconvex_function">quasi-linearity</a> is what’s needed here. But, in practice, we simply <em>define</em> a general convex problem as having only linear equality constraints. Doing so assists in the analysis of problems and in the development of the computational methods that solve them.</p>
</div>
</div>
</div>
<p>Since optimizing an unconstrained problem is considerably easier than optimizing one that is constrained, we seek to augment the constrained problem into an equivalent unconstrained problem.</p>
<p>The idea is to penalize infeasible <span class="math inline">\(x\)</span> using functions that express our <em>displeasure</em> for certain choices.</p>
<p>At first we use the <em>infinitely-hard</em> penalty functions <span class="math inline">\(\mathbb{1}_-\)</span> and <span class="math inline">\(\mathbb{1}_0\)</span> which are defined as follows:</p>
<p><span class="math display">\[\mathbb{1}_-(u) =
\begin{cases}
\begin{aligned}
&amp;0  &amp;\textrm{if} \ u \leq 0
\\
&amp;\infty  &amp;\textrm{if} \ u &gt; 0
\end{aligned}
\end{cases}\]</span> <br> <span class="math display">\[\mathbb{1}_0(u) =
\begin{cases}
\begin{aligned}
&amp;0  &amp;\textrm{if} \ u = 0
\\
&amp;\infty  &amp;\textrm{if} \ u \ne 0
\end{aligned}
\end{cases}\]</span></p>
<p>Then the equivalent unconstrained problem can be stated as:</p>
<p><span class="math display">\[\min_x: \mathcal{J}(x)\]</span></p>
<p>where <span class="math inline">\(\mathcal{J}(x) = f_0(x) + \sum_{i=1}^m \mathbb{1}_-(f_i(x)) + \sum_{i=1}^p \mathbb{1}_0(h_i(x))\)</span>.</p>
<p>Equivalently, by naming the primal feasible set <span class="math inline">\(\mathcal{X}\)</span>, we can express the objective <span class="math inline">\(\mathcal{J}(x)\)</span> as:</p>
<p><span class="math display">\[
\mathcal{J}(x) = \begin{cases}\begin{aligned}
&amp;f_0(x) \ \ x \in \mathcal{X}
\\
&amp;\infty \ \ \textrm{otherwise}
\end{aligned}\end{cases}
\]</span></p>
<p>Informally, if an <span class="math inline">\(\hat x\)</span> is chosen s.t <em>one or more</em> of the constraints are broken then the minimization incurs an infinitely positive penalty. Therefore, such a <span class="math inline">\(\hat x\)</span> will never be selected over any feasible choice, <span class="math inline">\(x \in \mathcal{X}\)</span>, which gives a finite value of <span class="math inline">\(f_0(x)\)</span>. Moreover, by optimality of <span class="math inline">\(x^*\)</span> in the original problem, we have <span class="math inline">\(f_0(x) \leq f_0(x^*) \ \ \forall x\)</span>. So, the optimum of <span class="math inline">\(\mathcal{J}\)</span> will also be <span class="math inline">\(f_0(x^*)\)</span>.</p>
<p>That is:</p>
<p><span class="math display">\[\min_x \mathcal{J}(x) = f_0(x^*) \tag{1}\]</span></p>
<p>Moreover, since the optimizer <span class="math inline">\(x^*\)</span> for the original problem is feasible, <span class="math inline">\(\mathcal{J}(x^*) = f_0(x^*)\)</span> by definition. It follows, by substitution into <span class="math inline">\((1)\)</span>, that:</p>
<p><span class="math display">\[\mathcal{J}(x^*) = \min_x \mathcal{J}(x) \tag{2.1}\]</span></p>
<p>Or, equivalently:</p>
<p><span class="math display">\[x^* = \arg \min_x \mathcal{J}(x) \tag{2.2}\]</span></p>
<p><span class="math inline">\((1)\)</span> says that it suffices to minimize the unconstrained objective <span class="math inline">\(\mathcal{J}\)</span> instead of the original problem since doing so yields <span class="math inline">\(f_0(x^*)\)</span>, the optimum of the unconstrained problem. <span class="math inline">\((2.1)\)</span> and <span class="math inline">\((2.2)\)</span>, on the other hand, say that it suffices to find an optimizer <span class="math inline">\(x^*\)</span> of the unconstrained problem, since such a point will also be an optimizer of the constrained problem.</p>
<p>To convince ourselves of this result, it helps to look at a simple example.</p>
<hr>
<p>Consider minimizing the quadratic form <span class="math inline">\(f_0(x) = ||x||_2^2\)</span> in <span class="math inline">\(\mathbb{R}^2\)</span> subject to the single circular inequality constraint <span class="math inline">\(x_1^2 + x_2^2 \leq 1\)</span>.Below are the 3D plots of the constrained and the unconstrained problem.</p>
<div id="5c4873d4" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Style Configurations</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.autolayout'</span>] <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'dark_background'</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>figsize <span class="op">=</span> (<span class="fl">9.80</span>, <span class="fl">4.90</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>background <span class="op">=</span> <span class="st">'#0a0a0a'</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Constrained objective function</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x,y):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Unconstrained augmentation of the objective </span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> j(x, y):</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    j <span class="op">=</span> f(x,y) <span class="co"># The copy array takes the values of the objective in the feasible region</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> <span class="op">~</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span> <span class="op">&lt;=</span> <span class="dv">1</span>) <span class="co"># Infeasible region</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    j[mask] <span class="op">=</span> <span class="dv">2</span> <span class="co"># Value on infeasible region. Use 2 instead of np.inf for visual purposes</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> j</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating the data</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> <span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>y_min, y_max <span class="op">=</span> <span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> np.meshgrid(np.linspace(x_min, x_max, <span class="dv">1000</span>), np.linspace(y_min, y_max, <span class="dv">1000</span>))</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>z1 <span class="op">=</span> np.ma.masked_where(<span class="op">~</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span> <span class="op">&lt;=</span> <span class="dv">1</span>), f(x,y))</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>z2 <span class="op">=</span> j(x,y)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating the plot</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize <span class="op">=</span> figsize, layout <span class="op">=</span> <span class="st">'tight'</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>fig.set_facecolor(background)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># First subplot</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, projection <span class="op">=</span> <span class="st">'3d'</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>ax.contour3D(x, y, z1, <span class="dv">50</span>, cmap <span class="op">=</span> cm.plasma)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>ax.set_zlim3d(<span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>ax.set_facecolor(background)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="vs">r'Constrained objective: $||x||_2^2 \ s.t. \ x_1^2 + x_2^2 \leq 1$'</span>, pad <span class="op">=</span> <span class="dv">5</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.arange(x_min, x_max, <span class="fl">1.0</span>))</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>ax.set_yticks(np.arange(y_min, y_max, <span class="fl">1.0</span>))</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">'z'</span>)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Second subplot</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, projection <span class="op">=</span> <span class="st">'3d'</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>ax.contour3D(x, y, z2, <span class="dv">100</span>, cmap <span class="op">=</span> cm.plasma)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>ax.set_zlim3d(<span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>ax.set_facecolor(background)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="vs">r'Unconstrained objective: $\mathcal</span><span class="sc">{J}</span><span class="vs">(x) = ||x||_2^2 + \mathbb</span><span class="sc">{1}</span><span class="vs">_-(x_1^2 + x_2^2 - 1)$'</span>, pad <span class="op">=</span> <span class="dv">5</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.arange(x_min, x_max, <span class="fl">1.0</span>))</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>ax.set_yticks(np.arange(y_min, y_max, <span class="fl">1.0</span>))</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">'z'</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Display result</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="duality-theory_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can clearly see in the plots that the optimum and the optimizer are the same for both problems: namely, <span class="math inline">\(f_0(x^*) = 0\)</span> and <span class="math inline">\(x^* = 0\)</span>.</p>
<hr>
<p>As we know, the local optima of unconstrained problems occur at their <em>stationary points</em> which can be easily identified using the <em>unconstrained optimality condition</em>.</p>
<blockquote class="blockquote">
<p><strong>Unconstrained Optimality Condition:</strong> &nbsp; If <span class="math inline">\(x^*\)</span> is an optimizer of the unconstrained objective <span class="math inline">\(f_0(x)\)</span> then <span class="math inline">\(\nabla f_0(x^*) = 0\)</span>. That is <span class="math inline">\(x^*\)</span> is a <strong><em>stationary point</em></strong> of <span class="math inline">\(f_0(x)\)</span>.</p>
</blockquote>
<p>Once such stationary points have been found, a global minimizer can be identified among them simply by evaluating the objective at each stationary point.</p>
<p>However, we’re immediately beset by a problem. We cannot find the gradient of <span class="math inline">\(\mathcal{J}\)</span> and set it to zero because the infinitely-hard penalty functions are discontinuous and non-differentiable. That is, <span class="math inline">\(\nabla \mathcal{J}(x)\)</span> simply does not exist.</p>
<p>To sidestep this difficulty we use linear relaxations instead of <span class="math inline">\(\mathbb{1}_-\)</span> and <span class="math inline">\(\mathbb{1}_0\)</span>.</p>
<section id="the-lagrangian-dual-variables-and-the-dual-function" class="level2">
<h2 class="anchored" data-anchor-id="the-lagrangian-dual-variables-and-the-dual-function">The Lagrangian, Dual Variables, and the Dual Function</h2>
<p>The <strong><em>Lagrangian linear relaxation</em></strong>, sometimes simply referred to as the <strong><em>Lagrangian</em></strong>, is:</p>
<p><span class="math display">\[\mathcal{L}(x,\lambda,\mu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{i=1}^p \mu_i h_i(x)\]</span> <span class="math display">\[\textrm{where} \ \lambda \geq 0\]</span></p>
<p>We call the <span class="math inline">\(\lambda_i\)</span>’s the <strong><em>Lagrange multipliers</em></strong> corresponding to the inequality constraints, and the <span class="math inline">\(\mu_i\)</span>’s those corresponding to the equality constraints. The vectors <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span>, composed of these Lagrange multipliers, are called the <strong><em>Lagrange multiplier vectors</em></strong> or, for reasons that will soon become apparent, the <strong><em>dual variables</em></strong>.</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>In some sources, the Lagrangian is simply stated as <span class="math inline">\(\mathcal{L}(x,\lambda) = f_0(x) + \sum_{i=1}^n \lambda_i f_i(x)\)</span>. Indeed, by separating the equality constraints <span class="math inline">\(h_i(x) = 0\)</span> into <span class="math inline">\(h_i(x) \leq 0\)</span> and <span class="math inline">\(-h_i(x) \leq 0\)</span>, we can transform a problem with equality constraints into one with only inequality constraints. So, this formulation of the Lagrangian is still general enough to account for problems with equality constraints.</p>
</div>
</div>
</div>
</section>
<section id="a-lagrangian-lower-bound" class="level2">
<h2 class="anchored" data-anchor-id="a-lagrangian-lower-bound">A Lagrangian Lower-Bound</h2>
<p>Not only does the Lagrangian (<span class="math inline">\(\mathcal{L}\)</span>) relax the unconstrained problem, it also plays a natural role in the formulation of the <strong><em>dual problem</em></strong>.</p>
<p>The first thing to note about the Lagrangian is that the coordinate-wise <span class="math inline">\(\lambda \geq 0\)</span> condition is crucial. This is because, in the event that an inequality constraint is violated, say <span class="math inline">\(f_i(x) &gt; 0\)</span>, the corresponding <span class="math inline">\(\lambda_i\)</span> must be non-negative in order to apply a positive penalty to the minimization. On the other hand, <span class="math inline">\(\mu\)</span> is free to assume any value since the equality constraints can be violated in either direction and both scenarios must be positively penalized.</p>
<p>The second thing to note about the Lagrangian is that, even though it applies a positive penalty that scales linearly in the severity of the violation, this penalty is, nevertheless, not as severe as the infinite penalty applied in <span class="math inline">\(\mathcal{J}\)</span>. Also, in the Lagrangian, we may actually be <em>rewarding</em> feasible choices of <span class="math inline">\(x\)</span> that have margin. That is, in the event that <span class="math inline">\(f_i(x) &lt; 0\)</span>, <span class="math inline">\(\lambda_if_i(x)\)</span> is a non-positive reward for the minimization problem.</p>
<p>All of this is to say that <span class="math inline">\(\mathcal{L}\)</span> is a point-wise lower-bound on <span class="math inline">\(\mathcal{J}\)</span>. That is, the following inequality holds:</p>
<p><span class="math display">\[\mathcal{L}(x,\lambda,\mu) \leq J(x) \ \ \forall x, \lambda \geq 0, \mu \tag{3.1}\]</span></p>
<p>This fact is also obvious by plotting each of the <span class="math inline">\(m + p\)</span> linear penalties, superimposing them against the plots of the corresponding infinitely hard penalty functions, and noticing that in each case <span class="math inline">\(\lambda_i f_i(x) \leq \mathbb{1}_-(f_i(x))\)</span> and <span class="math inline">\(\mu_i h_i(x) \leq \mathbb{1}_0(h_i(x))\)</span>.</p>
<p>Taking <span class="math inline">\(\min\)</span> w.r.t. <span class="math inline">\(x\)</span> of the LHS in <span class="math inline">\((3.1)\)</span> we get:</p>
<p><span class="math display">\[\min_x \mathcal{L}(x,\lambda,\mu) \leq J(x) \ \ \forall x, \lambda \geq 0, \mu\]</span></p>
<p>Furthermore, restricting <span class="math inline">\(x\)</span> to the primal feasible set <span class="math inline">\(\mathcal{X}\)</span> on which <span class="math inline">\(J(x) = f_0(x)\)</span>, we obtain something interesting:</p>
<p><span class="math display">\[\min_x \mathcal{L}(x,\lambda,\mu) \leq f_0(x) \ \ \forall x \in \mathcal{X}, \lambda \geq 0, \mu \tag{3.2}\]</span></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The Lagrangian may not attain its <span class="math inline">\(\min\)</span> w.r.t. <span class="math inline">\(x\)</span>, in which case the LHS is simply <span class="math inline">\(-\infty\)</span>. We shall see later, once we define the <strong><em>dual function</em></strong> and the <strong><em>duality gap</em></strong>, that this corresponds to the dual function being <span class="math inline">\(-\infty\)</span> <span class="math inline">\(\forall \lambda \geq0, \mu\)</span> and the duality gap being <span class="math inline">\(\infty\)</span>. In a sense, this is a useless lower bound. So, for now, we assume the interesting case in which the minimum <em>is</em> attained and thus <span class="math inline">\(\inf_x \mathcal{L}(x, \lambda, \mu) = \min_x \mathcal{L}(x, \lambda, \mu)\)</span>.</p>
</div>
</div>
</div>
<p>Designating the original problem as the <em>primal</em>, we call <span class="math inline">\(g(\lambda, \mu) := \min_x \mathcal{L}(x, \lambda, \mu)\)</span> the <strong><em>dual function</em></strong> because it exhibits the aforementioned property of weak duality. That is, per <span class="math inline">\((3.2)\)</span>, any feasible value of <span class="math inline">\(g(\lambda, \mu)\)</span> is a lower-bound for any feasible value of the primal.</p>
<p>Taking min of the other side, we have a more specific flavor of weak duality:</p>
<p><span class="math display">\[g(\lambda,\mu) \leq \min_x f_0(x) \ \ \forall \lambda \geq 0, \mu\]</span></p>
<p>Or simply:</p>
<p><span class="math display">\[g(\lambda,\mu) \leq f_0(x^*) \ \ \forall \lambda \geq 0, \mu \tag{3.3}\]</span></p>
<p>That is, any feasible value of the dual is a lower-bound for the primal optimum.</p>
<p>Maximizing both sides of <span class="math inline">\((3.3)\)</span> by noticing that the RHS is a constant, and by assuming the LHS attains its <span class="math inline">\(\max\)</span> we get an even more specific flavor of weak duality:</p>
<p><span class="math display">\[\max_{\lambda \geq 0, \mu} g(\lambda,\mu) \leq f_0(x^*)\]</span></p>
<p>Or simply, assuming <span class="math inline">\(\lambda^*\)</span> and <span class="math inline">\(\mu^*\)</span> to be dual-optimal:</p>
<p><span class="math display">\[g(\lambda^*, \mu^*) \leq f_0(x^*) \tag{3.4}\]</span></p>
<p>That is, the dual optimum is a lower-bound for the primal optimum.</p>
<p>From here we move, quite naturally, to defining the <em>dual problem</em>.</p>
</section>
<section id="the-lagrange-dual-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-lagrange-dual-problem">The Lagrange Dual Problem</h2>
<p>It’s natural, to ask what the <em>tightest</em> lower bound on the primal optimal value <span class="math inline">\(f_0(x^*)\)</span> is. This amounts to finding the values <span class="math inline">\(\lambda^* \geq 0\)</span>, and <span class="math inline">\(\mu^*\)</span> for which <span class="math inline">\(g(\lambda^*, \mu^*)\)</span> is maximized. We call this the <strong><em>Lagrange dual problem</em></strong> or, simply, the <strong><em>dual problem</em></strong>.</p>
<p>It can be stated as:</p>
<p><span class="math display">\[
\begin{aligned}
\max_{\lambda, \mu} &amp;: g(\lambda, \mu)
\\
s.t. &amp;: \lambda \geq  0
\end{aligned}
\]</span></p>
<p>Looking at the above, it becomes immediately clear why we were motivated to call <span class="math inline">\(\lambda\)</span>, and <span class="math inline">\(\mu\)</span> the <em>dual variables</em>: they are the variables of the dual problem.</p>
</section>
</section>
<section id="weak-duality-and-interpretations" class="level1">
<h1>Weak Duality and Interpretations</h1>
<p>We now return to the general setting of constrained optimization.</p>
<p>We’ve already seen weak duality formulated as <span class="math inline">\((3.2)\)</span>, <span class="math inline">\((3.3)\)</span>, and <span class="math inline">\((3.4)\)</span>. But, there’s yet another, more symmetric, formulation of weak duality.</p>
<p>Suppose <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*, \mu^*)\)</span> are primal-dual optimal. Since <span class="math inline">\(g(\lambda^*, \mu^*)\)</span> is the solution to the dual, and <span class="math inline">\(g(\lambda, \mu) = \min_x \mathcal{L}(x, \lambda, \mu)\)</span> we have:</p>
<p><span class="math display">\[g(\lambda^*, \mu^*) = \max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L}(x, \lambda, \mu) \right\} \tag{4.1}\]</span></p>
<p>Similarly, it can be shown that:</p>
<p><span class="math display">\[f_0(x^*) = \min_x \left\{ \max_{\lambda \geq 0, mu} \mathcal{L}(x, \lambda, \mu) \right\} \tag{4.2}\]</span></p>
<p>To see this, note that for some <span class="math inline">\(x\)</span> fixed by the outer minimizer, maximizing the Lagrangian over <span class="math inline">\(\lambda \geq 0\)</span> and <span class="math inline">\(\mu\)</span> recovers <span class="math inline">\(\mathcal{J}(x)\)</span>.</p>
<p>If all of the inequality constraints are respected, that is <span class="math inline">\(f_i(x) \leq 0\)</span> <span class="math inline">\(\forall i\)</span>, then, in order to maximize the Lagrangian, the best we can do is set <span class="math inline">\(\lambda_i = 0\)</span> <span class="math inline">\(\forall i\)</span>. In case <em>any</em> inequality constraint is violated, that is <span class="math inline">\(f_i(x) &gt; 0\)</span> for some <span class="math inline">\(i\)</span>, the result of maximizing the Lagrangian can be made <span class="math inline">\(\infty\)</span> by choosing <span class="math inline">\(\lambda_i \rightarrow \infty\)</span> and <span class="math inline">\(\lambda_j = 0\)</span> <span class="math inline">\(\forall j \ne i\)</span>.</p>
<p>Using similar logic, if all equality constraints are respected then <span class="math inline">\(h_i(x) = 0\)</span> <span class="math inline">\(\forall i\)</span>. In this case <span class="math inline">\(\mu_i\)</span> can be chosen to be any value. If, on the other hand, some equality constraint is violated then <span class="math inline">\(h_i(x) \ne 0\)</span> for some <span class="math inline">\(i\)</span>. By choosing <span class="math inline">\(\mu_i \rightarrow \pm \infty\)</span>, where the sign depends on the direction of the violation, the result can be made <span class="math inline">\(\infty\)</span>.</p>
<p>Thus we have shown that:</p>
<p><span class="math display">\[
\begin{aligned}\max_{\lambda \geq 0, \mu} \mathcal{L}(x,\lambda,\mu) &amp;= \begin{cases}\begin{aligned}
&amp;f_0(x) \ \ \textrm{if $x$ is feasible}
\\
&amp;\infty \ \ \textrm{otherwise}
\end{aligned}\end{cases} \\ &amp;= \mathcal{J}(x)\end{aligned}
\]</span></p>
<p>Now, since <span class="math inline">\(x^*\)</span> is primal optimal, we have <span class="math inline">\(\min_x \mathcal{J}(x) = \mathcal{J}(x^*)\)</span>. Furthermore, since <span class="math inline">\(x^*\)</span> is primal-feasible, we have <span class="math inline">\(J(x^*) = f_0(x^*)\)</span> which yields <span class="math inline">\((4.2)\)</span> as promised.</p>
<p>Thus, weak duality can be stated in the following symmetric form:</p>
<p><span class="math display">\[
\max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L}(x, \lambda, \mu) \right\} \leq \min_x \left\{ \max_{\lambda \geq 0, mu} \mathcal{L}(x, \lambda, \mu) \right\} \tag{3.5}
\]</span></p>
<section id="the-max-min-inequality" class="level2">
<h2 class="anchored" data-anchor-id="the-max-min-inequality">The Max-Min Inequality</h2>
<p>The inequality expressed as <span class="math inline">\((3.5)\)</span> is, in fact, a general result in mathematics called the <a href="https://en.wikipedia.org/wiki/Max%E2%80%93min_inequality"><em>Max-Min Inequality</em></a>. To summarize: the Max-Min Inequality makes no assumptions about the function, it’s true for all functions of the form <span class="math inline">\(f: X \times Y \rightarrow \mathbb{R}\)</span> and asserts that:</p>
<p><span class="math display">\[\sup_{x\in X} \left\{ \inf_{y\in Y} f(x,y) \right\} \leq \inf_{y\in Y} \left\{ \sup_{x\in X} f(x,y) \right\}\]</span></p>
<p>Since no assumption is made on <span class="math inline">\(f\)</span>, the inequality also holds for the Lagrangian, <span class="math inline">\(\mathcal{L}\)</span>. And, since we’re in the special case where the optimal values of the primal and the dual are assumed to exist, the functions do attain the respective optima. That is, we can replace <span class="math inline">\(\sup\)</span> and <span class="math inline">\(\inf\)</span> in the above inequality with <span class="math inline">\(\max\)</span> and <span class="math inline">\(\min\)</span> which obtains the symmetric formulation of weak duality as in <span class="math inline">\((3.5)\)</span>.</p>
<p>We can now prove weak duality through a non-optimization lens by proving the Max-Min Inequality.</p>
<p>For any <span class="math inline">\(f\)</span>, and <span class="math inline">\(x \in X\)</span>, <span class="math inline">\(y \in Y\)</span> we have:</p>
<p><span class="math display">\[f(x,y) \leq \sup_y f(x,y) \ \ \forall x\]</span></p>
<p>The right-hand side is now only a function of <span class="math inline">\(x\)</span>, so minimizing both sides w.r.t. <span class="math inline">\(x\)</span> yields:</p>
<p><span class="math display">\[ \inf_x f(x,y) \leq \inf_x \left\{ \sup_y f(x,y) \right\} \ \ \forall y\]</span></p>
<p>The right-hand side is now a constant, so maximizing both sides w.r.t. <span class="math inline">\(y\)</span> results in the desired conclusion.</p>
<p><span class="math display">\[\sup_y \left\{ \inf_x f(x,y) \right\} \leq \inf_x \left\{ \sup_y f(x,y) \right\}\]</span></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The Max-Min Inequality proof should remind us of the steps taken to obtain <span class="math inline">\((3.2)\)</span> through <span class="math inline">\((3.4)\)</span> from <span class="math inline">\((3.1)\)</span>. In fact, <span class="math inline">\((3.1)\)</span> is of form <span class="math inline">\(f(x,y) \leq \sup_y f(x,y) \ \ \forall x\)</span>, since <span class="math inline">\(J(x)\)</span> is, as shown earlier, equivalent to <span class="math inline">\(\max_{\lambda \geq 0, \mu} L(x, \lambda, \mu)\)</span>.</p>
</div>
</div>
</div>
<section id="game-theoretic-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="game-theoretic-interpretation">Game-Theoretic Interpretation</h3>
<p>The Max-Min Inequality is perhaps best understood intuitively as a game between two adversarial players (the optimizers above).</p>
<p>Let’s represent the game using a value tree. The nodes are the final scores, and the junctures represent player choices. The first juncture represents Player 1’s turn, and the second that of Player 2.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">   graph TD;
      A[Turn 1] --&gt; B[Turn 2];
      A--&gt;C[Turn 2];
      B--&gt;D[2];
      B--&gt;E[7];
      C--&gt;F[1];
      C--&gt;G[8];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>To the minimizer, as Player 1, the game tree above might as well be an imaginary tree shrouded in the mist of uncertainty because the true min of <span class="math inline">\(1\)</span> is unattainable. Player 2 has final say, and if the minimizer chooses <span class="math inline">\(1\)</span>’s subtree, the maximizer will choose <span class="math inline">\(8\)</span>. The minimizer must be more pragmatic and choose <em>not</em> the subtree that contains the true min, but rather that which restricts the maximizer’s choice most to the compromise: <span class="math inline">\(7\)</span>. That means, we can compute a hidden value tree for our minimizer (giving us a glimpse into one frame of the recursive <a href="https://en.wikipedia.org/wiki/Minimax">Minimax algorithm</a> which is used to maximize the minimum gain or minimize the maximum loss).</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">   graph TD;
      A[Turn 1] --&gt; B[7];
      A--&gt;C[8];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The outcome of this game is determinedly <span class="math inline">\(7\)</span>. That’s a score Player 2, the maximizer, is <em>very</em> satisfied with. Note that if we reverse the turns, the score of the game will favor the minimizer. That’s exactly what the max-min inequality is saying: a game that’s rigged in favor of Player 2 will always result in a better outcome for Player 2 than if the turns were reversed.</p>
</section>
</section>
</section>
<section id="strong-duality-and-interpretations" class="level1">
<h1>Strong Duality and Interpretations</h1>
<p>Strong duality is the special case when weak duality, as it’s stated in <span class="math inline">\((3.4)\)</span>, holds with strict equality. That is:</p>
<p><br> <span class="math display">\[g(\lambda^*, \mu^*) = f_0(x^*) \tag{5.1}\]</span> <br></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The existence of a primal optimal <span class="math inline">\(x^*\)</span> is needed in order to speak of strong duality at all. To show this, suppose the primal is feasible but unbounded. Then <span class="math inline">\(\not \exists x^*\)</span> that is primal optimal. Suppose further that the dual is feasible. Then <span class="math inline">\(\exists (\lambda, \mu)\)</span> such that weak duality obtains <span class="math inline">\(g(\lambda, \mu) \leq f(x) \ \ \forall x\)</span>. That is <span class="math inline">\(g(\lambda, \mu)\)</span> is a lower-bound of the primal objective. This contradicts the assumption of primal unboundedness. To avoid this contradiction, it must be the case that primal unboundedness implies dual infeasibility. However, if the dual is infeasible there can be no talk of strong duality since the dual optimal does not exist.</p>
</div>
</div>
</div>
<p>Alternatively, in its Max-Min characterization:</p>
<p><span class="math display">\[\max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\} = \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L} (x, \lambda, \mu) \right\} \tag{5.2}\]</span></p>
<p>Another common way to say a problem is strongly dual is to say its <strong><em>duality gap</em></strong> is zero. The duality gap is defined as the difference between the primal and dual optima, that is <span class="math inline">\(f_0(x^*) - g(\lambda^*, \mu^*)\)</span>. This characterization of strong duality follows immediately from the first definition of strong duality as it’s stated in <span class="math inline">\((5.1)\)</span>. Optimization problems that exhibit this property are called <strong><em>strongly dual</em></strong>.</p>
<p>As mentioned briefly in the introduction, strong duality gives applied scientists the ability to solve an equivalent, usually easier, dual problem instead of the primal one which may be difficult to solve. As it happens, strong duality also obtains powerful <strong><em>optimality conditions</em></strong> which allow scientists to check if suspected optimal points are, indeed, optimal. We will soon make both of these claims more rigorous but, for now, it’s enough to think of them simply as benefits of strong duality. Given these useful results it would certainly be helpful to know, in advance of solving the problem, whether or not it’s strongly dual</p>
<p>We shall see, through a direct proof, that all linear programs are strongly dual. When it comes to non-linear optimization, however, strong duality is not a general guarantee. The good news is that sufficient conditions for strong duality do exist and will be provided next.</p>
<section id="slaters-condition---sufficient-condition-for-strong-duality" class="level2">
<h2 class="anchored" data-anchor-id="slaters-condition---sufficient-condition-for-strong-duality">Slater’s Condition - Sufficient Condition for Strong Duality</h2>
<p>While the rare non-convex problem could exhibit the property, strong duality is mostly enjoyed by convex problems. However, not all convex problems are strongly dual. There are many results that establish conditions on the problem, beyond convexity and existence of a primal-optimal, under which strong duality holds. These conditions are called <strong><em>constraint qualifications</em></strong>. In this section we will explore such conditions for convex problems and discuss them in the specific case of linear programs.</p>
<p>One of these constraint qualification conditions is <strong><em>Slater’s condition</em></strong>.</p>
<blockquote class="blockquote">
<p><strong>Slater’s Condition:</strong> &nbsp; <span class="math inline">\(\exists \ \hat x\)</span> s.t. <span class="math inline">\(f_i(\hat x) &lt; 0\)</span>, and <span class="math inline">\(h_i(\hat x) = 0\)</span> <span class="math inline">\(\forall i\)</span>.</p>
</blockquote>
<p>Informally, Slater’s condition says that the existence of a feasible point which has margin w.r.t. all the inequality constraints is needed in addition to convexity. In even simpler terms, the feasible region must have an interior point.</p>
<p>The sufficient condition for strong duality in convex problems is then:</p>
<blockquote class="blockquote">
<p><strong>Sufficient Condition for Strong Duality:</strong> &nbsp; Any convex optimization problem satisfying Slater’s condition has zero duality gap.</p>
</blockquote>
<p>The proof of this is beyond what we’re trying to accomplish in this post.</p>
<p>A weaker constraint qualification condition guarantees strong duality in the case of linear constraints. If <span class="math inline">\(k\)</span> of the <span class="math inline">\(m\)</span> inequality constraints are linear then the condition becomes:</p>
<p><span class="math display">\[
\begin{aligned}f_i(\hat x) &amp;\leq 0, \ i = 1,...,k, \\
f_i(\hat x) &amp;&lt; 0, \ i = k+1,...,m, \\
h_i(\hat x) &amp;= 0, \ i = 1,...,p
\end{aligned}
\]</span></p>
<p>In other words, the linear constraints need not have margin.</p>
<p>Note that if all the constraints are linear, which is the case in linear programming, the above constraint qualification condition simply reduces to feasibility.</p>
<p>So, while a sufficient condition of strong duality in non-linear convex programs is, both, the existence of a feasible interior point and a primal optimal, the situation is remarkably simpler in linear programs. Since a primal optimal for a linear program is also feasible, it satisfies the weaker constraint qualification condition. Thus, for a linear program to be strongly dual the existence of a primal optimal is sufficient.</p>
</section>
<section id="the-max-min-equality" class="level2">
<h2 class="anchored" data-anchor-id="the-max-min-equality">The Max-Min Equality</h2>
<p>Just as weak duality is the Max-Min Inequality in disguise, strong duality is the <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a> in disguise. The Minimax Theorem is about the special case of the Max-Min Inequality in which the LHS and the RHS are strictly equal. It holds for any function <span class="math inline">\(f: X \times Y \rightarrow \mathbb{R}\)</span> that has some additional structure. Roughly speaking, when <span class="math inline">\(f\)</span> is saddle-shaped, convex in one variable and concave in the other, the Max-Min Inequality holds with strict equality.</p>
<p>The following theorem, which is offered without proof, translates this result into the setting of optimization.</p>
<blockquote class="blockquote">
<p><strong>Saddle Point Theorem:</strong> &nbsp; If <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*, \mu^*)\)</span> are primal and dual optimal solutions for a convex problem which satisfies Slater’s condition, they form a saddle point of the associated Lagrangian. Furthermore, if <span class="math inline">\((x^*, (\lambda^*, \mu^*))\)</span> is a saddle point of a Lagrangian, then <span class="math inline">\(x^*\)</span> is primal optimal and <span class="math inline">\((\lambda^*, \mu^*)\)</span> is dual optimal for the associated problem, and the <strong><em>duality gap</em></strong> is zero.</p>
</blockquote>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>This theorem should <em>not</em> be taken as a <strong><em>certificate of strong duality</em></strong>. If the Lagrangian is saddle-shaped then the associated problem is strongly dual, however the converse is not true. Since not all strongly dual problems are convex problems which satisfy Slater’s condition, if a problem is strongly dual it is <em>not</em> guaranteed that its Lagrangian is saddle-shaped.</p>
</div>
</div>
</div>
<section id="game-theoretic-interpretation-1" class="level3">
<h3 class="anchored" data-anchor-id="game-theoretic-interpretation-1">Game-Theoretic Interpretation</h3>
<p>In keeping with the game theoretic intuition developed in the section on weak duality, one can imagine a game in which the first player’s optimal choice is independent of the second player’s actions. In such a game, both players are free to play their best strategies and, consequently, the order of play is not important.</p>
</section>
</section>
<section id="an-easier-dual-problem" class="level2">
<h2 class="anchored" data-anchor-id="an-easier-dual-problem">An Easier Dual Problem</h2>
<p>Let’s further qualify what we mean when we say strong duality gives an equivalent, usually easier, problem to solve.</p>
<p>At the start of this post we considered a general convex program. However, everything we’ve discussed about Lagrangian duality applies to non-convex problems as well. Suppose the primal problem is non-convex. The task is that of finding the primal optimum:</p>
<p><span class="math display">\[f_0(x^*) = \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L} (x, \lambda, \mu) \right\}\]</span></p>
<p>But maximizing the Lagrangian over <span class="math inline">\(\lambda \geq 0\)</span> and <span class="math inline">\(\mu\)</span> for a fixed <span class="math inline">\(x\)</span>, recovers <span class="math inline">\(\mathcal{J}(x)\)</span>: a non-differentiable objective. So, we cannot use the unconstrained optimality condition in finding the stationary points of <span class="math inline">\(\mathcal{J}(x)\)</span> which is what’s required in the next step.</p>
<p>Meanwhile, the dual problem is that of finding the dual optimum:</p>
<p><span class="math display">\[g(\lambda^*, \mu^*) = \max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\}\]</span></p>
<p>Minimizing the Lagrangian over <span class="math inline">\(x\)</span> for fixed <span class="math inline">\(\lambda \geq 0\)</span> and <span class="math inline">\(\mu\)</span> may still be a difficult problem but, at least, it lends itself to using the method of unconstrained optimization. Moreover, the resulting dual function <span class="math inline">\(g(\lambda, \mu) = \min_x \mathcal{L}(x, \lambda, \mu)\)</span> is a point-wise minimum of linear functions in <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span>, so its always concave in those variables. Additionally, the constraint <span class="math inline">\(\lambda \geq 0\)</span> is a simple, convex (linear in fact), constraint. So, the dual problem is a convex optimization problem regardless of the convexity of the primal.</p>
<p>Solving a convex dual problem is usually easier that solving a non-convex primal problem. However, even if the primal is a convex problem to begin with, the dual may still be easier to solve. The primal could have more variables than constraints in which case its dual has more constraints than variables. This is yet another way in which the dual can be an easier problem to solve than the primal.</p>
</section>
</section>
<section id="theorems-of-the-alternative" class="level1">
<h1>Theorems of the Alternative</h1>
<p>Duality isn’t just a tool for applied science, it has important theoretical uses. For instance, in proving <strong><em>Theorems of the Alternative</em></strong>. These are theorems that describe exclusively disjoint scenarios that together comprise the entire outcome space. Formally, they are theorems of the form <span class="math inline">\(A \implies \neg B \land \neg A \implies  B\)</span> where <span class="math inline">\(A\)</span>, and <span class="math inline">\(B\)</span> are logical statements.</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Theorems of equivalence (i.e.&nbsp;theorems of the form <em>‘the following are equivalent - TFAE’</em>) can also be formulated as theorems of the alternative. To say that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are equivalent means $ A B$. But this breaks down as <span class="math inline">\(A \implies B \land B \implies A\)</span>. Letting <span class="math inline">\(\hat B = \neg B\)</span> we can rewrite the above as <span class="math inline">\(A \implies \neg \hat B \land B \implies A\)</span>. But, by taking the contrapositive, <span class="math inline">\(B \implies A\)</span> becomes <span class="math inline">\(\neg A \implies \neg B\)</span>, which is to say <span class="math inline">\(\neg A \implies \hat B\)</span>. In summary, we have shown that <span class="math inline">\(A \iff B\)</span> is equivalent to <span class="math inline">\(A \implies \neg \hat B \land \neg A \implies \hat B\)</span>. So, the class of theorems of the alternative is much broader than it appears and includes theorems of equivalence.</p>
</div>
</div>
</div>
<p>These theorems are usually proven by a <strong><em>Separation Argument</em></strong>, but can also be proven, quite elegantly, through duality.</p>
<p>A well-known instance of a Theorem of the Alternative is <a href="https://en.wikipedia.org/wiki/Farkas%27_lemma">Farkas’ Lemma</a> which underpins major results in the study of optimization.</p>
<section id="farkas-lemma" class="level2">
<h2 class="anchored" data-anchor-id="farkas-lemma">Farkas’ Lemma</h2>
<p>Farkas’ Lemma simply states that a given vector <span class="math inline">\(c\)</span> is either a <a href="../../posts/linear_algebra/linear_algebra_refresher_for_optimization.html#conic-combinations-of-n-points">conic combination</a> of some vectors <span class="math inline">\(a_i\)</span>’s (for <span class="math inline">\(i \in I\)</span>), or it’s entirely separated from their cone by some hyperplane.</p>
<p>We state Farkas’ Lemma without offering proof since it has such an obvious geometric interpretation.</p>
<blockquote class="blockquote">
<p><strong>Farkas’ Lemma:</strong> &nbsp; For any vector <span class="math inline">\(c\)</span> and <span class="math inline">\(a_i \ \ (i \in I)\)</span> either the first or the second statement holds:</p>
<ul>
<li><span class="math inline">\(\exists p \geq 0\)</span> s.t. <span class="math inline">\(c = \sum_{i \in I} a_ip_i\)</span></li>
<li><span class="math inline">\(\exists\)</span> vector <span class="math inline">\(d\)</span> s.t. <span class="math inline">\(d^Ta_i \geq 0 \ \ \forall i \in I\)</span> but <span class="math inline">\(d^Tc &lt; 0\)</span></li>
</ul>
</blockquote>
</section>
<section id="proving-a-theorem-of-the-alternative" class="level2">
<h2 class="anchored" data-anchor-id="proving-a-theorem-of-the-alternative">Proving a Theorem of the Alternative</h2>
<p>To see how we can prove a Theorem of the Alternative, it helps to state one.</p>
<blockquote class="blockquote">
<p><strong>Theorem:</strong> &nbsp; Exactly one of the following two statements most hold for a given matrix A.</p>
<ol type="1">
<li><span class="math inline">\(\exists x \ne 0\)</span> s.t. <span class="math inline">\(Ax = 0\)</span> and <span class="math inline">\(x \geq 0\)</span></li>
<li><span class="math inline">\(\exists p\)</span> s.t. <span class="math inline">\(p^TA &gt; 0\)</span></li>
</ol>
</blockquote>
<section id="proof-using-a-separation-argument" class="level3">
<h3 class="anchored" data-anchor-id="proof-using-a-separation-argument">Proof using a Separation Argument</h3>
<section id="prelude" class="level4">
<h4 class="anchored" data-anchor-id="prelude">Prelude</h4>
<p>At the heart of separation arguments lies this simple fact.</p>
<blockquote class="blockquote">
<p><strong>Separating Hyperplane Theorem:</strong> &nbsp; For any <em>convex</em> set <span class="math inline">\(C\)</span>, if a point <span class="math inline">\(\omega \notin C\)</span> then there exists a hyperplane separating <span class="math inline">\(\omega\)</span> and <span class="math inline">\(C\)</span>.</p>
</blockquote>
<p>Farkas’ Lemma, for instance, is proved by a separation argument that uses, as its convex set, the conic combination of the <span class="math inline">\(a_i\)</span>’s. The conclusion is immediate since in Farkas’ Lemma the first statement plainly says that a vector belongs to the convex set, and the second statement plainly says there exists a separating hyperplane between the two.</p>
<p>This is the pattern all separation arguments must follow. However, in general, it may take a bit of work to define the problem-specific convex set and also to show that the two statements are <em>really</em> talking about belonging to this set, and separation from it. However, once these components are in place, the proof is complete.</p>
<p>Using this idea, let’s give a proof of the above theorem using a separation argument.</p>
</section>
<section id="proof" class="level4">
<h4 class="anchored" data-anchor-id="proof">Proof</h4>
<p>First order of business is to come up with a convex set.</p>
<p>Let’s take <span class="math inline">\(C = \{ z : z = Ay, \sum_i y_i = 1, y \geq 0 \}\)</span> to be the convex hull of the columns of <span class="math inline">\(A\)</span>.</p>
<p>The first statement in the theorem was that <span class="math inline">\(\exists x \ne 0\)</span> s.t. <span class="math inline">\(Ax = 0\)</span> and <span class="math inline">\(x \geq 0\)</span>.</p>
<p>Since <span class="math inline">\(x \ne 0\)</span> and <span class="math inline">\(x \geq 0\)</span> we can scale as <span class="math inline">\(x\)</span> as <span class="math inline">\(y = \alpha x\)</span> until <span class="math inline">\(\sum_i y_i = 1\)</span>.</p>
<p>So, the first statement is equivalent to saying the origin belongs to the convex hull <span class="math inline">\(C\)</span> (i.e.&nbsp;<span class="math inline">\(0 \in C\)</span>)</p>
<p>The second statement was that <span class="math inline">\(\exists p\)</span> s.t. <span class="math inline">\(p^TA &gt; 0\)</span>. This is equivalent to saying that all the columns of <span class="math inline">\(A\)</span> lie to one side of the separating hyperplane introduced by <span class="math inline">\(p\)</span>.</p>
<p>But all <span class="math inline">\(z \in C\)</span> are convex combinations of <span class="math inline">\(A\)</span>’s columns. In particular since they’re a convex combination they’re also a conic combination, so all <span class="math inline">\(z \in C\)</span> also lie on the same side of the hyperplane. That is <span class="math inline">\(p^Tz &gt; 0 \ \ \forall z \in C\)</span>.</p>
<p>But, of course, <span class="math inline">\(p^T0 = 0\)</span> (not <span class="math inline">\(&gt; 0\)</span>). So, according to the second statement, the origin is separated from <span class="math inline">\(C\)</span>.</p>
<p>This concludes the proof since the two statements must be mutually exclusive.</p>
</section>
</section>
<section id="proof-using-strong-duality" class="level3">
<h3 class="anchored" data-anchor-id="proof-using-strong-duality">Proof using Strong Duality</h3>
<p>To prove the theorem we need to show two things. First, we need to show <span class="math inline">\(1 \implies \neg 2\)</span>, then we need to show <span class="math inline">\(\neg 1 \implies 2\)</span>.</p>
<p>The <span class="math inline">\(1 \implies \neg 2\)</span> direction is simple.</p>
<p>Suppose <span class="math inline">\(\exists x \ne 0\)</span> s.t. <span class="math inline">\(Ax = 0\)</span> and <span class="math inline">\(x \geq 0\)</span>.</p>
<p>Then <span class="math inline">\(\forall p \ \ (p^TA)x = p^T(Ax) = p^T0 = 0\)</span> (not <span class="math inline">\(&gt; 0\)</span>).</p>
<p>We tackle the <span class="math inline">\(\neg 1 \implies 2\)</span> direction using duality.</p>
<p>The strategy is to construct an LP based on <span class="math inline">\(\neg 1\)</span> such that the feasibility of its dual implies <span class="math inline">\(2\)</span>.</p>
<p>We can express <span class="math inline">\(\neg 1\)</span> as ‘<span class="math inline">\(\forall x \ne 0\)</span>, either <span class="math inline">\(Ax \ne 0\)</span> or <span class="math inline">\(x &lt; 0\)</span>.’ Equivalently, ‘<span class="math inline">\(x \ne 0 \implies Ax \ne 0\)</span> or <span class="math inline">\(x &lt; 0\)</span>.’ Taking the contrapositive, statement <span class="math inline">\(1\)</span> becomes ‘<span class="math inline">\(Ax = 0\)</span> and <span class="math inline">\(x \geq 0 \implies x = 0\)</span>.’</p>
<p>So, we form the LP as:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\max_x: \textbf{1}^Tx
\\
&amp;s.t.: \begin{aligned} &amp;Ax = 0
\\
&amp;x \geq 0
\end{aligned}
\end{aligned}
\]</span></p>
<p>Note that <span class="math inline">\(x = 0\)</span> is a feasible solution to the LP. Furthermore, assuming statement <span class="math inline">\(1\)</span> guarantees that <span class="math inline">\(x = 0\)</span> is the only feasible solution. Thus, the LP is feasible and bounded.</p>
<p>By strong duality, its dual exists and is also feasible and bounded.</p>
<p>The dual is:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\min_p: \textbf{0}^Tp
\\
&amp;s.t.: p^TA \geq \textbf{1}
\end{aligned}
\]</span></p>
<p>Since the dual is feasible, <span class="math inline">\(\exists p\)</span> s.t. <span class="math inline">\(p^TA \geq 1 &gt; 0\)</span> which demonstrates the truth of statement <span class="math inline">\(2\)</span> and, in doing so, completes the proof.</p>
</section>
</section>
</section>
<section id="strong-duality---optimality-conditions" class="level1">
<h1>Strong Duality - Optimality Conditions</h1>
<p>As mentioned before, strong duality also obtains powerful optimality conditions. These conditions are known as <strong><em>stationarity condition</em></strong> and <strong><em>complementary slackness</em></strong>, and they are often bundled into the <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions"><em>Karush–Kuhn–Tucker (KKT) Conditions</em></a> which will be provided shortly.</p>
<section id="stationarity-condition" class="level2">
<h2 class="anchored" data-anchor-id="stationarity-condition">Stationarity Condition</h2>
<p>In the section titled <a href="../../posts/optimization/duality-theory.html#an-easier-dual-problem">an easier dual problem</a> we mentioned that the dual problem is that of finding the dual optimal value:</p>
<p><span class="math display">\[g(\lambda^*, \mu^*) = \max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\}\]</span></p>
<p>If strong duality holds, this dual optimum agrees with the primal optimum. That is:</p>
<p><span class="math display">\[g(\lambda^*, \mu^*) = f_0(x^*)\]</span></p>
<p>Turns out in case of strong duality there’s even more to be said. As we saw earlier optimizing the unconstrained objective <span class="math inline">\(\mathcal{J}(x)\)</span> not only resulted in the primal optimum <span class="math inline">\(f_0(x^*)\)</span> for some optimal <span class="math inline">\(x^*\)</span> of the constrained problem, the very same point <span class="math inline">\(x^*\)</span> itself turned out to be an optimizer of <span class="math inline">\(\mathcal{J}(x)\)</span>. Similarly, we can show that the primal optimum <span class="math inline">\(x^*\)</span> for some primal-dual optimal pair <span class="math inline">\((x^*, (\lambda^*, \mu^*))\)</span> optimizes <span class="math inline">\(\mathcal{L}(x, \lambda^*, \mu^*)\)</span>. In other words, the primal optimum <span class="math inline">\(x^*\)</span> is a stationary point of the Lagrangian at the dual optimum <span class="math inline">\((\lambda^*,\mu^*)\)</span>.</p>
<p>That is:</p>
<p><span class="math display">\[x^* = \arg \min_x \mathcal{L} (x, \lambda^*, \mu^*) \tag{6.1}\]</span></p>
<p>Or, equivalently:</p>
<p><span class="math display">\[\min_x \mathcal{L}(x, \lambda^*, \mu^*) = \mathcal{L}(x^*, \lambda^*, \mu^*) \tag{6.2}\]</span></p>
<p>We can think of <span class="math inline">\((6.1)\)</span> and <span class="math inline">\((6.2)\)</span> as the analogs of <span class="math inline">\((2.1)\)</span> and <span class="math inline">\((2.2)\)</span> for the Lagrangian (<span class="math inline">\(\mathcal{L}\)</span>). This is exactly what we’ve been working towards. Recall that the original motivation in augmenting the constrained problem into the unconstrained <span class="math inline">\(\mathcal{J}\)</span> was to find the former’s optimizer using methods of unconstrained optimization on <span class="math inline">\(\mathcal{J}\)</span>. Once found, <span class="math inline">\((2.1)\)</span> or <span class="math inline">\((2.2)\)</span> would guarantee that an optimizer of <span class="math inline">\(\mathcal{J}\)</span> was, itself, an optimizer of the original problem. Failing that, we relaxed <span class="math inline">\(\mathcal{J}\)</span> into <span class="math inline">\(\mathcal{L}\)</span> hoping we could still accomplish the same. <span class="math inline">\((6.1)\)</span> and <span class="math inline">\((6.2)\)</span> are the results which guarantee precisely that. They say that the optimizer <span class="math inline">\(x^*\)</span> of the original problem can be found by optimizing the unconstrained objective <span class="math inline">\(\mathcal{L}\)</span>. And, since <span class="math inline">\(\mathcal{L}\)</span> is everywhere differentiable w.r.t. <span class="math inline">\(x\)</span>, we can now proceed.</p>
<p>In practice, however, <span class="math inline">\((6.1)\)</span> and <span class="math inline">\((6.2)\)</span> only give us a way to solve for a primal-optimal <span class="math inline">\(x^*\)</span> directly if a dual-optimal <span class="math inline">\((\lambda^*, \mu^*)\)</span> is already known. That is, any time the dual problem is easier to solve than the primal.</p>
<p>More generally, this fact gives us the next best thing. It gives us a way to check if a given pair <span class="math inline">\((x^*,(\lambda^*,\mu^*))\)</span> is primal-dual optimal – an optimality condition known as <em>stationarity condition</em>.</p>
<blockquote class="blockquote">
<p><strong>Stationarity Condition:</strong> &nbsp; Suppose <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*, \mu^*)\)</span> are primal-dual optimal for a strongly dual problem. Then: <span class="math display">\[\nabla_x f_0(x^*) + \sum_i^m \lambda^*_i\nabla_xf_i(x^*) + \sum_{i=1}^p \mu^*_i\nabla_xh_i(x^*) = 0\]</span></p>
</blockquote>
<p>The stationary condition is obtained simply by an application of the unconstrained optimality condition to <span class="math inline">\(\mathcal{L}(x, \lambda^*, \mu^*)\)</span>:</p>
<p><span class="math display">\[\nabla_x \mathcal{L} (x^*, \lambda^*, \mu^*) = 0\]</span></p>
<p>Expanding the LHS gives:</p>
<p><span class="math display">\[\nabla_x f_0(x^*) + \sum_i^m \lambda^*_i\nabla_xf_i(x^*) + \sum_{i=1}^p \mu^*_i\nabla_xh_i(x^*) = 0\]</span></p>
<p>For the sake of completeness, since we stated them without offering a proof, let’s prove the equivalent claims <span class="math inline">\((6.1)\)</span> and <span class="math inline">\((6.2)\)</span> from which stationarity condition ultimately follows.</p>
<section id="proof-of-claims-6.1-and-6.2" class="level4">
<h4 class="anchored" data-anchor-id="proof-of-claims-6.1-and-6.2">Proof of Claims (6.1) and (6.2)</h4>
<p>Suppose <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*, \mu^*)\)</span> are primal-dual optimal for a strongly dual problem.</p>
<p>The following point-wise inequality holds in general since its LHS is a minimization over <span class="math inline">\(x\)</span> and its RHS is a maximization over <span class="math inline">\((\lambda, \mu)\)</span> of the Lagrangian.</p>
<p><span class="math display">\[g(\lambda, \mu) \leq \mathcal{L}(x, \lambda, \mu) \leq \mathcal{J}(x) \ \ \forall x, \lambda \geq 0, \mu\]</span></p>
<p>It is also, in particular, true for the primal-dual optimal pair. That is:</p>
<p><span class="math display">\[g(\lambda^*, \mu^*) \leq \mathcal{L}(x^*, \lambda^*, \mu^*) \leq \mathcal{J}(x^*) \tag{7.1}\]</span></p>
<p>However, <span class="math inline">\(\mathcal{J}(x^*) = f_0(x^*)\)</span> and, by strong duality, <span class="math inline">\(g(\lambda^*, \mu^*) = f_0(x^*)\)</span>. Hence, <span class="math inline">\(g(\lambda^*, \mu^*) = \mathcal{J}(x^*)\)</span> and <span class="math inline">\((7.1)\)</span> is actually the equality.</p>
<p><span class="math display">\[\mathcal{L}(x^*, \lambda^*, \mu^*) = g(\lambda^*, \mu^*) \tag{7.2}\]</span></p>
<p>Substituting, the definition of the dual function for the RHS of <span class="math inline">\((7.2)\)</span>, we get:</p>
<p><span class="math display">\[\mathcal{L}(x^*, \lambda^*, \mu^*) = \min_x \mathcal{L}(x, \lambda^*, \mu^*)\]</span></p>
<p>Which is exactly <span class="math inline">\((6.2)\)</span> and, by equivalence, also <span class="math inline">\((6.1)\)</span>.</p>
</section>
</section>
<section id="complementary-slackness" class="level2">
<h2 class="anchored" data-anchor-id="complementary-slackness">Complementary Slackness</h2>
<p>Strong duality also obtains another optimality condition known as <em>complementary slackness (CS)</em>.</p>
<blockquote class="blockquote">
<p><strong>Complementary Slackness (CS):</strong> &nbsp; Suppose <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*, \mu^*)\)</span> are primal-dual optimal for a strongly dual problem. Then: <span class="math display">\[\lambda^*_i f_i(x^*) = 0 \ \ \forall i\]</span></p>
</blockquote>
<p>Informally, if a primal constraint at an optimal <span class="math inline">\(x^*\)</span> is <em>loose</em>, that is <span class="math inline">\(f_i(x^*) \ne 0\)</span>, then its corresponding dual variable <span class="math inline">\(\lambda^*_i\)</span> in the dual optimal <span class="math inline">\(\lambda^*\)</span> must be zero. Conversely, if the dual variable <span class="math inline">\(\lambda_i^*\)</span> is positive then the corresponding constraint must be <em>tight</em>.</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>If a primal constraint is <em>tight</em> at <span class="math inline">\(x^*\)</span>, complementary slackness tells us nothing about its corresponding dual variable.</p>
</div>
</div>
</div>
<section id="proof-of-complementary-slackness" class="level4">
<h4 class="anchored" data-anchor-id="proof-of-complementary-slackness">Proof of Complementary Slackness</h4>
<p>Suppose <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*, \mu^*)\)</span> are primal-dual optimal for a strongly dual problem.</p>
<p>Expanding the RHS we obtain:</p>
<p><br> <span class="math display">\[
\begin{aligned}
f_0(x^*) &amp;= g(\lambda^*, \mu^*) \\
&amp;= \min_x \mathcal{L}(x, \lambda^*, \mu^*) \\
&amp;= \mathcal{L}(x^*, \lambda^*, \mu^*) \\
&amp;=  f_0(x^*) + \sum_{i=1}^m \lambda_i^* f_i(x) + \sum_{i=1}^p \mu_i^* h_i(x^*) \\
&amp;\leq f_0(x^*)
\end{aligned} \tag{8.1}
\]</span> <br></p>
<p>The first equality holds by strong duality, the second holds by the definition of the dual function, the third equality holds by <span class="math inline">\((6.2)\)</span>, and the fourth is true by the expansion of <span class="math inline">\(\mathcal{L}(x^*, \lambda^*, \mu^*)\)</span>.</p>
<p>To see why the last inequality holds, note that:</p>
<p><span class="math display">\[\sum_{i=1}^p \mu_i^* h_i(x^*) = 0\]</span></p>
<p>since, by feasibility of <span class="math inline">\(x^*\)</span>, <span class="math inline">\(h_i(x^*) = 0 \ \ \forall i\)</span>. Then again, by feasibility of <span class="math inline">\(x^*\)</span>, we have:</p>
<p><span class="math display">\[f_i(x^*) \leq 0  \ \ \forall i \tag{8.2}\]</span></p>
<p>Furthermore, by construction of the Lagrangian, <span class="math inline">\(\lambda \geq 0\)</span>. So, together with <span class="math inline">\((8.2)\)</span>, we have:</p>
<p><span class="math display">\[\sum_{i=1}^m \lambda^*_i f_i(x^*) \leq 0\]</span></p>
<p>But taken altogether <span class="math inline">\((8.1)\)</span> says <span class="math inline">\(f_0(x^*) \leq f_0(x^*)\)</span> which can <em>only</em> hold through strict equality.</p>
<p>Then it must be the case that <span class="math inline">\(\sum_{i=1}^m \lambda^*_i f_i(x^*) = 0\)</span></p>
<p>Being a sum of non-positive terms, <span class="math inline">\(\sum_{i=1}^m \lambda^*_i f_i(x^*) = 0\)</span> <em>if and only if</em></p>
<p><span class="math display">\[\lambda^*_i f_i(x^*) = 0 \ \ \forall i \tag{8.3}\]</span></p>
<p>which concludes the proof of complementary slackness.</p>
</section>
</section>
<section id="karush-kuhn-tucker-kkt-conditions" class="level2">
<h2 class="anchored" data-anchor-id="karush-kuhn-tucker-kkt-conditions">Karush-Kuhn-Tucker (KKT) Conditions</h2>
<p>Complementary slackness and stationarity condition are often bundled into the KKT Conditions.</p>
<p>In the absence of strong duality the KKT Conditions are necessary but insufficient for optimality. However, for problems which <em>are</em> strongly dual the KKT Conditions become a <strong><em>certificate of optimality</em></strong>. That is, they are both necessary and sufficient.</p>
<blockquote class="blockquote">
<p><strong>KKT Conditions:</strong> &nbsp; The primal-dual pair <span class="math inline">\((x^*, (\lambda^*, \mu^*))\)</span> satisfies the <strong><em>KKT conditions</em></strong> if the following hold:</p>
<ol type="1">
<li><span class="math inline">\(\nabla_x f_0(x^*) + \sum_{i=1}^m \lambda^*_i\nabla_xf_i(x^*) + \sum_{i=1}^p \mu^*_i\nabla_xh_i(x^*) = 0\)</span></li>
<li><span class="math inline">\(\lambda^*_if_i(x^*) = 0 \ \ \forall i\)</span></li>
<li><span class="math inline">\(g_i(x^*) \leq 0 \ \ \forall i\)</span></li>
<li><span class="math inline">\(h_i(x^*) = 0 \ \ \forall i\)</span></li>
<li><span class="math inline">\(\lambda^* \geq 0\)</span></li>
</ol>
</blockquote>
<p>We recognize <em>KKT-1</em> as the stationarity condition, and <em>KKT-2</em> as complementary slackness. <em>KKT-3</em> through <em>KKT-5</em> simply ensure primal-dual feasibility.</p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>These conditions only apply to problems with differentiable objective and constraints. For the case in which one or more of the objective or constraints is non-differentiable, there is an easy generalization of the KKT conditions using sub-differentials. However, sub-differentials are beyond the scope of this post.</p>
</div>
</div>
</div>
<p>Primal-dual pairs which satisfy the KKT Conditions are called <strong><em>KKT pairs</em></strong>.</p>
<section id="generalization-of-unconstrained-optimization" class="level3">
<h3 class="anchored" data-anchor-id="generalization-of-unconstrained-optimization">Generalization of Unconstrained Optimization</h3>
<p>The KKT conditions represent a strict generalization of the unconstrained optimality condition for use in constrained problems.</p>
<p>To see this, note that if there are no constraints then the KKT conditions simply reduce to the familiar unconstrained optimality condition:</p>
<p><br> <span class="math display">\[\nabla_x f_0(x^*) = 0\]</span> <br></p>
<p>In order to discuss optimality in constrained problems, we must first define a <strong><em>feasible direction</em></strong>.</p>
<blockquote class="blockquote">
<p><strong>Feasible Direction:</strong> &nbsp; A unit vector <span class="math inline">\(d\)</span> is called a <em>feasible direction</em> at any <span class="math inline">\(x\)</span> if <span class="math inline">\(x + \epsilon d\)</span> remains feasible for <span class="math inline">\(\epsilon &gt; 0\)</span> small enough.</p>
</blockquote>
<p>We are now in a position to generalize the unconstrained optimality condition into a <strong><em>constrained optimality condition</em></strong>.</p>
<p>By using <em>Taylor expansion</em>, for small enough <span class="math inline">\(\epsilon &gt; 0\)</span> and any feasible <span class="math inline">\(d\)</span>, we can estimate <span class="math inline">\(f_0(x^* + \epsilon d)\)</span> by its linear approximation as:</p>
<p><br> <span class="math display">\[f_0(x^* + \epsilon d) = f_0(x^*) + \epsilon \nabla f_0(x^*)^Td\]</span> <br></p>
<p>But since <span class="math inline">\(x^*\)</span> is optimal, we have:</p>
<p><br> <span class="math display">\[
\begin{aligned}
f_0(x^*) &amp;\leq f_0(x^* + \epsilon d) \\
&amp; = f_0(x^*) + \epsilon \nabla f_0(x^*)^Td
\end{aligned}
\]</span> <br></p>
<p>Which necessitates that <span class="math inline">\(\nabla f_0(x^*)^Td \geq 0\)</span>. Since <span class="math inline">\(d\)</span> was just an arbitrary feasible direction, this result must hold for <em>all</em> feasible directions. Hence, the constrained optimality condition can be given as:</p>
<blockquote class="blockquote">
<p><strong>Constrained Optimality Condition:</strong> &nbsp; If <span class="math inline">\(x^*\)</span> is an optimizer of <span class="math inline">\(f_0\)</span> over some constraint set then, for any feasible direction <span class="math inline">\(d\)</span> at <span class="math inline">\(x^*\)</span>, <span class="math inline">\(\nabla f_0(x^*)^Td \geq 0\)</span>.</p>
</blockquote>
<p>Note that <span class="math inline">\(\nabla f_0(x^*)^Td\)</span> is simply the <strong><em>directional derivative</em></strong> of <span class="math inline">\(f_0\)</span> in the direction <span class="math inline">\(d\)</span>. So, in plain words, the constrained optimality condition says that the directional derivative of the objective function in any feasible direction at an optimizer should be non-negative. This ensures that moving in any feasible direction does not minimize the objective any further.</p>
</section>
<section id="certificate-of-optimality" class="level3">
<h3 class="anchored" data-anchor-id="certificate-of-optimality">Certificate of Optimality</h3>
<p>As promised, the KKT Conditions together with strong duality obtain a certificate of optimality.</p>
<blockquote class="blockquote">
<p><strong>Certificate of Optimality:</strong> &nbsp; If strong duality holds, then <span class="math inline">\(x^*, (\lambda^*, \mu^*)\)</span> are primal-dual optimal if and only if they are a KKT pair.</p>
</blockquote>
<section id="proof-of-certificate-of-optimality" class="level4">
<h4 class="anchored" data-anchor-id="proof-of-certificate-of-optimality">Proof of Certificate of Optimality</h4>
<p>We have already shown one direction of the certificate in the sections on <a href="../../posts/optimization/duality-theory.html#stationarity-condition">stationarity condition</a> and <a href="../../posts/optimization/duality-theory.html#complementary-slackness">complementary slackness</a>, where we proved that being a primal-dual optimal pair in a strongly convex problem guarantees <span class="math inline">\((x^*, (\lambda^*, \mu^*))\)</span> is also a KKT pair.</p>
<p>Showing the other direction provides us with an interesting geometric viewpoint of the KKT conditions. Incidentally, Farkas’ Lemma is the key theoretical result that underpins this proof.</p>
<p>Let’s begin the proof.</p>
<p>If a particular constraint is loose at <span class="math inline">\(x^*\)</span> then taking a small enough step in any direction from <span class="math inline">\(x^*\)</span> does not violate it. Formally, if <span class="math inline">\(f_i(x^*) &lt; 0\)</span>, then <span class="math inline">\(f_i(x^* + \epsilon d) \leq 0\)</span> <span class="math inline">\(\forall d\)</span> and for some <span class="math inline">\(\epsilon &gt;0\)</span>. So, loose constraints do not pose any restrictions on the set of feasible directions.</p>
<p>However, if a constraint is tight at <span class="math inline">\(x^*\)</span>, that is <span class="math inline">\(f_i(x^*) = 0\)</span>, then we must be careful not to violate it. Suppose the set of indices of all the tight constraints at <span class="math inline">\(x^*\)</span> is given by <span class="math inline">\(I_{x^*}\)</span>. For small enough <span class="math inline">\(\epsilon &gt; 0\)</span>, we can estimate <span class="math inline">\(f_i(x^* + \epsilon d)\)</span> by its linear Taylor expansion as:</p>
<p><span class="math display">\[f_i(x^* + \epsilon d) = f_i(x^*) + \epsilon \nabla f_i(x^*)^Td \ \ \forall i \in I_{x^*}\]</span></p>
<p>For feasibility, we want <span class="math inline">\(f_i(x^* + \epsilon d) \leq 0\)</span>. So, we require:</p>
<p><span class="math display">\[f_i(x^*) + \epsilon \nabla f_i(x^*)^Td \leq 0 \ \ \forall i \in I_{x^*}\]</span></p>
<p>But since <span class="math inline">\(f_i\)</span> is tight at <span class="math inline">\(x^*\)</span>, <span class="math inline">\(f_i(x^*) = 0\)</span>, which simply leaves us with:</p>
<p><span class="math display">\[\nabla f_i(x^*)^Td \leq 0 \ \ \forall i \in I_{x^*}\]</span></p>
<p>With the above restriction of <span class="math inline">\(d\)</span>, the feasible directions can now be stated as:</p>
<p><span class="math display">\[d \ \textrm{s.t.} \ \nabla f_i(x^*)^Td \leq 0 \ \ \forall i \in I_{x^*} \tag{8.1}\]</span></p>
<p>Or, equivalently:</p>
<p><span class="math display">\[d \ \textrm{s.t.} \ - \nabla f_i(x^*)^Td \geq 0 \ \ \forall i \in I_{x^*} \tag{8.2}\]</span></p>
<p>But, since <span class="math inline">\(x^*\)</span> is optimal, by the constrained optimality condition we have:</p>
<p><span class="math display">\[\nabla f_0(x^*)^Td \geq 0 \ \ \forall \ \textrm{feasible} \ d \tag{8.3}\]</span></p>
<p>That is, for all <span class="math inline">\(d\)</span> as in <span class="math inline">\((8.2)\)</span>.</p>
<p>Put together, <span class="math inline">\((8.2)\)</span> and <span class="math inline">\((8.3)\)</span> say that <span class="math inline">\(\not \exists \ d\)</span> which defines a separating hyperplane between <span class="math inline">\(\nabla f_0(x^*)\)</span> and <span class="math inline">\(-\nabla f_i(x^*)\)</span> for all binding constraints at <span class="math inline">\(x^*\)</span>. By Farka’s Lemma, this means that the only other alternative scenario must be true — it must be the case that <span class="math inline">\(\nabla f_0(x^*)\)</span> lies in the cone of the <span class="math inline">\(-\nabla f_i(x^*)\)</span>’s.</p>
<p>Formally, <span class="math inline">\(\exists \ \lambda^* \geq 0\)</span> s.t.</p>
<p><span class="math display">\[\nabla f_0(x^*) + \sum_{i \in I_{x^*}} \lambda^*_i f_i(x^*) = 0 \tag{8.4}\]</span></p>
<p>Upon closer examination, <span class="math inline">\((8.4)\)</span> is exactly <em>KKT-1</em>, <em>KKT- 2</em>, and <em>KKT-5</em> all rolled into one condition. The remaining conditions, <em>KKT-3</em> and <em>KKT-4</em> simply follow from the assumed feasibility of <span class="math inline">\(x^*\)</span>.</p>
<p>Thus, we have shown that if <span class="math inline">\(x^*\)</span> is primal-optimal, its KKT pair <span class="math inline">\((x^*, (\lambda^*, \mu^*))\)</span> exists. Furthermore, as proved earlier, if strong duality holds then any KKT pair is primal-dual optimal. Hence, if strong duality holds, the <span class="math inline">\((\lambda^*, \mu^*)\)</span> obtained through the above procedure is also dual-optimal.</p>
</section>
</section>
</section>
</section>
<section id="strong-duality---linear-programs" class="level1">
<h1>Strong Duality - Linear Programs</h1>
<p>Linear Programs, due to their simpler structure, lend themselves to a direct proof of strong duality. So, to wrap up this post, we show that LPs have strong duality through a direct proof.</p>
<p>Strong duality for LPs can be stated as:</p>
<blockquote class="blockquote">
<p><strong>LP Strong Duality:</strong> &nbsp; If the primal is feasible and bounded with optimal <span class="math inline">\(x^*\)</span> then the dual is also feasible and bounded. Furthermore, a dual optimal <span class="math inline">\(p^*\)</span> is s.t. <span class="math inline">\(c^Tx^* = b^Tp^*\)</span>.</p>
</blockquote>
<p>Where <span class="math inline">\(x\)</span> is the primal variable, <span class="math inline">\(c^Tx\)</span> is the primal objective, <span class="math inline">\(p\)</span> is the dual variable, and <span class="math inline">\(b^Tp\)</span> is the dual objective.</p>
<section id="proof-of-strong-duality-in-lps" class="level2">
<h2 class="anchored" data-anchor-id="proof-of-strong-duality-in-lps">Proof of Strong Duality in LP’s</h2>
<section id="prelude-1" class="level3">
<h3 class="anchored" data-anchor-id="prelude-1">Prelude</h3>
<p>As in the general case, we construct a KKT pair through the use of Farkas’ Lemma. Then, by a structural property of LPs, we notice that the dual and the primal optima agree. This concludes the proof of LP strong duality.</p>
</section>
<section id="proof-1" class="level3">
<h3 class="anchored" data-anchor-id="proof-1">Proof</h3>
<p>Suppose <span class="math inline">\(x^*\)</span> is primal-optimal. Let the set <span class="math inline">\(I_{x^*} = \{ i : a_i^Tx^* = b_i\}\)</span> be the set of the indices of the active constraints at <span class="math inline">\(x^*\)</span>. Our goal is to construct a dual optimal solution <span class="math inline">\(p^*\)</span> s.t. <span class="math inline">\(c^Tx^* = b^Tp^*\)</span>.</p>
<p>Let <span class="math inline">\(d\)</span> be any vector that satisfies <span class="math inline">\(d^Ta_i \geq 0 \ \ \forall i \in I_{x^*}\)</span>. That is, <span class="math inline">\(d\)</span> is a feasible direction w.r.t. to all the active constraints.</p>
<p>By the assumption that <span class="math inline">\(x^*\)</span> is optimal, we have <span class="math inline">\(c^Tx^* \leq c^T(x^* + \epsilon d) = c^Tx^* + \epsilon c^Td\)</span>. Thus, <span class="math inline">\(c^Td = d^Tc \geq 0\)</span></p>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Note">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(d^Tc\)</span> is nothing but the <em>directional derivative</em> at the minimizer <span class="math inline">\(x^*\)</span>. So, this also follows from the optimality of <span class="math inline">\(x^*\)</span> using the constrained optimality condition.</p>
</div>
</div>
</div>
<p>But, since <span class="math inline">\(d\)</span> is a vector s.t. <span class="math inline">\(d^Ta_i \geq 0 \ \ \forall i \in I_{x^*}\)</span> and <span class="math inline">\(d^Tc \geq 0\)</span>, <span class="math inline">\(d\)</span> does <em>not</em> separate <span class="math inline">\(c\)</span> from the cone of the <span class="math inline">\(a_i\)</span>’s. And, since <span class="math inline">\(d\)</span> was arbitrary, this puts us in the setting of Farkas’ Lemma. Namely, there exist <em>no</em> vectors <span class="math inline">\(d\)</span> that separate <span class="math inline">\(c\)</span> from the cone. This means the alternative must be true — <span class="math inline">\(c\)</span> must a conic combination of the <span class="math inline">\(a_i\)</span>’s that are active at the minimizer. In other words, <span class="math inline">\(\exists p \geq 0\)</span> s.t. <span class="math inline">\(c = \sum_{i \in I_{x^*}} p_ia_i\)</span>.</p>
<p>But <span class="math inline">\(p\)</span> has dimension equal to only the number of active constraints at <span class="math inline">\(x^*\)</span>. To be a dual variable at all, it must have dimension equal to the number of all primal constraints. We extend <span class="math inline">\(p\)</span> to <span class="math inline">\(p^*\)</span> by setting all the entries that do not correspond to the active constraints at <span class="math inline">\(x^*\)</span> to be zero.</p>
<p>That is <span class="math inline">\(p^*_i = \begin{cases} p_i \ \ \textrm{if} \ \  i \in I_{x^*} \\ 0   \ \ \textrm{if} \ \  i \notin I_{x^*} \end{cases}\)</span>.</p>
<p>Now <span class="math inline">\(A^Tp^*  = \sum_{i} p^*_ia_i = c\)</span>, so any feasibility condition in the dual, whether it be <span class="math inline">\(A^Tp \leq c\)</span>, <span class="math inline">\(A^Tp \geq c\)</span>, or <span class="math inline">\(A^Tp = c\)</span>, is satisfied by <span class="math inline">\(p^*\)</span>.</p>
<p>Furthermore, the dual objective at <span class="math inline">\(p^*\)</span> agrees with the primal objective at <span class="math inline">\(x^*\)</span>.</p>
<p><span class="math display">\[b^Tp^* = \sum_{i} b_ip_i^* = \sum_{i \in I_{x^*}} b_ip_i^* + \sum_{i \notin I_{x^*}} b_ip_i^* = \sum_{i \in I_{x^*}} a_i^Tx^*p_i^* = (\sum_{i \in I_{x^*}} p_ia_i^T)x^* = c^Tx^* \]</span></p>
<p>This concludes the proof.</p>
</section>
</section>
</section>
<section id="further-reading---duality-in-unconstrained-problems" class="level1">
<h1>Further Reading - Duality in Unconstrained Problems</h1>
<p>As mentioned briefly, in the case of certain types of unconstrained problems, the <strong><em>Fenchel-Legendre (FL) Transform</em></strong> is what gives rise to the dual.</p>
<p>First, we define the FL transform which is also known as a <strong><em>convex conjugate</em></strong> for reasons that will soon become apparent.</p>
<blockquote class="blockquote">
<p><strong>FL Transform / Convex Conjugate:</strong> &nbsp; The <em>FL Transform</em> or <em>Convex Conjugate</em> of a function <span class="math inline">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> is: <span class="math display">\[f^*(y) = \sup_x \left\{y^Tx - f(x)\right\}\]</span></p>
</blockquote>
<p>We note some key properties of the FL Transform.</p>
<section id="fl-transform---a-convex-operation" class="level2">
<h2 class="anchored" data-anchor-id="fl-transform---a-convex-operation">FL Transform - a Convex Operation</h2>
<p>The FL Transform <span class="math inline">\(f^*\)</span> is always convex regardless of the convexity of <span class="math inline">\(f\)</span>.</p>
<p>That’s because, for a fixed <span class="math inline">\(x\)</span>, <span class="math inline">\(y^Tx - f(x)\)</span> is a linear function in <span class="math inline">\(y\)</span>. So, <span class="math inline">\(f^*\)</span> is a point-wise supremum of linear functions, making it convex.</p>
</section>
<section id="the-case-of-involution" class="level2">
<h2 class="anchored" data-anchor-id="the-case-of-involution">The Case of Involution</h2>
<p>The double FL Transform <span class="math inline">\(f^{**}\)</span> does not always recover <span class="math inline">\(f\)</span>. To see this fact note that, as an FL Transform of the <em>some</em> function (namely, <span class="math inline">\(f^*\)</span>), <span class="math inline">\(f^{**}\)</span> is always convex. Therefore, <span class="math inline">\(f^{**} \ne f\)</span> if <span class="math inline">\(f\)</span> is non-convex.</p>
<p>But convexity alone is not enough to guarantee involution. We need an additional condition on <span class="math inline">\(f\)</span>, namely that its sub-level sets must be closed, to ensure <span class="math inline">\(f^{**} = f\)</span>.</p>
</section>
<section id="inverse-gradients" class="level2">
<h2 class="anchored" data-anchor-id="inverse-gradients">Inverse Gradients</h2>
<p>If <span class="math inline">\(f\)</span> has closed sub-level sets and is convex then the gradients of <span class="math inline">\(f\)</span> and <span class="math inline">\(f^*\)</span> are inverses. That is, assuming both <span class="math inline">\(f\)</span> and <span class="math inline">\(f^*\)</span> are differentiable:</p>
<p><span class="math display">\[y = \nabla f(x) \iff x = \nabla f^*(y)\]</span></p>
<p>Let’s first prove the <span class="math inline">\(\implies\)</span> direction.</p>
<p>Suppose <span class="math inline">\(y = \nabla f(x)\)</span>. By <span class="math inline">\(f\)</span>’s convexity:</p>
<p><span class="math display">\[f(\hat x) \geq f(x) + y^T(\hat x - x) \ \ \forall \hat x\]</span></p>
<p>And so:</p>
<p><span class="math display">\[y^T \hat x - f(\hat x) \leq y^T x - f(x) \ \ \forall \hat x\]</span></p>
<p>By taking supremum over <span class="math inline">\(x\)</span> and by noting that, since the sub-level sets are closed, the supremum is attained, we obtain:</p>
<p><span class="math display">\[f^*(y) = y^T x - f(x)\]</span></p>
<p>The desired result follows by taking the gradient of both sides w.r.t. <span class="math inline">\(y\)</span>. That is:</p>
<p><span class="math display">\[\nabla f^*(y) = x\]</span></p>
<p>The <span class="math inline">\(\impliedby\)</span> direction is similar. We start from the assumption that <span class="math inline">\(x = \nabla f^*(y)\)</span> and get the desired result by using the involution property <span class="math inline">\(f^{**} = f\)</span>.</p>
</section>
<section id="fl-duality" class="level2">
<h2 class="anchored" data-anchor-id="fl-duality">FL Duality</h2>
<p>As mentioned, the FL Transform has a natural role in duality.</p>
<p>Suppose the unconstrained optimization problem is:</p>
<p><span class="math display">\[\min_x : f(x) + h(Ax)\]</span></p>
<p>Where <span class="math inline">\(f\)</span> and <span class="math inline">\(h\)</span> are convex functions, and <span class="math inline">\(A\)</span> is a matrix representing a bounded linear transformation.</p>
<p>We introduce a dummy variable <span class="math inline">\(y\)</span> and form the artificial constraint <span class="math inline">\(y = Ax\)</span>. The problem becomes:</p>
<p><span class="math display">\[
\begin{aligned}
\min_{x,y} &amp;: f(x) + h(y) \\
s.t. &amp;: Ax = y
\end{aligned}
\]</span></p>
<p>Forming the Lagrangian gives us:</p>
<p><span class="math display">\[\mathcal{L}(x,y,z) = f(x) + h(y) + z^T(Ax - y)\]</span></p>
<p>Then, the dual function is the following FL Transform:</p>
<p><span class="math display">\[
\begin{aligned}
g(z) &amp;= \min_{x,y} \mathcal{L}(x,y,z) \\
&amp;= \min_{x,y} f(x) + h(y) + z^T(Ax - y) \\
&amp;= \min_{x,y} (A^Tz)^Tx + f(x) - z^Ty + h(y) \\
&amp;= \min_x \left\{ (A^Tz)^Tx + f(x) \right\} + \min_y \left\{ -z^Ty + h(y) \right\} \\
&amp;= \min_x \left\{ -\left((-A^Tz)^Tx - f(x)\right) \right\} + \min_y \left\{ -\left(z^Ty - h(y)\right) \right\} \\
&amp;= - \max_x \left\{ (-A^Tz)^Tx - f(x) \right\} - \max_y \left\{ z^Ty - h(y) \right\} \\
&amp;= - f^*(-A^Tz) - h^*(z)
\end{aligned}
\]</span></p>
<p>And, consequently, the dual problem is:</p>
<p><span class="math display">\[\max_z: - f^*(-A^Tz) - h^*(z)\]</span></p>
<p>To convince ourselves of the utility of this dual, note that the dual is, indeed, an easier problem. This is because the negative of an FL Transform is always concave regardless of the convexity of <span class="math inline">\(f\)</span> and <span class="math inline">\(h\)</span>. So, the dual problem is a maximization of a concave function which is, in general, an easy optimization problem.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/v-poghosyan\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="v-poghosyan/blog" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2021, Vahram Poghosyan</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.github.com/v-poghosyan">
      <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/vahrampoghosyan/">
      <i class="bi bi-linkedin" role="img" aria-label="GitHub">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script type="application/javascript" src="../../javascript/light-dark.js"></script>




</body></html>