{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Three.js - 3D Animations in the Browser\"\n",
    "author: \"Vahram Poghosyan\"\n",
    "date: \"2024-12-26\"\n",
    "categories: [\"Three.js\", \"Visualization\", \"JavaScript\"]\n",
    "format:\n",
    "  html:\n",
    "    css: ./css/three-js-demo.css\n",
    "    code-fold: false\n",
    "toc-depth: 4\n",
    "jupyter: python3\n",
    "highlight-style: github\n",
    "include-after-body:\n",
    "  text: |\n",
    "    <script type=\"application/javascript\" src=\"../../../javascript/light-dark.js\"></script>\n",
    "    <script type=\"importmap\">\n",
    "      {\n",
    "          \"imports\": {\n",
    "              \"three\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/+esm\",\n",
    "              \"OBJLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js\",\n",
    "              \"MTLLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js\"\n",
    "          }\n",
    "      }\n",
    "    </script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-grid-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-custom-object-with-material-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-many-ducks-demo.js\"></script>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this post we use [Three.js](https://threejs.org/) external scripts to render 3D scenes inside this Jupyter notebook. \n",
    "\n",
    "This post will be very similar, in terms of its stack, to the [D3.js interactive US map post](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb).\n",
    "\n",
    "In *that* post, we learned that Canvas and SVG are two ways in which we can display complex graphics inside a web browser. We already explored SVG graphics in [D3.js interactive US map](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb). It's worth noting that a lot of the same functionality could've been replicated using the HTML Canvas element instead of SVG (which we ultimately chose for its superior interactive capabilities) -- the article mentions one way to do that by using [skia-canvas](https://github.com/samizdatco/skia-canvas). \n",
    "\n",
    "We ended up using [linkedom](https://github.com/WebReflection/linkedom#readme) to add a DOM API on top of the Deno environment. \n",
    "\n",
    "In fact, what I realized later on is that we could've simply used the Markdown inside our Jupyter notebook to create the `<svg>` element without the need to introduce a third-party DOM API on top of a browser-less JavaScript environment (Deno). Then, we could have simply fetched the `TopoJSON` data and constructed the map inside our external scripts with the rest of the complex D3 animations that had to be added as external scripts. \n",
    "These scripts are run by Quarto only *after* the page has been rendered to the browser, so we can easily reference the DOM elements we create inside our notes by `class` or `id`. Crucially, the external scripts are meant to run *inside the browser* (as opposed to being pre-computed in the browser-less Deno environment). Inside the browser they're able to leverage the existing DOM API provided by the browser's engine (e.g. `document.getElementById`). Hence, this way, we eliminate the need for Deno as well as Linkedom.\n",
    "\n",
    "We will use the [IPython.display](https://ipython.readthedocs.io/en/8.26.0/api/generated/IPython.display.html) module to create HTML elements inside our notes rather than just using Markdown directly.\n",
    "\n",
    "# Three.js, WebGL, and Canvas API\n",
    "\n",
    "[Three.js](https://threejs.org/) is a library for drawing 3D graphics in the browser using JavaScript and [WebGL](https://get.webgl.org/) (see [wiki](https://www.khronos.org/webgl/wiki/Main_Page)). \n",
    "\n",
    "WebGL runs in an HTML Canvas (i.e. `<canvas>`). \n",
    "\n",
    "From the WebGL wiki: \n",
    "\n",
    "> WebGL is a DOM API, which means that it can be used from any DOM-compatible language: e.g. JavaScript\n",
    "\n",
    "Three.js is a library that provides conveniences in JavaScript that abstract much of this [WebGL](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API) DOM API calls behind friendly JavaScript. \n",
    "\n",
    "Note that WebGL and Canvas API are two ways in which the browser draws graphics, but they both require and HTML Canvas to draw on. Three.js offers a WebGL renderer as well as a Canvas renderer. Canvas API is usually a fallback option for when WebGL, the more powerful of the two APIs, isn't available. \n",
    "\n",
    "Note, also, that Three.js isn't suitable for modelling purposes, for that we can use [Blender](https://www.blender.org/) or a number of other closed-source 3D modelling applications. We can even download or purchase third-party models from vendors.\n",
    "\n",
    "Canvas and SVG elements are two ways in which we can display complex graphics inside a web browser. We already explored SVG graphics in the [D3.js interactive US Map](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb) post. It's worth noting that a lot of the same functionality could've been achieved by using the HTML Canvas element with D3 instead. The article mentions one way to do that by using [skia-canvas](https://github.com/samizdatco/skia-canvas). In this post we use Three.js (not D3) to draw inside a Canvas element using, not the Canvas API, but rather WebGL.\n",
    "\n",
    "# 3D Scenes - A Primer\n",
    "\n",
    "In *any* 3D scene, be it in the web browser, inside a game engine, in a movie, in a 3D modelling application, etc. there are a bunch of **geometries**, or **shapes** that are packaged with **materials** as **meshes**. The materials can describe simple properties like reflectivity, opacity, refraction index, etc. or they can be  **textures** which are just simple [raster](https://en.wikipedia.org/wiki/Raster_graphics) images. We can also apply **shaders** to our objects, which are complex mappings of pixels (or vertices) that make up an interesting animation.\n",
    " \n",
    "A scene will also have one or more **light sources**, and a **camera** to *serve* the scene in some perspective.\n",
    "\n",
    "## Meshes, Objects, Geometries, and Materials\n",
    "\n",
    "An `object`, for the foreseeable future, means an object file of the [OBJ Wavefront format](https://en.wikipedia.org/wiki/Wavefront_.obj_file). These are files that consist of `object.children[n].geometry` and `object.children[n].material` fields. However, the material fields inside an OBJ are just *references* (via `usemtl` statements) to the true materials which come separately in `.mtl` files (typically from the same place as the `.obj` file).\n",
    "\n",
    "There's usually no need to break the object down into individual child geometries and their corresponding objects. But, it's certainly possible. One use case would be if we want to apply a different transformation to each component. Usually, however, we load the object as a whole.\n",
    "\n",
    "# Our First Canvas\n",
    "\n",
    "Let's create a `<canvas>` with `id=\"three-d-canvas\"`.\n",
    "\n",
    "We can do it either using raw markup below this very cell, or by using the `IPython.display` module which allows us to display rich representations of objects in a Jupyter notebook (much like the `Deno.jupyter.display` module we saw in the [D3.js US map post](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb)).\n",
    "\n",
    "Using `IPython.display` is more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas'></canvas>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code that produces the above output. Feel free to expand and examine. We will paint the general strokes below.\n",
    "\n",
    "<details><summary>Click to expand the Torus code</summary>\n",
    "```javascript\n",
    "import * as three from 'https://cdn.jsdelivr.net/npm/three@0.173.0/+esm'\n",
    "\n",
    "const scene = new three.Scene();\n",
    "\n",
    "const body = document.getElementById(\"quarto-document-content\");\n",
    "const bodyWidth = body.clientWidth;\n",
    "const bodyHeight = 600;\n",
    "\n",
    "const canvas = document.getElementById(\"three-d-canvas\")\n",
    "\n",
    "const camera = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "camera.position.setZ(30);\n",
    "\n",
    "const renderer = new three.WebGLRenderer({\n",
    "    canvas: canvas\n",
    "});\n",
    "\n",
    "renderer.setPixelRatio( window.devicePixelRatio );\n",
    "renderer.setSize( bodyWidth, bodyHeight );\n",
    "\n",
    "\n",
    "renderer.render(scene, camera);\n",
    "\n",
    "const geometry = new three.TorusGeometry(10,3,16,100);\n",
    "const material = new three.MeshBasicMaterial({ color: 0xFF6347, wireframe: true });\n",
    "const torus = new three.Mesh(geometry, material);\n",
    "\n",
    "scene.add(torus);\n",
    "\n",
    "function animate() {\n",
    "    requestAnimationFrame(animate);\n",
    "\n",
    "    torus.rotation.x += 0.01;\n",
    "    torus.rotation.y += 0.005;\n",
    "    torus.rotation.z += 0.01;\n",
    "\n",
    "    renderer.render(scene, camera);\n",
    "}\n",
    "\n",
    "animate();\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice some general strokes.\n",
    "\n",
    "First, we create a `three.Scene` object.\n",
    "\n",
    "```js\n",
    "const scene = new three.Scene();\n",
    "```\n",
    "\n",
    "Then, we define some constants for Three.js's [WebGLRenderer](https://threejs.org/docs/#api/en/renderers/WebGLRenderer) relative to the HTML document's body (grabbing the latter using the DOM API).\n",
    "\n",
    "```js\n",
    "const body = document.getElementById(\"quarto-document-content\");\n",
    "const bodyWidth = body.clientWidth;\n",
    "const bodyHeight = 600;\n",
    "```\n",
    "\n",
    "Then, we grab the `<canvas>` element we created.\n",
    "\n",
    "```js\n",
    "const canvas = document.getElementById(\"three-d-canvas\")\n",
    "```\n",
    "After that, we create a [PerspectiveCamera](https://threejs.org/docs/#api/en/cameras/PerspectiveCamera), supplying it the [field of view](https://en.wikipedia.org/wiki/Field_of_view) among other attributes, and setting its position.\n",
    "\n",
    "```js\n",
    "const camera = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "camera.position.setZ(30);\n",
    "```\n",
    "\n",
    "We then create the `WebGLRenderer` object, supplying it the `canvas` to render, as well as setting some of its parameters.\n",
    "\n",
    "```js\n",
    "const renderer = new three.WebGLRenderer({\n",
    "    canvas: canvas\n",
    "});\n",
    "renderer.setPixelRatio( window.devicePixelRatio );\n",
    "renderer.setSize( bodyWidth, bodyHeight );\n",
    "```\n",
    "\n",
    "Finally, we render the scene by invoking the renderer's `.render(scene, camera)`.\n",
    "\n",
    "```js\n",
    "renderer.render(scene, camera);\n",
    "```\n",
    "\n",
    "The `scene` object continues to be our window into the 3D world we just created. To it, we add `geometries` and their `materials` through a combination object called a [Mesh](https://threejs.org/docs/#api/en/objects/Mesh).\n",
    "\n",
    "```js\n",
    "const geometry = new three.TorusGeometry(10,3,16,100);\n",
    "const material = new three.MeshBasicMaterial({ color: 0xFF6347, wireframe: true });\n",
    "const torus = new three.Mesh(geometry, material);\n",
    "\n",
    "scene.add(torus);\n",
    "```\n",
    "\n",
    "We can also add a little life to the scene by using a custom animation function.\n",
    "```js\n",
    "function animate() {\n",
    "    requestAnimationFrame(animate);\n",
    "\n",
    "    torus.rotation.x += 0.01;\n",
    "    torus.rotation.y += 0.005;\n",
    "    torus.rotation.z += 0.01;\n",
    "\n",
    "    renderer.render(scene, camera);\n",
    "}\n",
    "```\n",
    "We can invoke the animation within the outer lexical environment, for now.\n",
    "\n",
    "```\n",
    "animate();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid View\n",
    "\n",
    "To display multiple 3D `scenes` in a grid, we can simply use CSS-grid inside Jupyter.\n",
    "\n",
    "First we lay out the markup inside the notes:\n",
    "\n",
    "```html\n",
    "<div class=\"three-d-grid-container\">\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-1\"></canvas></div>\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-2\"></canvas></div>\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-3\"></canvas></div>\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-4\"></canvas></div>\n",
    "</div>\n",
    "```\n",
    "\n",
    "Then, we include the stylesheet in the post's own subdirectory, and use something like Quarto's `include-after-body` (as we also load the external scripts used to produce these rich 3D outputs):\n",
    "\n",
    "```yaml\n",
    "include-after-body:\n",
    "    <script type=\"module\" src=\"./javascript/three-js-demo.js\"></script>\n",
    "```\n",
    "\n",
    "It turns out that there's support for including CSS inside a Quarto post. It's done using the `format.html` flag in the front-matter as follows:\n",
    "\n",
    "```yaml\n",
    "format:\n",
    "  html:\n",
    "    css: ./css/three-js-demo.css\n",
    "```\n",
    "\n",
    "The file `three-js-demo.css` should contain these minimal styles: \n",
    "\n",
    "```css\n",
    "#three-d-grid-container {\n",
    "    display: grid;\n",
    "    grid-template-columns: repeat(2, 1fr);\n",
    "    grid-template-rows: repeat(2, 1fr);\n",
    "    gap: 10px;\n",
    "    width: 100%;\n",
    "    height: 50%;\n",
    "}\n",
    ".three-d-grid-item {\n",
    "    display: flex;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the grid markup.\n",
    "\n",
    "Now, inside the external script, we can reference the various `canvas` elements by `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id='three-d-grid-container'>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-1\"><canvas id=\"three-d-canvas-1\"></canvas></div>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-2\"><canvas id=\"three-d-canvas-2\"></canvas></div>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-3\"><canvas id=\"three-d-canvas-3\"></canvas></div>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-4\"><canvas id=\"three-d-canvas-4\"></canvas></div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\n",
    "    \"\"\"\n",
    "    <div id='three-d-grid-container'>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-1\"><canvas id=\"three-d-canvas-1\"></canvas></div>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-2\"><canvas id=\"three-d-canvas-2\"></canvas></div>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-3\"><canvas id=\"three-d-canvas-3\"></canvas></div>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-4\"><canvas id=\"three-d-canvas-4\"></canvas></div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Custom Objects with Materials\n",
    "\n",
    "Quarto won't serve `.obj` files (at least by default), so we can just commit the object file to the remote repository and use the `raw` GitHub link (as a CDN).\n",
    "\n",
    "We will also need the `OBJLoader`, a Three.js add-on. This can be grabbed from a CDN as well. We may also include it in the `include-after-body.text` front matter *before* loading the script file itself as:\n",
    "\n",
    "```yaml\n",
    "<script type=\"importmap\">\n",
    "    {\n",
    "        \"imports\": {\n",
    "            \"three\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/+esm\",\n",
    "            \"OBJLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js\"\n",
    "        }\n",
    "    }\n",
    "</script>\n",
    "```\n",
    "And then, within the script, import as follows:\n",
    "\n",
    "```js\n",
    "import * as three from 'three';\n",
    "import { OBJLoader } from 'OBJLoader';\n",
    "```\n",
    "\n",
    "Here's the full code to render a rubber ducky. It will help us debug our code going forward. I downloaded this model from [Sketchfab](https://sketchfab.com/3d-models/rubber-duck-ecb9ce9ff973406398ee56e391f9c902) which hosts many such free models.\n",
    "\n",
    "<details><summary> Click to expand the code used to generate the rubber ducky</summary>\n",
    "\n",
    "```js\n",
    "import * as three from 'https://cdn.jsdelivr.net/npm/three@0.173.0/build/three.module.js';\n",
    "import { OBJLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js';\n",
    "import { MTLLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js';\n",
    "\n",
    "// Get the container and set dimensions\n",
    "const body = document.getElementById(\"quarto-document-content\");\n",
    "const bodyWidth = body.clientWidth;\n",
    "const bodyHeight = 600;\n",
    "\n",
    "// Set up the canvas, scene, camera, and renderer\n",
    "const canvas = document.getElementById(\"three-d-canvas\");\n",
    "const scene = new three.Scene();\n",
    "const camera = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "const renderer = new three.WebGLRenderer({ canvas: canvas });\n",
    "renderer.setPixelRatio(window.devicePixelRatio);\n",
    "renderer.setSize(bodyWidth, bodyHeight);\n",
    "\n",
    "// Position the camera so the object will be in view.\n",
    "camera.position.set(0, 20, 0);\n",
    "\n",
    "// Add some lights so the materials are visible.\n",
    "const ambientLight = new three.AmbientLight(0xffffff, 0.6);\n",
    "scene.add(ambientLight);\n",
    "\n",
    "const directionalLight = new three.DirectionalLight(0xffffff, 0.8);\n",
    "directionalLight.position.set(10, 20, 10);\n",
    "scene.add(directionalLight);\n",
    "\n",
    "// Load the MTL file first.\n",
    "const mtlLoader = new MTLLoader();\n",
    "mtlLoader.load(\n",
    "  'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.mtl',\n",
    "  (materials) => {\n",
    "    materials.preload();\n",
    "\n",
    "    // Now load the OBJ file and set its materials.\n",
    "    const objLoader = new OBJLoader();\n",
    "    objLoader.setMaterials(materials);\n",
    "    objLoader.load(\n",
    "      'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.obj',\n",
    "      (object) => {\n",
    "        // Scale and position the loaded object.\n",
    "        object.scale.set(5, 5, 5);\n",
    "        object.position.set(0, 15, -20);\n",
    "        scene5.add(object);\n",
    "\n",
    "        // Animation loop\n",
    "        function animate() {\n",
    "          requestAnimationFrame(animate);\n",
    "          object.rotation.y += 0.01;\n",
    "          renderer.render(scene, camera);\n",
    "        }\n",
    "        animate();\n",
    "      },\n",
    "      // onProgress callback\n",
    "      (xhr) => {\n",
    "        console.log(\"Loading object...\");\n",
    "      },\n",
    "      // onError callback\n",
    "      (error) => {\n",
    "        console.error('An error occurred while loading the OBJ:', error);\n",
    "      }\n",
    "    );\n",
    "  },\n",
    "  // onProgress callback for MTL\n",
    "  (xhr) => {\n",
    "    console.log(\"Loading materials...\");\n",
    "  },\n",
    "  // onError callback for MTL\n",
    "  (error) => {\n",
    "    console.error('An error occurred while loading the MTL:', error);\n",
    "  }\n",
    ");\n",
    "```\n",
    "</details>\n",
    "\n",
    "Note that `OBJLoader` takes the URL of the object followed by a callback function that gets triggered by the object fully loading. \n",
    "\n",
    "The geometries of the object are in `object.children[n].geometry`. Each child is a part of the object (for example the eyes, wings, and nose of the duck correspond to the object's child geometries).\n",
    "\n",
    "Let's create another canvas to render the rubber ducky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas-5'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas-5'></canvas>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the materials, we used `MTLLoader`. Another add-on downloaded from the following CDN in the `include-after-body.text` front matter:\n",
    "\n",
    "```yaml\n",
    "<script type=\"importmap\">\n",
    "    {\n",
    "        \"imports\": {\n",
    "            \"MTLLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js\"\n",
    "        }\n",
    "    }\n",
    "</script>\n",
    "```\n",
    "Notice the nested calls? `OBJLoader` is typically called within `MTLLoader`, and gets the `material` supplied to it.\n",
    "\n",
    "The `MTLLoader` loads the material file (`rubber_duck.mtl`) and then calls `materials.preload()`. The `OBJLoader`’s `.setMaterials(materials)` ensures that when the OBJ file is loaded, it uses the material definitions from the MTL file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Complex Scenes\n",
    "\n",
    "HTML Canvas, by itself, is a thing of wonder. Here's a curated list of cool [Canvas API examples](https://github.com/raphamorim/awesome-canvas?tab=readme-ov-file). For example, here's [Pong](https://cssdeck.com/labs/full/ping-pong-game-tutorial-with-html5-canvas-and-sounds). Here's a cool [Matrix animation](https://matrix.dotglitch.dev/), and here's a tool that visualizes [L-systems](https://www.kevs3d.co.uk/dev/lsystems/#). The Canvas is what makes things like drawing tools or diagramming tools, such as Lucid, possible on the browser. \n",
    "\n",
    "For complex scenes, the HTML Canvas with the Canvas API is not enough. The [Canvas API](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API) is usually good for 2D applications (it explicitly sets its context as `\"2d\"`). This is where Three.js with its WebGL support comes in. \n",
    "\n",
    "For truly complex 3D web-applications (with mouse and keyboard controls and other advanced features or, perhaps, gameplay), we will need to integrate Three.js into a React app using [React Three Fiber (r3f)](https://r3f.docs.pmnd.rs/getting-started/introduction). React Three Fiber is a library that serves as a React renderer for Three.js. It enables the creation and management of 3D scenes and objects using React components, rather than plain HTML which allows developers to leverage React's ecosystem for state management, component reusability, effect management (through `useEffect`), and its DOM lifecycle (so as not to rely on the browser's events that signal certain phases of the document's life like `DOMContentLoaded`).\n",
    "\n",
    "But for now, we will push the limits of Three.js in Jupyter using Quarto. Let's continue by adding many more objects. Let's add more rubber duckies to the scene. Then we will make it rain rubber duckies, which will require the use of physics! \n",
    "\n",
    "## Multiple Objects in a Scene\n",
    "\n",
    "Previously we rendered separate scenes in a grid, now let's see how many ducks we can add to the same scene. \n",
    "\n",
    "Sure, we might think, let's just use `object.clone()` in the `OBJLoader` callback:\n",
    "\n",
    "```js\n",
    "// Clone the already loaded duck object\n",
    "const duckClone = object.clone();\n",
    "```\n",
    "\n",
    "But here's where we first stumble onto major performance issues in the browser. Depending on how much RAM our machine has, we will start noticing jittery behavior and slowed animations when we try to render `50` or more of these rubber duckies. Luckily, Three.js has an optimization for rendering multiple of the same object to the scene (even if they have to be animated differently). \n",
    "\n",
    "### InstancedMesh\n",
    "\n",
    "Instead of using `Mesh` we must used `InstancedMesh`. This optimization is called **instancing**. In Three.js this is implemented via the `InstancedMesh` class, as already mentioned, which lets us render many copies of the same geometry and material using a *single* draw call. Instead of creating a separate `Mesh` for each object, which incurs a draw call per object, we can create one `InstancedMesh` and assign each instance its own transformation matrix (and even per-instance colors, if needed). This technique reduces CPU-to-GPU communication overhead, making it ideal for rendering thousands of identical objects efficiently\n",
    "\n",
    "We don’t call `clone()` for each duck when using instancing. Instead, we create one `InstancedMesh` that shares the *same* geometry and material for every instance and then assign each instance its own transformation matrix. A transformation matrix is just what it sounds like, it's a matrix supplied to `InstancedMesh` that applies a rotation, a translation, and a scaling transform. This sounds like it's too complicated to come up with, after all is this a Linear Algebra exercise? But it's very simple, and there are a lot of tricks to help us do just that! \n",
    "\n",
    "`InstancedMesh` is basically an indexed data structure that stores *instances* of the `InstancedMesh`. These instances aren't directly accessible, unlike clones. However, we get the next best thing: an interface to update the transformation matrices of the instances (or other instance attributes, like color). We have the getter `getMatrixAt(index, matrix)`, and the setter `setMatrixAt(index, matrix)`.\n",
    "\n",
    "One question that may arise: Why does the getter require a `matrix` parameter? The design of the `getMatrixAt` method is such that we supply an existing `Matrix4` as a container. The method then writes the transformation matrix of the instance at index `i` into that provided matrix. \n",
    "Why use a $4 \\times 4$ matrix in 3D space? Refer to the subsection below on [homogeneous-coordinates](#homogeneous-coordinates---linearaffine-transformations). We should avoid creating a new `Matrix4` object on every call and, instead, re-use one `dummy.matrix`.\n",
    "\n",
    "Here's the code, feel free to expand and examine. We will also walk through the changes at the bottom.\n",
    "\n",
    "<details><summary>Click to expand</summary>\n",
    "\n",
    "```js\n",
    "// NEW CODE WILL GO HERE\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "`InstancedMesh` works with a single `geometry` and `material`.\n",
    "Since our OBJ is a group, we need to extract the mesh out of it in order to instance the mesh. \n",
    "\n",
    "The simplest way to do this is by taking the first mesh child `object.children[0]`.\n",
    "\n",
    "```js\n",
    "// Extract the mesh from OBJ\n",
    "const duckMesh = object.children[0];\n",
    "if (!duckMesh) {\n",
    "  console.error('Loaded object does not contain a mesh.');\n",
    "  return;\n",
    "}\n",
    "```\n",
    "But this produces nothing other than the duck's wingless body without eyes or a beak. So we have to merge the geometries. This is done using the Three.js add-on [BufferGeometryUtils.mergeBufferGeometries](https://threejs.org/docs/#examples/en/utils/BufferGeometryUtils.mergeBufferGeometries). This requires an understanding of the OBJ representation.\n",
    "\n",
    "#### The OBJ Representation of an Object\n",
    "\n",
    "When Three.js gets an OBJ file, it represents it as this `Group`. \n",
    "\n",
    "<details><summary>Click to expand pseudo-json with comments</details>\n",
    "\n",
    "```json\n",
    "Group {\n",
    "  \"children\": [\n",
    "    \"Mesh\": {\n",
    "      \"geometry\": \"BufferGeometry\" // See below for full expansion...\n",
    "      \"material\": \"Material\" // See below for full expansion...\n",
    "    },\n",
    "    \"Mesh\": {\n",
    "      \"geometry\": {\n",
    "        \"metadata\": { // Metadata provides info about the export\n",
    "          \"version\": 4.5, // Exporter version\n",
    "          \"type\": \"BufferGeometry\", // Type of object\n",
    "          \"generator\": \"BufferGeometry.toJSON\"// Method that generated this JSON\n",
    "        },\n",
    "        \"uuid\": \"12345678-1234-1234-1234-123456789abc\", // Unique identifier for this geometry\n",
    "        \"type\": \"BufferGeometry\", // Confirms that this is a BufferGeometry\n",
    "        \"data\": { // Main container for all geometry data\n",
    "          \"attributes\": { // Vertex attributes (data arrays for each vertex property)\n",
    "            \"position\": { // Positions of vertices\n",
    "              \"itemSize\": 3, // Each vertex position has 3 components: x, y, z\n",
    "              \"type\": \"Float32Array\", // Data stored as a Float32Array\n",
    "              \"array\": [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0], // Example vertex positions\n",
    "              \"normalized\": false // Data is not normalized\n",
    "            },\n",
    "            \"normal\": { // Normals at each vertex\n",
    "              \"itemSize\": 3, // 3 components per normal (x, y, z)\n",
    "              \"type\": \"Float32Array\",\n",
    "              \"array\": [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1], // Example normals\n",
    "              \"normalized\": false\n",
    "            },\n",
    "            \"uv\": { // Texture coordinates\n",
    "              \"itemSize\": 2, // Each UV coordinate has 2 components: u, v\n",
    "              \"type\": \"Float32Array\",\n",
    "              \"array\": [0, 0, 1, 0, 1, 1, 0, 1], // Example UV values\n",
    "              \"normalized\": false\n",
    "            }\n",
    "          },\n",
    "          \"index\": { // Index data defines the order to connect vertices into triangles\n",
    "            \"type\": \"Uint16Array\", // Data type of the index array\n",
    "            \"array\": [0, 1, 2, 0, 2, 3] // Indices forming triangles\n",
    "          },\n",
    "          \"groups\": [ // Groups specify portions of the geometry that use different materials\n",
    "            {\n",
    "              \"start\": 0, // Starting index in the index array for this group\n",
    "              \"count\": 6, // Number of indices (here, one quad made of 2 triangles)\n",
    "              \"materialIndex\": 0  // Which material from the material array should be used\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"material\": {\n",
    "        \"metadata\": { // Metadata about this material export\n",
    "          \"version\": 4.5, // Version of the exporter\n",
    "          \"type\": \"Object\", // This is a JSON object\n",
    "          \"generator\": \"Material.toJSON\" // Generated by Material.toJSON method\n",
    "        },\n",
    "        \"uuid\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\", // Unique ID for the material\n",
    "        \"type\": \"MeshStandardMaterial\", // Type of material (could be MeshBasicMaterial, etc.)\n",
    "        \"color\": 16777215, // Base color (in decimal, here 16777215 equals 0xffffff - white)\n",
    "        \"roughness\": 0.5, // Roughness parameter (controls how rough the surface is)\n",
    "        \"metalness\": 0.5, // Metalness parameter (how metallic the material looks)\n",
    "        \"emissive\": 0, // Emissive color (self-illumination; 0 means black, no emission)\n",
    "        \"opacity\": 1, // Opacity value (1 means fully opaque)\n",
    "        \"transparent\": false, // Flag indicating whether the material supports transparency\n",
    "        \"wireframe\": false, // If true, the material renders as a wireframe instead of solid\n",
    "        \"side\": 2 // Which side of the faces to render (2 indicates DoubleSide)\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  // Other group properties...\n",
    "}\n",
    "```\n",
    "\n",
    "</summary>\n",
    "\n",
    "In a `BufferGeometry`, the *index array*, which looks as below, is an optional array that defines how the vertices (stored in the attributes `\"position\"`) are connected to form faces (usually triangles). The indices (numbers) in an index array refer to vertices in the attributes.\n",
    "\n",
    "```json\n",
    "\"index\": {\n",
    "  \"type\": \"Uint16Array\",\n",
    "  \"array\": [0, 1, 2, 0, 2, 3]\n",
    "}\n",
    "```\n",
    "\n",
    "For example, if our geometry's `\"position\"` attribute contains the following vertices:\n",
    "\n",
    "```json\n",
    "\"position\": {\n",
    "  \"itemSize\": 3,\n",
    "  \"array\": [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n",
    "}\n",
    "```\n",
    "\n",
    "Then the index array above tells Three.js to use the vertices at positions `0, 1, 2` to form the first triangle, and vertices at positions `0, 2, 3` to form the second triangle.\n",
    "\n",
    "The *starting index* of the group refers to the *offset* in the index array where a specific group (which might be assigned a particular material) begins. The `\"group\"` defines a subset of the index array that should be rendered with a specific material.\n",
    "\n",
    "Now that we understand the structure of an object better, we can build a mesh merger that preserves materials.\n",
    "\n",
    "#### Merging Meshes while Preserving Materials\n",
    "\n",
    "We need to merge the child meshes while preserving each of their materials. Somehow, we have got to preserve information about which *parts* of the merged geometry should use which material. In Three.js this is done using `groups` inside a `BufferGeometry`. Each `group` defines a *start index*, a *count*, and a *material index*.\n",
    "When using `mergeBufferGeometries`, we pass a second parameter as `true` to tell the function to preserve the groups from each individual geometry. Then we supply a materials array (in the same order that the groups refer to) when we create the Mesh.\n",
    "\n",
    "Since merging meshes (while preserving the materials) is a thing we're going to do quite often, let's make a helper function called `mergeMeshes` that takes an array of `three.Mesh` objects, merges their geometries while preserving their material assignments via groups, and returns a single merged mesh. We'll store it as its own module and import it into our external scripts. Here's the implementation, see below it for an explanation of each step.\n",
    "\n",
    "```js\n",
    "import * as three from 'three';\n",
    "import { mergeBufferGeometries } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/utils/BufferGeometryUtils.js';\n",
    "\n",
    "/**\n",
    " * mergeMeshes accepts an array of three.Mesh objects and returns a single merged mesh.\n",
    " * It preserves each mesh's material by assigning groups to the merged geometry.\n",
    " *\n",
    " * @param {three.Mesh[]} meshes - Array of meshes to merge.\n",
    " * @returns {three.Mesh} - A new mesh that is the merged result.\n",
    " */\n",
    "function mergeMeshes(meshes) {\n",
    "  // Arrays to hold the individual geometries and their corresponding materials.\n",
    "  const geometries = [];\n",
    "  const materials = [];\n",
    "  \n",
    "  // materialIndex will be used to assign a unique material index for each mesh.\n",
    "  let materialIndex = 0;\n",
    "  \n",
    "  // Loop through each mesh in the input array.\n",
    "  meshes.forEach((mesh) => {\n",
    "    // 1. Update the world matrix so that we capture the mesh's global transformation.\n",
    "    mesh.updateWorldMatrix(true, false);\n",
    "\n",
    "    // 2. Clone the mesh's geometry so we don't modify the original.\n",
    "    const geom = mesh.geometry.clone();\n",
    "\n",
    "    // 3. Apply the mesh's world transformation to the geometry. This \"bakes\" the mesh's position, rotation, and scale into its vertices.\n",
    "    geom.applyMatrix4(mesh.matrixWorld);\n",
    "\n",
    "    // 4. If the geometry doesn't already have groups defined (which tell us which part uses which material),\n",
    "    //    we add a single group that covers the whole geometry.\n",
    "    //    This group assigns a material index that corresponds to the mesh's material in our materials array.\n",
    "    if (geom.groups.length === 0) {\n",
    "      // Determine the number of elements (either from the index count or the vertex count)\n",
    "      const count = geom.index ? geom.index.count : geom.attributes.position.count;\n",
    "      // Add a group from start=0 to count with the current material index.\n",
    "      geom.addGroup(0, count, materialIndex);\n",
    "    }\n",
    "\n",
    "    // 5. Push the processed geometry and the mesh's material into our arrays.\n",
    "    geometries.push(geom);\n",
    "    materials.push(mesh.material);\n",
    "    materialIndex++;\n",
    "  });\n",
    "\n",
    "  // 6. Merge all the geometries into a single BufferGeometry.\n",
    "  //    The second argument 'true' tells the function to preserve the groups from each geometry.\n",
    "  const mergedGeometry = mergeBufferGeometries(geometries, true);\n",
    "\n",
    "  // 7. Create a new Mesh using the merged geometry and the array of materials.\n",
    "  //    THREE.Mesh accepts an array of materials when the geometry contains groups with material indices.\n",
    "  const mergedMesh = new THREE.Mesh(mergedGeometry, materials);\n",
    "  \n",
    "  // Return the merged mesh.\n",
    "  return mergedMesh;\n",
    "}\n",
    "```\n",
    "\n",
    "First, inside the loop that iterates over each child mesh, we update the mesh's `matrixWorld`. Calling `mesh.updateWorldMatrix(true, false)` ensures that the mesh’s **global transformation** (its position, rotation, and scale) is up-to-date. In short, updating the world matrix is necessary so that the transformation we apply to the geometry truly represents the mesh’s position, rotation, and scale within the entire scene. Each mesh as its own **local transformation** (which is exclusively applied to it), but meshes can also be in a group with its own local transformation. The final transformation, the `matrixWorld`, is the application of all these local transformation matrices. Calling `mesh.updateWorldMatrix(true, false)` just ensures this calculation is up-to-date.\n",
    "\n",
    "```js\n",
    "mesh.updateWorldMatrix(true, false);\n",
    "```\n",
    "It's good practice to clone the mesh's geometry so that we don't alter the original.\n",
    "\n",
    "```js\n",
    "const geom = mesh.geometry.clone();\n",
    "```\n",
    "\n",
    "Note that earlier we cloned the entire object with [three.Object3D.clone](https://threejs.org/docs/#api/en/core/Object3D.clone), but now we're cloning just the geometry of the mesh using [three.BufferGeometry.clone](https://threejs.org/docs/#api/en/core/BufferGeometry.clone).\n",
    "\n",
    "Next step is to apply the updated world matrix (transformation) by calling `geom.applyMatrix4(mesh.matrixWorld)`. This is known as *baking-in* the mesh's world transformation into the geometry. Don't get discouraged if you don't understand transformations, all that these transformations mean, essentially, is that the vertices of the geometry are moved to their correct positions in the world space.\n",
    "\n",
    "```js\n",
    "geom.applyMatrix4(mesh.matrixWorld);\n",
    "```\n",
    "\n",
    "We then assign groups (if absent). Groups in `BufferGeometry` indicate which sections of the geometry use which material. If a mesh’s geometry doesn’t already have groups, we add one covering the entire geometry and assign it the current *material index*. This is essential for preserving different materials when the geometries are merged.\n",
    "\n",
    "\n",
    "\n",
    "1. **Collect Geometries and Materials:**  \n",
    "   We store each processed geometry and its corresponding material in separate arrays. The order is important because the group’s material index in each geometry will correspond to the position of the material in the `materials` array.\n",
    "\n",
    "2. **Merge Geometries:**  \n",
    "   `mergeBufferGeometries(geometries, true)` merges all collected geometries into a single geometry, preserving the groups. This is what reduces the number of draw calls during rendering.\n",
    "\n",
    "3. **Create Merged Mesh:**  \n",
    "   Finally, we create a new THREE.Mesh with the merged geometry and the array of materials. The merged geometry’s groups ensure that the correct material is used for each part of the merged mesh.\n",
    "\n",
    "You can now call this function with any array of meshes (for example, the children of a loaded OBJ) to obtain a single, optimized mesh with preserved materials.\n",
    "\n",
    "----- I AM HERE -----\n",
    "\n",
    "\n",
    "Once we have the mesh extracted out of the OBJ, we create an `InstancedMesh` with `numDuckies` number of ducks, and supplying the mesh `geometry` and `material`.\n",
    "\n",
    "```js\n",
    "const numDuckies = 200;\n",
    "\n",
    "// Create an InstancedMesh using the duck's geometry and material.\n",
    "const instancedDuck = new three.InstancedMesh(\n",
    "  duckMesh.geometry,\n",
    "  duckMesh.material,\n",
    "  numDuckies\n",
    ");\n",
    "```\n",
    "As we would do with regular objects (like clones), we need to add the `InstancedMesh` to the scene using:\n",
    "\n",
    "```js\n",
    "scene.add(instancedDuck);\n",
    "```\n",
    "The next step involves an industry trick. Instead of coming up with a transformation matrix ourselves, we create a `dummy` object and use its `.position.set(x,y,z)` as always. We give it some rotation (like before). Then we do `.updateMatrix()` and use its `.matrix` to *get* the object's transformation matrix. \n",
    "\n",
    "Once we have this `dummy` object's transformation matrix, we provide it to the `.setMatrixAt(index, matrix)` method of the `InstancedMesh`.\n",
    "\n",
    "```js\n",
    "// Create a dummy Object3D to build transformation matrices.\n",
    "const dummy = new three.Object3D();\n",
    "\n",
    "// Initialize each instance with a random position and rotation.\n",
    "for (let i = 0; i < numDuckies; i++) {\n",
    "  dummy.position.set(\n",
    "    randInRange(-30, 30),\n",
    "    randInRange(-30, 30),\n",
    "    randInRange(-30, 30)\n",
    "  );\n",
    "  dummy.rotation.y = randInRange(0, Math.PI * 2);\n",
    "  dummy.updateMatrix();\n",
    "  instancedDuck.setMatrixAt(i, dummy.matrix);\n",
    "}\n",
    "```\n",
    "Finally, we need to update the `animate()` function to apply a $y$-rotation to each individual instance. This is where `matrix.decompose(position, rotation, scale)` comes in. It does what it sounds like it does! It decomposes a $4 \\times 4$ transformation matrix into its constituent transformations: capturing the translation, rotation, and scale.\n",
    "\n",
    "```js\n",
    "// Animate: update rotation for each instance.\n",
    "function animate(time) {\n",
    "  requestAnimationFrame(animate);\n",
    "\n",
    "  // Rotate each duck around its own y-axis.\n",
    "  for (let i = 0; i < numDuckies; i++) {\n",
    "    // Retrieve the current matrix of instance i.\n",
    "    instancedDuck.getMatrixAt(i, dummy.matrix);\n",
    "    // Decompose the matrix into position, rotation, and scale.\n",
    "    dummy.matrix.decompose(dummy.position, dummy.rotation, dummy.scale);\n",
    "    // Increment the rotation.\n",
    "    dummy.rotation.y += 0.01;\n",
    "    // Update the dummy's matrix.\n",
    "    dummy.updateMatrix();\n",
    "    // Set the new matrix for instance i.\n",
    "    instancedDuck.setMatrixAt(i, dummy.matrix);\n",
    "  }\n",
    "  // Mark the instance matrix attribute as needing an update.\n",
    "  instancedDuck.instanceMatrix.needsUpdate = true;\n",
    "  renderer6.render(scene6, camera6);\n",
    "}\n",
    "```\n",
    "\n",
    "### Homogeneous Coordinates - Linear/Affine Transformations \n",
    "\n",
    "Why do 3D graphics use a $4 \\times 4$ matrix (`Matrix4`) rather than a $3 \\times 3$ matrix to represent transformations in 3D space? A $3 \\times 3$ matrix can handle linear transformations like rotation and scaling, but it cannot handle affine transformations like a simple translation. It also can't handle projection (**perspective** or **orthogonal** -- corresponding to non-linear and linear transformations). \n",
    "\n",
    "The $4 \\times 4$ matrix incorporates an extra row and column that stores the translation (or projection) components, enabling *all* simple transformations to be combined into one matrix. This makes it very efficient for computer graphics since we can apply a single matrix to transform an object in 3D space, reducing the number of required matrix operations. \n",
    "\n",
    "The use of a $4 \\times 4$ matrix necessitates the use of **homogeneous coordinates** (which all 3D libraries do under the hood). This is when the normal $(x,y,x)$ coordinates are augmented as $(x,y,z,w)$ (where $w$ is an extra coordinate that's $1$ by default). Let's see how this helps.\n",
    "Suppose we want to translate a point by $(t_x, t_y, t_z)$. In homogeneous coordinates, the translation matrix is:\n",
    "\n",
    "$$\n",
    "T = \\begin{pmatrix}\n",
    "1 & 0 & 0 & t_x \\\\\n",
    "0 & 1 & 0 & t_y \\\\\n",
    "0 & 0 & 1 & t_z \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Now, take a point $P$ represented as:\n",
    "\n",
    "$$\n",
    "P = \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "When we apply the translation matrix (identity transformation) to the point, we multiply:\n",
    "\n",
    "$$\n",
    "T P = \\begin{pmatrix}\n",
    "1 & 0 & 0 & t_x \\\\\n",
    "0 & 1 & 0 & t_y \\\\\n",
    "0 & 0 & 1 & t_z \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x + t_x \\\\\n",
    "y + t_y \\\\\n",
    "z + t_z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This shows that the point $(x, y, z)$ is translated to $(x+t_x, y+t_y, z+t_z)$. We simply mentally discard the extra coordinate.\n",
    "\n",
    "In summary, the extra coordinate $w$ in homogeneous coordinates enables us to include translation (and projection) in the *same* framework as other transformations.\n",
    "\n",
    "-----\n",
    "\n",
    "```js\n",
    "// An array to store our duck clones\n",
    "const duckClones = [];\n",
    "\n",
    "// The number of duckies we want\n",
    "const numDuckies = 50;\n",
    "\n",
    "// Function to generate a random number in a provided range\n",
    "function randInRange(min, max) {\n",
    "  return Math.random() * (max - min) + min;\n",
    "}\n",
    "\n",
    "for (let i = 0; i < numDuckies; i++) {\n",
    "  // Clone the loaded duck object\n",
    "  const duckClone = object.clone();\n",
    "\n",
    "  // Randomize position (for example, within a certain X/Z range and different Y values)\n",
    "  duckClone.position.set(\n",
    "    randInRange(-50, 50),  // Random x position between (-50,50)\n",
    "    randInRange(0, 20),    // Random y position \n",
    "    randInRange(-50, 50)   // Random z position\n",
    "  );\n",
    "\n",
    "  // Optionally, randomize rotation so they face different directions.\n",
    "  duckClone.rotation.y = randInRange(0, Math.PI * 2);\n",
    "\n",
    "  // Add the clone to the scene and our array.\n",
    "  scene.add(duckClone);\n",
    "  duckClones.push(duckClone);\n",
    "};\n",
    "```\n",
    "\n",
    "This is a good time to make an effort to understand the coordinate system in Three.js. How do we know which specific range of positions to supply `randInRange`? We can actually display the axes and coordinate grid. Click the note below to see how.\n",
    "\n",
    "::: {.callout-tip title=\"💡 TIP: Displaying `AxesHelper` and `GridHelper` in the Scene\" appearance=\"minimal\" collapse=\"true\"}\n",
    "\n",
    "The `AxesHelper` displays lines for the x, y, and z axes (typically colored red, green, and blue, respectively). For example:\n",
    "\n",
    "```js\n",
    "// An AxesHelper with a size of 50 units\n",
    "const axesHelper = new three.AxesHelper(50);\n",
    "scene.add(axesHelper);\n",
    "```\n",
    "This helper will render lines originating from the scene’s origin $(0, 0, 0)$, so we can visually see how objects are positioned relative to it.\n",
    "\n",
    "If we want an additional visual cue that represents a grid on the ground (helpful for orienting objects in a scene), we can use the `GridHelper`:\n",
    "\n",
    "```js\n",
    "// A GridHelper with a grid size of 100 and 10 divisions\n",
    "const gridHelper = new three.GridHelper(100, 10);\n",
    "scene.add(gridHelper);\n",
    "```\n",
    "\n",
    "Finally, if our grid or axes are not showing up it may be due to the camera's position. We can point the camera to any vector!\n",
    "\n",
    "```js\n",
    "camera.lookAt(new three.Vector3(0, 0, 0));\n",
    "```\n",
    ":::\n",
    "\n",
    "Let's create another canvas for our new scene!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas-6'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas-6'></canvas>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manim-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
