{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Three.js - 3D Animations in the Browser\"\n",
    "author: \"Vahram Poghosyan\"\n",
    "date: \"2024-12-26\"\n",
    "categories: [\"Three.js\", \"Visualization\", \"JavaScript\"]\n",
    "format:\n",
    "  html:\n",
    "    css: ./css/three-js-demo.css\n",
    "    code-fold: false\n",
    "toc-depth: 4\n",
    "jupyter: python3\n",
    "highlight-style: github\n",
    "include-after-body:\n",
    "  text: |\n",
    "    <script type=\"application/javascript\" src=\"../../../javascript/light-dark.js\"></script>\n",
    "    <script type=\"importmap\">\n",
    "      {\n",
    "          \"imports\": {\n",
    "              \"three\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/+esm\",\n",
    "              \"OBJLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js\",\n",
    "              \"MTLLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js\",\n",
    "              \"OrbitControls\": \"https://cdn.skypack.dev/three@0.133.0/examples/jsm/controls/OrbitControls.js\",\n",
    "              \"Cannon\": \"https://cdn.jsdelivr.net/npm/cannon-es@0.20.0/dist/cannon-es.js\"\n",
    "          }\n",
    "      }\n",
    "    </script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-grid-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-duck-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-many-ducks-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-many-ducks-physics-demo.js\"></script>\n",
    "    <script type=\"module\" src=\"./javascript/three-js-shader-demo.js\"></script>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this post we use [Three.js](https://threejs.org/) external scripts to render 3D scenes inside this Jupyter notebook. \n",
    "\n",
    "This post will be very similar, in terms of its stack, to the [D3.js interactive US map post](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb).\n",
    "\n",
    "In *that* post, we learned that Canvas and SVG are two ways in which we can display complex graphics inside a web browser. We already explored SVG graphics in [D3.js interactive US map](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb). It's worth noting that a lot of the same functionality could've been replicated using the HTML Canvas element instead of SVG (which we ultimately chose for its superior interactive capabilities) -- the article mentions one way to do that by using [skia-canvas](https://github.com/samizdatco/skia-canvas). \n",
    "\n",
    "We ended up using [linkedom](https://github.com/WebReflection/linkedom#readme) to add a DOM API on top of the Deno environment. \n",
    "\n",
    "In fact, what I realized later on is that we could've simply used the Markdown inside our Jupyter notebook to create the `<svg>` element without the need to introduce a third-party DOM API on top of a browser-less JavaScript environment (Deno). Then, we could have simply fetched the `TopoJSON` data and constructed the map inside our external scripts with the rest of the complex D3 animations that had to be added as external scripts. \n",
    "These scripts are run by Quarto only *after* the page has been rendered to the browser, so we can easily reference the DOM elements we create inside our notes by `class` or `id`. Crucially, the external scripts are meant to run *inside the browser* (as opposed to being pre-computed in the browser-less Deno environment). Inside the browser they're able to leverage the existing DOM API provided by the browser's engine (e.g. `document.getElementById`). Hence, this way, we eliminate the need for Deno as well as Linkedom.\n",
    "\n",
    "We will use the [IPython.display](https://ipython.readthedocs.io/en/8.26.0/api/generated/IPython.display.html) module to create HTML elements inside our notes rather than just using Markdown directly.\n",
    "\n",
    "# Three.js, WebGL, and the Canvas Element\n",
    "\n",
    "[Three.js](https://threejs.org/) is a library for drawing 3D graphics in the browser using JavaScript and [WebGL](https://get.webgl.org/) (see [wiki](https://www.khronos.org/webgl/wiki/Main_Page)). One excellent resource for learning WebGL is the [WebGLFundamentals](https://webglfundamentals.org/webgl/lessons) website.\n",
    "\n",
    "WebGL runs in an HTML Canvas (i.e. `<canvas>`). \n",
    "\n",
    "From the WebGL wiki: \n",
    "\n",
    "> WebGL is a DOM API, which means that it can be used in any DOM-compatible language: e.g. JavaScript\n",
    "\n",
    "Three.js is a library that provides conveniences in JavaScript that abstract much of this [WebGL](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API) DOM API calls behind friendlier JavaScript code. \n",
    "\n",
    "Note that WebGL and Canvas API are two distinct ways in which the browser draws graphics, but they both require and HTML Canvas to draw on. Three.js offers a WebGL renderer as well as a Canvas renderer. Canvas API is usually a fallback option for when WebGL, the more powerful of the two APIs, isn't available. \n",
    "\n",
    "Note, also, that Three.js isn't suitable for modelling purposes, for that we can use [Blender](https://www.blender.org/) or a number of other closed-source 3D modelling applications. We can even download or purchase third-party models from vendors.\n",
    "\n",
    "Canvas and SVG elements are two ways in which we can display complex graphics inside a web browser. We already explored SVG graphics in the [D3.js interactive US Map](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb) post. It's worth noting that a lot of the same functionality could've been achieved by using the HTML Canvas element with D3.js instead. The post above mentions one way to do that by using [skia-canvas](https://github.com/samizdatco/skia-canvas). \n",
    "\n",
    "However, in this post, we use Three.js (not D3.js), to draw inside an HTML Canvas element (rather than an HTML SVG element) using WebGL (as opposed to the Canvas API).\n",
    "\n",
    "# 3D Scenes - A Primer\n",
    "\n",
    "In *any* 3D scene, be it in the web browser, inside a game engine, in a movie, in a 3D modelling application, etc. there are a bunch of **geometries**, or **shapes** that are packaged with **materials** as **meshes**. The materials can describe simple properties like reflectivity, opacity, refraction index, etc. or they can be  **textures** which are just simple [raster](https://en.wikipedia.org/wiki/Raster_graphics) images. We can also apply **shaders** to our objects, which are complex mappings of pixels (or vertices) that make up an interesting animation.\n",
    " \n",
    "A scene will also have one or more **light sources**, and a **camera** to *serve* the scene in some perspective.\n",
    "\n",
    "## Meshes, Objects, Geometries, and Materials\n",
    "\n",
    "An `object`, for the foreseeable future, means an object file of the [OBJ Wavefront format](https://en.wikipedia.org/wiki/Wavefront_.obj_file). These are files that consist of `object.children[n].geometry` and `object.children[n].material` fields. However, the material fields inside an OBJ are just *references* (via `usemtl` statements) to the true materials which come separately in `.mtl` files (typically from the same place as the `.obj` file).\n",
    "\n",
    "There's usually no need to break the object down into individual child geometries and their corresponding objects. But, it's certainly possible. One use case would be if we want to apply a different transformation to each component. Usually, however, we load the object as a whole.\n",
    "\n",
    "# Our First Scene\n",
    "\n",
    "Let's create a `<canvas>` with `id=\"three-d-canvas\"`.\n",
    "\n",
    "We can do it either using raw markup below this very cell, or by using the `IPython.display` module which allows us to display rich representations of objects in a Jupyter notebook (much like the `Deno.jupyter.display` module we saw in the [D3.js US map post](../d3_in_jupyter_with_deno/d3_js_in_jupyter_with_deno.ipynb)).\n",
    "\n",
    "Using `IPython.display` is more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas'></canvas>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code that produces the above output. Feel free to expand and examine. We will paint the general strokes below.\n",
    "\n",
    "<details><summary>Click to expand the Torus code</summary>\n",
    "```javascript\n",
    "import * as three from 'https://cdn.jsdelivr.net/npm/three@0.173.0/+esm'\n",
    "\n",
    "const scene = new three.Scene();\n",
    "\n",
    "const body = document.getElementById(\"quarto-document-content\");\n",
    "const bodyWidth = body.clientWidth;\n",
    "const bodyHeight = 600;\n",
    "\n",
    "const canvas = document.getElementById(\"three-d-canvas\")\n",
    "\n",
    "const camera = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "camera.position.setZ(30);\n",
    "\n",
    "const renderer = new three.WebGLRenderer({\n",
    "    canvas: canvas\n",
    "});\n",
    "\n",
    "renderer.setPixelRatio( window.devicePixelRatio );\n",
    "renderer.setSize( bodyWidth, bodyHeight );\n",
    "\n",
    "\n",
    "renderer.render(scene, camera);\n",
    "\n",
    "const geometry = new three.TorusGeometry(10,3,16,100);\n",
    "const material = new three.MeshBasicMaterial({ color: 0xFF6347, wireframe: true });\n",
    "const torus = new three.Mesh(geometry, material);\n",
    "\n",
    "scene.add(torus);\n",
    "\n",
    "function animate() {\n",
    "    requestAnimationFrame(animate);\n",
    "\n",
    "    torus.rotation.x += 0.01;\n",
    "    torus.rotation.y += 0.005;\n",
    "    torus.rotation.z += 0.01;\n",
    "\n",
    "    renderer.render(scene, camera);\n",
    "}\n",
    "\n",
    "animate();\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice some general strokes.\n",
    "\n",
    "## Creating a Scene\n",
    "\n",
    "First, we create a `three.Scene` object.\n",
    "\n",
    "```js\n",
    "const scene = new three.Scene();\n",
    "```\n",
    "## Defining Scene Properties and Selecting a Canvas\n",
    "\n",
    "Then, we define some constants for Three.js's [WebGLRenderer](https://threejs.org/docs/#api/en/renderers/WebGLRenderer) relative to the HTML document's body (grabbing the latter using the DOM API).\n",
    "\n",
    "```js\n",
    "const body = document.getElementById(\"quarto-document-content\");\n",
    "const bodyWidth = body.clientWidth;\n",
    "const bodyHeight = 600;\n",
    "```\n",
    "\n",
    "We then grab the `<canvas>` element we created.\n",
    "\n",
    "```js\n",
    "const canvas = document.getElementById(\"three-d-canvas\")\n",
    "```\n",
    "\n",
    "## Creating a Camera\n",
    "\n",
    "After defining scene properties, we create a [PerspectiveCamera](https://threejs.org/docs/#api/en/cameras/PerspectiveCamera), supplying it the [field of view](https://en.wikipedia.org/wiki/Field_of_view) among other attributes, and setting its position.\n",
    "\n",
    "```js\n",
    "const camera = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "camera.position.setZ(30);\n",
    "```\n",
    "## Creating a WebGL Renderer\n",
    "\n",
    "We then create the `WebGLRenderer` object, supplying it the `canvas` to render, as well as setting some of its parameters to the constants we defined in step one.\n",
    "\n",
    "```js\n",
    "const renderer = new three.WebGLRenderer({\n",
    "    canvas: canvas\n",
    "});\n",
    "renderer.setPixelRatio( window.devicePixelRatio );\n",
    "renderer.setSize( bodyWidth, bodyHeight );\n",
    "```\n",
    "\n",
    "### How Does a Renderer Work?\n",
    "\n",
    "A renderer such as WebGL uses [ray-marching](https://en.wikipedia.org/wiki/Ray_marching) and [signed distance functions](https://en.wikipedia.org/wiki/Signed_distance_function) (SDFs) to render a scene. \n",
    "\n",
    "At a very high level, there's a plane that represents what the camera sees. This is what's displayed on our 2D screens, the plane maps to pixels on our screen. A \"ray\" is cast through each pixel and the ray marching algorithm determines which object in our 3D scene the ray intersects with first. This will determine which object is on the foreground and which in the background (the pixel will be colored according to this determination). \n",
    "\n",
    "Each point on the ray has a known coordinate in 3D space. Each object in our 3D scene also has a known position in the coordinate system (i.e. all of its vertices/edges are not unknowns). For each object, the distance between a point $p$ on the ray and the boundary of the object is calculated using a *signed distance function* (as mentioned before). These functions depend on the geometry. They are known for some primitive geometries (and their unions/intersections). A comprehensive list of SDFs is available [here](https://iquilezles.org/articles/distfunctions/). \n",
    "\n",
    "The point $p$ on the ray is marched only as far as the distance between the previous $p$ iterate (say $p^-$) and the closest object to it in the 3D scene (call this object $A$). This guarantees that there are no collisions with any of the *other* objects for point $p$ moving on the ray. So, $p$ is marched that far. Then, $p$ is updated again in the same way, iteratively. Eventually point $p$ touches an object (the object that intersects with the ray *first*) -- in the limit. In practice, we can stop after some $K$ iterations or when the distance $d(p, A)$ -- where $A$ is the nearest object -- is sufficiently small (i.e. less than some $\\Epsilon$). \n",
    "\n",
    "If the ray misses, the corresponding pixel is rendered as background (for example, the color the sky). In contrast, the objects the ray hits are colored according to their distance from the pixel on the screen (according to a greyscale, for example). \n",
    "\n",
    "In this article we just focus on the high-level implementations in Three.js, so all of this is abstracted behind WebGL and further abstracted behind Three.js. However, in the future it may be nice to program a rudimentary renderer from scratch...\n",
    "\n",
    "## Rendering the Scene and Adding Objects\n",
    "\n",
    "Finally, we render the scene by invoking the renderer's `.render(scene, camera)`.\n",
    "\n",
    "```js\n",
    "renderer.render(scene, camera);\n",
    "```\n",
    "\n",
    "The `scene` object continues to be our window into the 3D world we just created. To it, we add `geometries` and their `materials` through a combination object called a [Mesh](https://threejs.org/docs/#api/en/objects/Mesh).\n",
    "\n",
    "```js\n",
    "const geometry = new three.TorusGeometry(10,3,16,100);\n",
    "const material = new three.MeshBasicMaterial({ color: 0xFF6347, wireframe: true });\n",
    "const torus = new three.Mesh(geometry, material);\n",
    "\n",
    "scene.add(torus);\n",
    "```\n",
    "\n",
    "## Adding Simple Animations\n",
    "\n",
    "We can also add a little life to the scene by using a custom animation function.\n",
    "```js\n",
    "function animate() {\n",
    "    requestAnimationFrame(animate);\n",
    "\n",
    "    torus.rotation.x += 0.01;\n",
    "    torus.rotation.y += 0.005;\n",
    "    torus.rotation.z += 0.01;\n",
    "\n",
    "    renderer.render(scene, camera);\n",
    "}\n",
    "```\n",
    "We invoke the animation within the outer lexical environment (for now).\n",
    "\n",
    "```\n",
    "animate();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Displaying Multiple Scenes\n",
    "\n",
    "To display multiple 3D `scenes` in a grid, we can simply use a CSS-grid inside Jupyter.\n",
    "\n",
    "First we lay out the markup inside the notes:\n",
    "\n",
    "```html\n",
    "<div class=\"three-d-grid-container\">\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-1\"></canvas></div>\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-2\"></canvas></div>\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-3\"></canvas></div>\n",
    "    <div class=\"three-d-grid-item\"><canvas id=\"three-d-canvas-4\"></canvas></div>\n",
    "</div>\n",
    "```\n",
    "\n",
    "Then, we include the stylesheet in this post's subdirectory, and use Quarto's front-matter to load it into the browser (just as we load the external scripts used to produce these rich 3D outputs):\n",
    "\n",
    "```yaml\n",
    "include-after-body:\n",
    "    <script type=\"module\" src=\"./javascript/three-js-demo.js\"></script>\n",
    "```\n",
    "\n",
    "It turns out that there's support for including CSS inside a Quarto post. It's done using the `format.html` flag in the front-matter as follows:\n",
    "\n",
    "```yaml\n",
    "format:\n",
    "  html:\n",
    "    css: ./css/three-js-demo.css\n",
    "```\n",
    "\n",
    "The file `three-js-demo.css` should contain these minimal styles: \n",
    "\n",
    "```css\n",
    "#three-d-grid-container {\n",
    "    display: grid;\n",
    "    grid-template-columns: repeat(2, 1fr);\n",
    "    grid-template-rows: repeat(2, 1fr);\n",
    "    gap: 10px;\n",
    "    width: 100%;\n",
    "    height: 50%;\n",
    "}\n",
    ".three-d-grid-item {\n",
    "    display: flex;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the grid markup.\n",
    "\n",
    "Now, inside the external script, we can reference the various `canvas` elements by `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id='three-d-grid-container'>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-1\"><canvas id=\"three-d-canvas-1\"></canvas></div>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-2\"><canvas id=\"three-d-canvas-2\"></canvas></div>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-3\"><canvas id=\"three-d-canvas-3\"></canvas></div>\n",
       "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-4\"><canvas id=\"three-d-canvas-4\"></canvas></div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\n",
    "    \"\"\"\n",
    "    <div id='three-d-grid-container'>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-1\"><canvas id=\"three-d-canvas-1\"></canvas></div>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-2\"><canvas id=\"three-d-canvas-2\"></canvas></div>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-3\"><canvas id=\"three-d-canvas-3\"></canvas></div>\n",
    "        <div class=\"three-d-grid-item\" id=\"three-d-grid-item-4\"><canvas id=\"three-d-canvas-4\"></canvas></div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Custom Objects with Materials\n",
    "\n",
    "Quarto won't serve `.obj` files (at least by default), so we can just commit the object file to the remote repository and use the `raw` GitHub link (as a CDN).\n",
    "\n",
    "We will also need the `OBJLoader`, a Three.js add-on. This can be grabbed from a CDN as well. We may also include it in the `include-after-body.text` front matter *before* loading the script file itself as:\n",
    "\n",
    "```yaml\n",
    "<script type=\"importmap\">\n",
    "    {\n",
    "        \"imports\": {\n",
    "            \"three\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/+esm\",\n",
    "            \"OBJLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js\"\n",
    "        }\n",
    "    }\n",
    "</script>\n",
    "```\n",
    "And then, within the script, import as follows:\n",
    "\n",
    "```js\n",
    "import * as three from 'three';\n",
    "import { OBJLoader } from 'OBJLoader';\n",
    "```\n",
    "\n",
    "Here's the full code to render a rubber ducky which will help us in debugging our code going forward! I downloaded this model from [Sketchfab](https://sketchfab.com/3d-models/rubber-duck-ecb9ce9ff973406398ee56e391f9c902) which hosts many such free models.\n",
    "\n",
    "### Creating a Skybox\n",
    "\n",
    "We can also create a sky background (using what's known as a *skybox*). This can be done in several ways, the most unsophisticated of which is to add a simple gradient background. \n",
    "\n",
    "Going one step further, we can add a skybox (a [cubemap](https://threejs.org/docs/#api/en/loaders/CubeTextureLoader)). \n",
    "\n",
    "```js\n",
    "const loader = new three.CubeTextureLoader();\n",
    "const skyboxTexture = loader.load([\n",
    "  'px.jpg', // Right\n",
    "  'nx.jpg', // Left\n",
    "  'py.jpg', // Top\n",
    "  'ny.jpg', // Bottom\n",
    "  'pz.jpg', // Front\n",
    "  'nz.jpg'  // Back\n",
    "]);\n",
    "\n",
    "// Set the scene's background to `skyboxTexture`\n",
    "scene.background = skyboxTexture;\n",
    "```\n",
    "\n",
    "Here's a [convenient tool](https://jaxry.github.io/panorama-to-cubemap/) that lets us convert a 360$^{\\circ}$ image of a sky into a cubemap. We can also download existing cubemaps from the internet. One place to get them is [Poly Haven's HDRI section](https://polyhaven.com/a/lilienstein). We can download any sky HDRs and use [this awesome tool](https://matheowis.github.io/HDRI-to-CubeMap/) which converts the HDR file into six separate textures which can be supplied to the `loader.load()` call above.\n",
    "\n",
    "Then, [CubeCamera](https://threejs.org/docs/#api/en/cameras/CubeCamera) is used to render the skybox images. This camera exists independently of the main camera in our scene. The `CubeCamera` uses what's known as a [render target](https://webglfundamentals.org/webgl/lessons/webgl-render-to-texture.html) (a buffer where the GPU draws pixels for a scene that is being rendered in the background). Our `CubeCamera` will use [WebGLCubeRenderTarget](https://threejs.org/docs/index.html#api/en/renderers/WebGLRenderTarget) to render the skybox images.\n",
    "\n",
    "```js\n",
    "// Create the CubeRenderTarget and CubeCamera\n",
    "const cubeRenderTarget = new three.WebGLCubeRenderTarget(512);\n",
    "const cubeCamera = new three.CubeCamera(1, 1000, cubeRenderTarget);\n",
    "\n",
    "// Add CubeCamera to the scene\n",
    "scene.add(cubeCamera);\n",
    "```\n",
    "\n",
    "We also have the option to use the `Sky` class that's built into Three.js to generate a procedural sky. The `Sky` class is a separate import accessible at the CDN address:\n",
    "\n",
    "```html\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/three@0.132.2/examples/js/objects/Sky.js\"></script>\n",
    "```\n",
    "However, this is beyond the scope of this post.\n",
    "\n",
    "### Loading the Object\\\n",
    "\n",
    "Here's the final code snippet that produces the scene below. \n",
    "\n",
    "<details><summary> Click to expand the code used to generate the rubber ducky</summary>\n",
    "\n",
    "```js\n",
    "import * as three from 'https://cdn.jsdelivr.net/npm/three@0.173.0/build/three.module.js';\n",
    "import { OBJLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js';\n",
    "import { MTLLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js';\n",
    "\n",
    "// Get the container and set dimensions\n",
    "const body = document.getElementById(\"quarto-document-content\");\n",
    "const bodyWidth = body.clientWidth;\n",
    "const bodyHeight = 600;\n",
    "\n",
    "// Set up the canvas, scene, camera, and renderer\n",
    "const canvas = document.getElementById(\"three-d-canvas\");\n",
    "const scene = new three.Scene();\n",
    "const camera = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "const renderer = new three.WebGLRenderer({ canvas: canvas });\n",
    "renderer.setPixelRatio(window.devicePixelRatio);\n",
    "renderer.setSize(bodyWidth, bodyHeight);\n",
    "\n",
    "// Position the camera so the object will be in view.\n",
    "camera.position.set(0, 20, 0);\n",
    "\n",
    "// Add some lights so the materials are visible.\n",
    "const ambientLight = new three.AmbientLight(0xffffff, 0.6);\n",
    "scene.add(ambientLight);\n",
    "\n",
    "const directionalLight = new three.DirectionalLight(0xffffff, 0.8);\n",
    "directionalLight.position.set(10, 20, 10);\n",
    "scene.add(directionalLight);\n",
    "\n",
    "// Add a skybox\n",
    "const loader = new three.CubeTextureLoader();\n",
    "const px = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/px.png'\n",
    "const nx = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/nx.png'\n",
    "const py = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/py.png'\n",
    "const ny = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/ny.png'\n",
    "const pz = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/pz.png'\n",
    "const nz = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/nz.png'\n",
    "const texture = loader.load([\n",
    "  px, // Right\n",
    "  nx, // Left\n",
    "  py, // Top\n",
    "  ny, // Bottom\n",
    "  pz, // Front\n",
    "  nz  // Back\n",
    "]);\n",
    "// Set the scene's background to `texture`\n",
    "scene.background = texture;\n",
    "// Create the CubeRenderTarget\n",
    "const cubeRenderTarget = new three.WebGLCubeRenderTarget(512);\n",
    "const cubeCamera = new three.CubeCamera(1, 1000, cubeRenderTarget);\n",
    "scene.add(cubeCamera);\n",
    "\n",
    "// Instantiate MTLLoader and define the URLs for the material and object.\n",
    "const mtlLoader = new MTLLoader();\n",
    "const duckMtl = \"https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.mtl\"\n",
    "const duckObj = \"https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.obj\"\n",
    "\n",
    "// Load the MTL file first.\n",
    "mtlLoader.load(\n",
    "  duckMtl,\n",
    "  (materials) => {\n",
    "    materials.preload();\n",
    "    // Now load the OBJ file and set its materials.\n",
    "    const objLoader = new OBJLoader();\n",
    "    objLoader.setMaterials(materials);\n",
    "    objLoader.load(\n",
    "      duckObj,\n",
    "      (object) => {\n",
    "        // Scale and position the loaded object.\n",
    "        object.scale.set(5, 5, 5);\n",
    "        object.position.set(0, 15, -20);\n",
    "        scene.add(object);\n",
    "\n",
    "        // Animation loop\n",
    "        function animate() {\n",
    "          requestAnimationFrame(animate);\n",
    "          object.rotation.y += 0.01;\n",
    "          renderer.render(scene, camera);\n",
    "        }\n",
    "        animate();\n",
    "      },\n",
    "      // onProgress callback\n",
    "      (xhr) => {\n",
    "        console.log(\"Loading object...\");\n",
    "      },\n",
    "      // onError callback\n",
    "      (error) => {\n",
    "        console.error('An error occurred while loading the OBJ:', error);\n",
    "      }\n",
    "    );\n",
    "  },\n",
    "  // onProgress callback for MTL\n",
    "  (xhr) => {\n",
    "    console.log(\"Loading materials...\");\n",
    "  },\n",
    "  // onError callback for MTL\n",
    "  (error) => {\n",
    "    console.error('An error occurred while loading the MTL:', error);\n",
    "  }\n",
    ");\n",
    "```\n",
    "</details>\n",
    "\n",
    "Note that `OBJLoader` takes the URL of the object followed by a callback function that gets triggered by the object fully loading. \n",
    "\n",
    "The geometries of the object are in `object.children[n].geometry`. Each child is a single part of the duck (for example its eyes, wings, and nose).\n",
    "\n",
    "In addition to the material that comes with the object, we can also add our own materials on top of it using this syntax:\n",
    "\n",
    "```js\n",
    "// Set envMap for all materials\n",
    "materials.materials && Object.values(materials.materials).forEach(material => {\n",
    "  material.envMap = scene.background;\n",
    "  material.envMapIntensity = 0.3;  // Lower value = less reflective (range 0-1)\n",
    "  material.needsUpdate = true;\n",
    "});\n",
    "```\n",
    "\n",
    "The above code should be called within the `mtlLoader.load` callback function, after the `materials` have been preloaded. This uses short-circuit evaluation (logical AND) to check if `materials.materials` is truthy (i.e. not `undefined` or `null`). If it is, we can safely call `Object.values(materials.materials)` to get the values of the materials, and then method-chain to set the `envMap` and `envMapIntensity` properties for each material.\n",
    "\n",
    "Let's create another canvas to render the rubber duck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas-5'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas-5'></canvas>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the materials, we used `MTLLoader`. Another add-on downloaded from the following CDN in the `include-after-body.text` front matter:\n",
    "\n",
    "```yaml\n",
    "<script type=\"importmap\">\n",
    "    {\n",
    "        \"imports\": {\n",
    "            \"MTLLoader\": \"https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js\"\n",
    "        }\n",
    "    }\n",
    "</script>\n",
    "```\n",
    "Notice the nested calls? `OBJLoader` is typically called within `MTLLoader`, and gets the `material` supplied to it.\n",
    "\n",
    "The `MTLLoader` loads the material file (`rubber_duck.mtl`) and then calls `materials.preload()`. The `OBJLoader`’s `.setMaterials(materials)` ensures that when the OBJ file is loaded, it uses the material definitions from the MTL file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Simple Camera Controls\n",
    "\n",
    "What good is rendering a skybox if we can't zoom and pan around to experience it in 3D? [OrbitControls](https://threejs.org/docs/#examples/en/controls/OrbitControls) allow us to do just that! Let's add them to our scene.\n",
    "\n",
    "`OrbitControls` can be imported from the following CDN:\n",
    "\n",
    "```html\n",
    "<script src=\"https://cdn.skypack.dev/three@0.133.0/examples/jsm/controls/OrbitControls.js\"></script>\n",
    "```\n",
    "As with all Three.js add-ons so far, we import `OrbitControls` using Quarto's front-matter.\n",
    "\n",
    "Once it's imported, we add `OrbitControls` to our scene.\n",
    "\n",
    "```js\n",
    "// Add OrbitControls\n",
    "const controls = new OrbitControls(camera, renderer.domElement);\n",
    "controls.enableDamping = true; // Smooth damping effect during rotation\n",
    "controls.dampingFactor = 0.05;\n",
    "```\n",
    "The line `const controls = new OrbitControls(camera, renderer.domElement)` passes `renderer.domElement` instead of just `renderer` because `OrbitControls` needs a DOM element to attach event listeners to (for mouse or touch interactions), not a renderer object. A Three.js rendering object manages the WebGL context, `renderer.domElement` is the actual HTML Canvas element to which Three.js renders the scene.\n",
    "\n",
    "Furthermore, inside the `animate()` call, we need to ensure that we're updating `CubeCamera`'s environment map. This is done to retain realistic reflections on shiny objects. Reflective objects show surrounding environment reflected on their surfaces, so the `CubeMap` needs to be updated whenever the scene changes in order to keep reflections on objects accurate.\n",
    "\n",
    "The animate block, which previously looked like:\n",
    "```js\n",
    "function animate() {\n",
    "  requestAnimationFrame(animate);\n",
    "  object.rotation.y += 0.01;\n",
    "  renderer.render(scene, camera);\n",
    "}\n",
    "```\n",
    "Becomes:\n",
    "```js\n",
    "function animate() {\n",
    "  requestAnimationFrame(animate);\n",
    "  object.rotation.y += 0.01;\n",
    "  cubeCamera.update(renderer, scene);  \n",
    "  renderer.render(scene, camera);\n",
    "  controls.update();\n",
    "}\n",
    "```\n",
    "The line `conrols.update()` is required the animation loop to ensure smooth interaction and rendering. Without this call, the camera might not respond to user input correctly.\n",
    "\n",
    "Also, now that we have `OrbitControls`, let's ensure we're positioning the camera to show the duck at the start of our scene. This is done within the `OBJLoader` callback, where the `object` is defined.\n",
    "\n",
    "```js\n",
    "camera5.position.copy(object.position);  // Set camera at duck position\n",
    "camera5.position.y += 20;  // Add y-offset (adjust value as needed)\n",
    "camera5.position.z += -20  // Add z-offset offset (adjust value as needed)\n",
    "camera5.lookAt(object.position) // Orient the camera to look at the duck\n",
    "```\n",
    "\n",
    "Go ahead and try the controls in the canvas above. Use:\n",
    "\n",
    "* Right mouse button (RMB) to pan\n",
    "* Left mouse button (LMB) to rotate\n",
    "* Scroll wheel (SW) to zoom\n",
    "\n",
    "Before we move on to creating more complex scenes, with multiple objects, we should explore how an OBJ file represents an object. We will need to understand the structure of an Object to manipulate it correctly using Three.js. \n",
    "\n",
    "# Creating More Complex Scenes\n",
    "\n",
    "The Canvas, by itself, is a thing of wonder (as in the HTML Canvas element used in conjunction with the [Canvas API](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API)). Here's a curated list of cool [Canvas API examples](https://github.com/raphamorim/awesome-canvas?tab=readme-ov-file). For example, here's [Pong](https://cssdeck.com/labs/full/ping-pong-game-tutorial-with-html5-canvas-and-sounds). Here's a cool [Matrix animation](https://matrix.dotglitch.dev/), and here's a tool that visualizes [L-systems](https://www.kevs3d.co.uk/dev/lsystems/#). The Canvas is what makes things like drawing, vector art, and diagramming tools (such as [Lucidchart](https://www.lucidchart.comB) or [diagrams.net](https://app.diagrams.net/)) possible on the browser. Some of that burden is also, perhaps, shared by the [SVG DOM API](https://developer.mozilla.org/en-US/docs/Web/API/SVG_API) used in conjunction with an SVG element.\n",
    "\n",
    "For more complex scenes, the HTML Canvas used purely with Canvas API is not enough. The Canvas API is usually good for 2D applications, however. It often requires explicitly setting its `context` as 2D. This is where WebGL (which is abstracted for us behind Three.js) comes into play. WebGL is a more powerful DOM API than is Canvas API.\n",
    "\n",
    "Furthermore, for truly complex 3D web-applications (complete with mouse and keyboard controls and other advanced features), we will need to integrate Three.js into a React app, perhaps, using [React Three Fiber (r3f)](https://r3f.docs.pmnd.rs/getting-started/introduction). React Three Fiber is a library that serves as a React renderer for Three.js. It enables the creation and management of 3D scenes and objects using React components, rather than plain HTML ( allowing developers to leverage React's component system as well as state/effect management (through hooks like `useEffect`). React's lifecycle methods, like `componentDidMount`, `componentDidUpdate`, and `componentWillUnmount`, help to further abstract the browser's own DOM events (so that we don't have to use something like `DOMContentLoaded` manually).\n",
    "\n",
    "For now, however, we will not use React Three Fiber. We will see how far we can take Three.js in Jupyter notebooks using Quarto, instead of React, to publish this page on the browser. Let's make a more complex scene now, by adding more objects. Let's add more rubber duckies to the scene! Once we are able to display more of the same object, we can perhaps explore some physics (like making it rain ducks).\n",
    "\n",
    "## Representation of an Object\n",
    "\n",
    "When Three.js parses an `.obj` (an OBJ file supplied to it), it represents it as a `Group` which is a JSON representation of an object that looks much like the following one (as far as Three.js is concerned): \n",
    "\n",
    "<details><summary>Click to expand json with comments</summary>\n",
    "\n",
    "```json\n",
    "Group {\n",
    "  \"children\": [\n",
    "    \"Mesh\": {\n",
    "      \"geometry\": \"BufferGeometry\" // See below for full expansion...\n",
    "      \"material\": \"Material\" // See below for full expansion...\n",
    "    },\n",
    "    \"Mesh\": {\n",
    "      \"geometry\": {\n",
    "        \"metadata\": { // Metadata provides info about the export\n",
    "          \"version\": 4.5, // Exporter version\n",
    "          \"type\": \"BufferGeometry\", // Type of object\n",
    "          \"generator\": \"BufferGeometry.toJSON\"// Method that generated this JSON\n",
    "        },\n",
    "        \"uuid\": \"12345678-1234-1234-1234-123456789abc\", // Unique identifier for this geometry\n",
    "        \"type\": \"BufferGeometry\", // Confirms that this is a BufferGeometry\n",
    "        \"data\": { // Main container for all geometry data\n",
    "          \"attributes\": { // Vertex attributes (data arrays for each vertex property)\n",
    "            \"position\": { // Positions of vertices\n",
    "              \"itemSize\": 3, // Each vertex position has 3 components: x, y, z\n",
    "              \"type\": \"Float32Array\", // Data stored as a Float32Array\n",
    "              \"array\": [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0], // Example vertex positions\n",
    "              \"normalized\": false // Data is not normalized\n",
    "            },\n",
    "            \"normal\": { // Normals at each vertex\n",
    "              \"itemSize\": 3, // 3 components per normal (x, y, z)\n",
    "              \"type\": \"Float32Array\",\n",
    "              \"array\": [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1], // Example normals\n",
    "              \"normalized\": false\n",
    "            },\n",
    "            \"uv\": { // Texture coordinates\n",
    "              \"itemSize\": 2, // Each UV coordinate has 2 components: u, v\n",
    "              \"type\": \"Float32Array\",\n",
    "              \"array\": [0, 0, 1, 0, 1, 1, 0, 1], // Example UV values\n",
    "              \"normalized\": false\n",
    "            }\n",
    "          },\n",
    "          \"index\": { // Index data defines the order to connect vertices into triangles\n",
    "            \"type\": \"Uint16Array\", // Data type of the index array\n",
    "            \"array\": [0, 1, 2, 0, 2, 3] // Indices forming triangles\n",
    "          },\n",
    "          \"groups\": [ // Groups specify portions of the geometry that use different materials\n",
    "            {\n",
    "              \"start\": 0, // Starting index in the index array for this group\n",
    "              \"count\": 6, // Number of indices (here, one quad made of 2 triangles)\n",
    "              \"materialIndex\": 0  // Which material from the material array should be used\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"material\": {\n",
    "        \"metadata\": { // Metadata about this material export\n",
    "          \"version\": 4.5, // Version of the exporter\n",
    "          \"type\": \"Object\", // This is a JSON object\n",
    "          \"generator\": \"Material.toJSON\" // Generated by Material.toJSON method\n",
    "        },\n",
    "        \"uuid\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\", // Unique ID for the material\n",
    "        \"type\": \"MeshStandardMaterial\", // Type of material (could be MeshBasicMaterial, etc.)\n",
    "        \"color\": 16777215, // Base color (in decimal, here 16777215 equals 0xffffff - white)\n",
    "        \"roughness\": 0.5, // Roughness parameter (controls how rough the surface is)\n",
    "        \"metalness\": 0.5, // Metalness parameter (how metallic the material looks)\n",
    "        \"emissive\": 0, // Emissive color (self-illumination; 0 means black, no emission)\n",
    "        \"opacity\": 1, // Opacity value (1 means fully opaque)\n",
    "        \"transparent\": false, // Flag indicating whether the material supports transparency\n",
    "        \"wireframe\": false, // If true, the material renders as a wireframe instead of solid\n",
    "        \"side\": 2 // Which side of the faces to render (2 indicates DoubleSide)\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  // Other group properties...\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "This is only an example. The above JSON is a simplified version of what Three.js might output when converting an OBJ file into its internal representation. But let's go over it because the general strokes are the same...\n",
    "\n",
    "In a `BufferGeometry`, there's am *index array*, which looks as below: \n",
    "\n",
    "```json\n",
    "\"index\": {\n",
    "  \"type\": \"Uint16Array\",\n",
    "  \"array\": [0, 1, 2, 0, 2, 3]\n",
    "}\n",
    "```\n",
    "\n",
    "It is an optional array that, one that defines how the *vertices* (which are stored in the `attributes.position`) are connected to form *faces* (usually composed of triangles). The values at the indices (the numbers themselves in the `index` array) refer to the same vertices in the `attributes` field of the data structure.\n",
    "\n",
    "For example, let's say our geometry's `attributes.position` field contains the following vertices:\n",
    "\n",
    "```json\n",
    "\"position\": {\n",
    "  \"itemSize\": 3,\n",
    "  \"array\": [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n",
    "}\n",
    "```\n",
    "\n",
    "Then, the index array above (`[0, 1, 2, 0, 2, 3]`) tells Three.js to use the vertices at positions `0, 1, 2`, in the position array, to form the first triangle, and vertices at positions `0, 2, 3` to form the second triangle. Meaning, the points $(x,y,z) = (0,0,0)$, $(1,0,0)$, and $(1,1,0)$ form a triangle, as do the points $(0,0,0), (1,1,0),$ and $(0,1,0)$. There are two triangles, so the given `Mesh`'s `geometry` represents a quad (which can also be seen from the fct that `attributes.position` contains only 4 vertices).  \n",
    "\n",
    "The *starting index*, which is the value of `group.start` in the above object data structure refers to the *offset* in the above `index` array where a specific group (which might be assigned one *particular* material) begins. In simpler terms, it excludes certain faces from having the specified material. In this way, a `group` basically defines a subset of the index array that should be rendered with a specific material. Of course, the group also defines how many vertices, from the offset, should the material apply to (using `group.count`), as well as which material to use (using `group.materialIndex`).\n",
    "\n",
    "Back to the [rubber ducky](./models/rubber_duck.obj) we downloaded earlier, when we look inside the `.obj` file, the groupings look different -- we see syntax like: `\"o <GroupName>\"` followed by the vertices. The JSON above is how Three.js interprets the `.obj`. When we print the rubbery ducky objects to the console we don't see a group of meshes (as in the JSON above), we see a single mesh. All objects in `.obj` format are translated into Three.js differently, there's a lot of variety. The `attributes.positions` and `index` arrays always behave the same way, however. The `group` is just a way to group certain vertices together, it is not a requirement of the OBJ format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneous Coordinates\n",
    "\n",
    "We use $4 \\times 4$ matrices (`Matrix4`), rather than $3 \\times 3$ matrices, to represent transformations in 3D space. But why? \n",
    "\n",
    "A $3 \\times 3$ matrix can handle linear transformations like rotation and scaling, but it cannot handle *affine* transformations (something as simple as a translation). All linear transformations are affine, but not all affine transformations are linear. As soon as a transformation has a transalation component, it's no longer linear (it's affine). A $3 \\times 3$ matrix also can't handle projection (either *perspective* or *orthogonal* projection -- which are non-linear and linear transformations, respectively). \n",
    "\n",
    "The $4 \\times 4$ matrix incorporates an extra row and column that stores the translation (or projection) components, enabling *all* simple transformations to be combined into one matrix. This makes it very efficient for computer graphics since we can apply a single matrix to transform an object in 3D space, reducing the number of required matrix operations. \n",
    "\n",
    "The use of a $4 \\times 4$ matrix necessitates the use of **homogeneous coordinates** (which all 3D libraries do under the hood). This is when the normal $(x,y,x)$ coordinates are augmented as $(x,y,z,w)$ (where $w$ is an extra coordinate that's $1$ by default). Let's see how this helps.\n",
    "Suppose we want to translate a point by $(t_x, t_y, t_z)$. In homogeneous coordinates, the translation matrix is:\n",
    "\n",
    "$$\n",
    "T = \\begin{pmatrix}\n",
    "1 & 0 & 0 & t_x \\\\\n",
    "0 & 1 & 0 & t_y \\\\\n",
    "0 & 0 & 1 & t_z \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Now, take a point $p$ represented as:\n",
    "\n",
    "$$\n",
    "p = \\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "When we apply the translation matrix (identity transformation) to the point, we multiply:\n",
    "\n",
    "$$\n",
    "T p = \\begin{pmatrix}\n",
    "1 & 0 & 0 & t_x \\\\\n",
    "0 & 1 & 0 & t_y \\\\\n",
    "0 & 0 & 1 & t_z \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x + t_x \\\\\n",
    "y + t_y \\\\\n",
    "z + t_z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This shows that the point $(x, y, z)$ is translated to $(x+t_x, y+t_y, z+t_z)$. We simply mentally discard the extra coordinate.\n",
    "\n",
    "In summary, the extra coordinate $w$ in homogeneous coordinates enables us to include translation (and projection) in the *same* framework as other transformations.\n",
    "\n",
    "## The Coordinate System\n",
    "\n",
    "This is a good time to make an effort to understand the coordinate system in Three.js. We can actually display the axes and the coordinate grid. \n",
    "\n",
    "Three.js provides a couple of helper classes to visualize the coordinate system in 3D space. The most common ones are `AxesHelper` and `GridHelper`.\n",
    "\n",
    "The `AxesHelper` displays lines for the $x$, $y$, and $z$ axes (typically colored red, green, and blue, respectively). For example:\n",
    "\n",
    "```js\n",
    "// An AxesHelper with a size of 50 units\n",
    "const axesHelper = new three.AxesHelper(50);\n",
    "scene.add(axesHelper);\n",
    "```\n",
    "This helper will render lines originating from the scene’s origin $(0, 0, 0)$, so we can visually see how objects are positioned relative to it.\n",
    "\n",
    "If we want an additional visual cue that represents a grid on the ground (helpful for orienting objects in a scene), we can use the `GridHelper`:\n",
    "\n",
    "```js\n",
    "// A GridHelper with a grid size of 100 and 10 divisions\n",
    "const gridHelper = new three.GridHelper(100, 10);\n",
    "scene.add(gridHelper);\n",
    "```\n",
    "\n",
    "Finally, if our grid or axes are not showing up it may be due to the camera's position. We can point the camera to any vector! Here we point it at the origin.\n",
    "\n",
    "```js\n",
    "camera.lookAt(new three.Vector3(0, 0, 0));\n",
    "```\n",
    "\n",
    "## Adding Multiple of the Same Object to a Scene (Efficiently)\n",
    "\n",
    "Previously we rendered separate scenes in a grid, now let's see how many ducks we can add to the same scene. \n",
    "\n",
    "Sure, we might think, let's just use `object.clone()` in the `OBJLoader` callback:\n",
    "\n",
    "```js\n",
    "// Clone the already loaded duck object\n",
    "const duckClone = object.clone();\n",
    "```\n",
    "\n",
    "But here's where we first stumble onto major performance issues in the browser. Depending on how much memory our machine has, we will start noticing jittery behavior and slowed animations when we try to render (roughly) `50` or more of these rubber ducky objects (that's the case on my development machine, at least). Luckily, Three.js has an optimization for rendering multiple of the *same* object to the scene (even if they're animated differently). \n",
    "\n",
    "### Instanced Mesh\n",
    "\n",
    "This optimization is called **instancing**. In Three.js, instancing is implemented via the `InstancedMesh` class, which is what we have to use instead of `Mesh`. `InstancedMesh` lets us render many copies of the same mesh (which, recall, is just a pairing of geometry and material) using a *single* draw call to the GPU (rather than many calls, one per each mesh). Instead of creating a separate `Mesh` for each object, which will incurs a draw call per object, we can create one `InstancedMesh`. We can assign each instance its own transformation matrix to vary the object's position, but its geometry and, to a lesser extent, materials will be fixed. This technique reduces CPU-to-GPU communication overhead, making it ideal for rendering thousands of identical objects efficiently. This is but one of many optimization techniques we can use to render thousands, or even millions of objects to a scene. Another one is using a variable *level-of-detail* (LOD) for objects that are far away from the camera or player. This technique uses shaders (which we'll discuss later) to decrease the number of vertices of our geometries if the given mesh is far away from the camera (or a player character). More on that later!\n",
    "\n",
    "We don’t call `clone()` for each duck when using instancing. Instead, we create one `InstancedMesh` that shares the *same* geometry and material for every instance and then assigns each instance its own transformation matrix. A transformation matrix is just what it sounds like, it's a matrix supplied to `InstancedMesh` that applies a **rotation**, a **translation**, and a **scaling** transform. If this matrix sounds like it's too complicated to come up with on the spot, don't worry. We will see that its, in fact, very simple and that there are a lot of tricks to help us do just that!\n",
    "\n",
    "`InstancedMesh` is basically an indexed data structure (a collection like an array) that stores *instances* of the mesh. These instances aren't directly accessible, unlike clones. However, we get the next best thing: an interface to update the transformation matrices of the instances (or to apply other instance attributes, like color). \n",
    "\n",
    "This interface consists of: \n",
    "- A getter method: `getMatrixAt(index, matrix)` \n",
    "- A setter method `setMatrixAt(index, matrix)`\n",
    "\n",
    "One question that may arise: Why does the getter method require a `matrix` parameter? The design of the `getMatrixAt` method is such that we supply an existing `Matrix4` as an empty container. The method, then, writes the transformation matrix of the instance at index `i` (which is stored in the object JSON) into the provided dummy matrix. \n",
    "\n",
    "But why do we use a $4 \\times 4$ matrix in 3D space? For the answer to that, refer to the subsection above on [homogeneous-coordinates](#homogeneous-coordinates). For now, let's accept this as fact. One tip, when dealing with `InstancedMecs`, is to avoid re-creating a new `Matrix4` object on every call and, instead, re-use the same dummy transformation matrix for each call.\n",
    "\n",
    "Fist, we create an `InstancedMesh` with `N` number of ducks. The `InstancedMesh` constructor takes a single `geometry` and a single `material` object (separately). Since the duck `.obj` comes with 4 child `Meshes` (each with its own `geometry` and `material`) we need separate `InstancedMeshes` for each of the duck's parts (for each child `Mesh`, representing the eyes, beak, wings, and body of the duck). Remember, `InstancedMesh` just repeats the provided geometry and material over-and-over again (with the only difference being in the transformation matrix that's applied to each instance). \n",
    "\n",
    "Let's review what we need:\n",
    "\n",
    "- We need to take each mesh of the duck and create a separate `InstancedMesh` for each of them.\n",
    "  - For `N` ducks, there will be `N` beaks, `N` eyes, `N` wings, and `N` bodies.\n",
    "  - For each of these `4N` meshes, we need to create a separate `InstancedMesh` object.\n",
    "- We need to create `N` transformation matrices for each of the ducks.\n",
    "  - This is because while we have `4N` meshes, we only need `N` transformation matrices (one for each duck). The same transformation matrix can be applied to all parts of the duck (the beak, eyes, wings, and body).\n",
    "\n",
    "Here's the code\n",
    "\n",
    "<details><summary>Click to expand the code used to create the instanced meshes</summary>\n",
    "\n",
    "```js\n",
    "/* Imports ---------------------------------------------- */\n",
    "import * as three from 'https://cdn.jsdelivr.net/npm/three@0.173.0/build/three.module.js';\n",
    "import { OBJLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js';\n",
    "import { MTLLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js';\n",
    "import { OrbitControls } from \"https://cdn.skypack.dev/three@0.133.0/examples/jsm/controls/OrbitControls.js\";\n",
    "\n",
    "/* Scene / camera / renderer ---------------------------------------- */\n",
    "const bodyWidth  = document.getElementById(\"quarto-document-content\").clientWidth;\n",
    "const bodyHeight = 600;\n",
    "const canvas6    = document.getElementById(\"three-d-canvas-6\");\n",
    "\n",
    "const scene6     = new three.Scene();\n",
    "const camera6    = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "const renderer6  = new three.WebGLRenderer({ canvas: canvas6 });\n",
    "renderer6.setPixelRatio(window.devicePixelRatio);\n",
    "renderer6.setSize(bodyWidth, bodyHeight);\n",
    "\n",
    "/* Lights */\n",
    "scene6.add(new three.AmbientLight(0xffffff, 0.6));\n",
    "const dir = new three.DirectionalLight(0xffffff, 0.8);\n",
    "dir.position.set(10, 20, 10);\n",
    "scene6.add(dir);\n",
    "\n",
    "/* Skybox */\n",
    "scene6.background = new three.CubeTextureLoader().load([\n",
    "  'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/px.png',\n",
    "  'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/nx.png',\n",
    "  'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/py.png',\n",
    "  'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/ny.png',\n",
    "  'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/pz.png',\n",
    "  'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/textures/skybox/nz.png'\n",
    "]);\n",
    "\n",
    "/* Controls */\n",
    "const controls = new OrbitControls(camera6, renderer6.domElement);\n",
    "controls.enableDamping = true;\n",
    "controls.dampingFactor = 0.05;\n",
    "\n",
    "/* Load duck model --------------------------------------------------- */\n",
    "const mtlURL = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.mtl';\n",
    "const objURL = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.obj';\n",
    "\n",
    "new MTLLoader().load(mtlURL, (materials) => {\n",
    "  materials.preload();\n",
    "\n",
    "  new OBJLoader().setMaterials(materials).load(objURL, (obj) => {\n",
    "\n",
    "    /* Grab geometries & materials of every duck part ---------------- */\n",
    "    const geos = [];\n",
    "    const mats = [];\n",
    "    obj.traverse((c) => { if (c.isMesh) { geos.push(c.geometry); mats.push(c.material); } });\n",
    "\n",
    "    /* Build N shared transform matrices for each N duck *once* ----------------------------- */\n",
    "    const N = 15;\n",
    "    const dummy  = new three.Object3D();\n",
    "    const matrices = []; // store for reuse\n",
    "    for (let i = 0; i < N; i++) {\n",
    "      const angle  = (i / N) * Math.PI * 2;\n",
    "      const radius = 40;\n",
    "      dummy.position.set(Math.cos(angle)*radius, 0, Math.sin(angle)*radius);\n",
    "      dummy.rotation.y = Math.random() * Math.PI * 2;\n",
    "      dummy.scale.set(3, 3, 3);\n",
    "      dummy.updateMatrix();\n",
    "      matrices.push(dummy.matrix.clone());   // ⬅️ keep a copy\n",
    "    }\n",
    "\n",
    "    /* One instanced mesh per part, but use *same* matrices for each of the 4 parts ------------ */\n",
    "    const meshGroup = new three.Group();\n",
    "\n",
    "    /* Adding the transformation matrix to each duck part */\n",
    "    for (let p = 0; p < geos.length; p++) {\n",
    "      const mesh = new three.InstancedMesh(geos[p], mats[p], N); // Make N InstancedMeshes of the duck part\n",
    "\n",
    "      // Set the transform of each N InstancedMesh to one of the N matrices created above\n",
    "      // Note that because of linearity: T(duck) = T(beak) + T(eyes) + T(body)\n",
    "      // So the same transform can be applies to all parts of the duck \n",
    "      for (let i = 0; i < N; i++) {\n",
    "        mesh.setMatrixAt(i, matrices[i]);    // ⬅️ reuse the matrix\n",
    "      }\n",
    "      mesh.instanceMatrix.needsUpdate = true;\n",
    "      meshGroup.add(mesh);\n",
    "    }\n",
    "\n",
    "    scene6.add(meshGroup);\n",
    "\n",
    "    /* Camera / animation ------------------------------------------- */\n",
    "    camera6.position.set(0, 50, 100);\n",
    "    camera6.lookAt(0, 0, 0);\n",
    "\n",
    "    (function animate() {\n",
    "      requestAnimationFrame(animate);\n",
    "      controls.update();\n",
    "      renderer6.render(scene6, camera6);\n",
    "    })();\n",
    "  });\n",
    "});\n",
    "```\n",
    "</details>\n",
    "\n",
    "Some of the steps involved are explained below.\n",
    "\n",
    "```js\n",
    "/* Build N shared transform matrices for each N duck *once* ----------------------------- */\n",
    "const N = 15;\n",
    "const dummy  = new three.Object3D();\n",
    "const matrices = []; // store for reuse\n",
    "for (let i = 0; i < N; i++) {\n",
    "  const angle  = (i / N) * Math.PI * 2;\n",
    "  const radius = 40;\n",
    "  dummy.position.set(Math.cos(angle)*radius, 0, Math.sin(angle)*radius);\n",
    "  dummy.rotation.y = Math.random() * Math.PI * 2;\n",
    "  dummy.scale.set(3, 3, 3);\n",
    "  dummy.updateMatrix();\n",
    "  matrices.push(dummy.matrix.clone());\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "The step above involves a cool trick. Instead of coming up with a transformation matrix ourselves, we create a `dummy` object and use its `.position.set(x,y,z)` to manipulate the dummy object. We give it some rotation (like before). Then we do `.updateMatrix()` and use the `.matrix` method to *get* the object's transformation matrix. This way we don't have to worry about the math behind the transformation matrix. We can just use the `dummy` object to set its position, rotation, and scale.\n",
    "\n",
    "In the example above we move the `dummy` object around a circle of `radius` 40. We subdivide the circle (of $2\\pi$ radians) into `N` segments. \n",
    "\n",
    "```js\n",
    "dummy.position.set(Math.cos(angle)*radius, 0, Math.sin(angle)*radius);\n",
    "```\n",
    "Sets the `dummy` object on the perimeter of the circle. \n",
    "\n",
    "The `dummy` object is also rotated by a random angle around its own $y$-axis.\n",
    "\n",
    "Once we have this `dummy` object's transformation matrix, we provide it to the `.setMatrixAt(index, matrix)` method of the `InstancedMesh`.\n",
    "\n",
    "We then create a Three.js group to capture all the `InstancedMeshes` to display them easier using the scene's `add()` method. \n",
    "\n",
    "```js\n",
    "const meshGroup = new three.Group();\n",
    "```\n",
    "\n",
    "The line below is important. It tells Three.js that the transformation matrix of the `InstancedMesh` has changed and needs to be updated.\n",
    "\n",
    "```js\n",
    "mesh.instanceMatrix.needsUpdate = true;\n",
    "```\n",
    "\n",
    "If we don't set `needsUpdate` to `true`, Three.js won't know that the matrices have changed (because of the underlying optimizations it makes to cut on GPU workload) and won't update them in the GPU.\n",
    "\n",
    "Finally, we need the `animate()` function to start an animation loop where we can update out `controls` for `OrbitControls`, request the animation frame, and render the scene. \n",
    "\n",
    "```js\n",
    "(function animate() {\n",
    "  requestAnimationFrame(animate);\n",
    "  controls.update();\n",
    "  renderer6.render(scene6, camera6);\n",
    "})();\n",
    "```\n",
    "\n",
    "Expand to see the result.\n",
    "\n",
    "<details><summary>Click to expand</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas-6'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas-6'></canvas>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Physics\n",
    "\n",
    "Let's add some physics to our scene. We can use a popular JavaScript physics engine called [Cannon.js](https://schteppe.github.io/cannon.js/). \n",
    "\n",
    "First, we include Cannon.js in the `include-after-body.text` front matter, and import it from a CDN like so:\n",
    "\n",
    "```html\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/cannon-es@0.20.0/dist/cannon-es.js\"></script>\n",
    "```\n",
    "\n",
    "Like we created a `Scene` using the Three.js graphics engine, we need to create a `World` using Cannon.js. The world is where all the physics simulation happens. We can create a world like so:\n",
    "\n",
    "```js\n",
    "// Physics World\n",
    "const world = new cannon.World();\n",
    "world.gravity.set(0, -9.82, 0); // Gravity pointing down\n",
    "```\n",
    "We also need to create a ground plane, otherwise the ducks will keep falling forever. We can create a plane like so:\n",
    "\n",
    "```js\n",
    "// Ground plane\n",
    "const groundBody = new cannon.Body({\n",
    "  mass: 0, // Static body\n",
    "  shape: new cannon.Plane(),\n",
    "});\n",
    "groundBody.quaternion.setFromEuler(-Math.PI / 2, 0, 0); // Rotate to be horizontal\n",
    "world.addBody(groundBody);\n",
    "\n",
    "// Ground mesh for visualization\n",
    "const groundMesh = new three.Mesh(\n",
    "  new three.PlaneGeometry(200, 200),\n",
    "  new three.MeshStandardMaterial({ color: 0x808080, side: three.DoubleSide })\n",
    ");\n",
    "groundMesh.rotation.x = -Math.PI / 2;\n",
    "scene6.add(groundMesh);\n",
    "```\n",
    "Note that we need to create a `cannon.Body` for the ground plane `Mesh`. Any object that we want to be affected by physics needs to be a `cannon.Body`. We also need to set the `quaternion` of the ground plane to be horizontal (the default is vertical). The `mass` property is set to `0`, which makes this body static. Static bodies do not move under the influence of forces or collisions—they are immovable objects in the simulation. This is ideal for objects like the ground or walls.\n",
    "\n",
    "```js\n",
    "groundBody.quaternion.setFromEuler(-Math.PI / 2, 0, 0); // Rotate to be horizontal\n",
    "```\n",
    "\n",
    "The line above sets the rotation of the ground plane to be horizontal. The `quaternion` is a way to represent rotations in 3D space. The `setFromEuler` method takes three angles (in radians) representing rotations around the $x$, $y$, and $z$ axes, respectively. In the context of 3D graphics and physics, [quaternions](https://en.wikipedia.org/wiki/Quaternion) are widely used because they provide a robust and efficient way to handle rotations. They avoid common problems associated with other rotation representations, such as [gimbal lock](https://en.wikipedia.org/wiki/Gimbal_lock#:~:text=In%20formal%20language%2C%20gimbal%20lock,which%20point%20gimbal%20lock%20occurs.), which can occur when using Euler angles. More on gimbal lock and quaternions later...\n",
    "\n",
    "We also need to create a `cannon.Body` for each duck. We can do this in the `OBJLoader` callback, where we load the duck model. For the duck shape, we can use a `cannon.Sphere` shape for simplicity (for now). \n",
    "\n",
    "As before, the positions and rotations of the physics bodies are applied to the `InstancedMesh` instances using a `dummy` object.\n",
    "\n",
    "The physics world is stepped forward using `world.step`, and the positions of the ducks are updated based on the physics simulation.\n",
    "\n",
    "\n",
    "In summary:\n",
    "\n",
    "1. **Physics World**:\n",
    "   - A `cannon.World` is created with gravity pointing downward.\n",
    "   - A ground plane is added to stop the ducks from falling infinitely.\n",
    "\n",
    "2. **Duck Physics Bodies**:\n",
    "   - Each duck is assigned a `cannon.Body` with a `cannon.Sphere` shape for simplicity.\n",
    "   - The positions of the *physics bodies* are updated in the animation loop.\n",
    "\n",
    "3. **Synchronizing Physics and Graphics**:\n",
    "   - The positions and rotations of the physics bodies are applied to the `InstancedMesh` instances using a `dummy` object.\n",
    "\n",
    "4. **Animation Loop**:\n",
    "   - The physics world is stepped forward using `world.step`.\n",
    "   - The positions of the ducks are updated based on the physics simulation.\n",
    "\n",
    "Let's see the code:\n",
    "\n",
    "<details><summary>Click to expand the code used to add physics</summary>\n",
    "\n",
    "```js\n",
    "import * as three from 'https://cdn.jsdelivr.net/npm/three@0.173.0/+esm';\n",
    "import { OBJLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/OBJLoader.js';\n",
    "import { MTLLoader } from 'https://cdn.jsdelivr.net/npm/three@0.173.0/examples/jsm/loaders/MTLLoader.js';\n",
    "import { OrbitControls } from 'https://cdn.skypack.dev/three@0.133.0/examples/jsm/controls/OrbitControls.js';\n",
    "import * as cannon from 'https://cdn.jsdelivr.net/npm/cannon-es@0.20.0/dist/cannon-es.js';\n",
    "\n",
    "/* Scene / Ccmera / renderer ---------------------------------------------- */ \n",
    "const bodyWidth = document.getElementById(\"quarto-document-content\").clientWidth;\n",
    "const bodyHeight = 600;\n",
    "const canvas = document.getElementById(\"three-d-canvas\");\n",
    "\n",
    "const scene = new three.Scene();\n",
    "const camera = new three.PerspectiveCamera(75, bodyWidth / bodyHeight, 0.1, 1000);\n",
    "const renderer = new three.WebGLRenderer({ canvas: canvas });\n",
    "renderer.setPixelRatio(window.devicePixelRatio);\n",
    "renderer.setSize(bodyWidth, bodyHeight);\n",
    "\n",
    "/* Lights ---------------------------------------------- */\n",
    "scene.add(new three.AmbientLight(0xffffff, 0.6));\n",
    "const dir = new three.DirectionalLight(0xffffff, 0.8);\n",
    "dir.position.set(10, 20, 10);\n",
    "scene.add(dir);\n",
    "\n",
    "/* Physics World ---------------------------------------------- */\n",
    "const world = new cannon.World();\n",
    "world.gravity.set(0, -9.82, 0); // Gravity pointing down\n",
    "\n",
    "// Ground plane\n",
    "const groundBody = new cannon.Body({\n",
    "  mass: 0, // Static body\n",
    "  shape: new cannon.Plane(),\n",
    "});\n",
    "groundBody.quaternion.setFromEuler(-Math.PI / 2, 0, 0); // Rotate to be horizontal\n",
    "world.addBody(groundBody);\n",
    "\n",
    "// Ground mesh for visualization\n",
    "const groundMesh = new three.Mesh(\n",
    "  new three.PlaneGeometry(200, 200),\n",
    "  new three.MeshStandardMaterial({ color: 0x808080, side: three.DoubleSide })\n",
    ");\n",
    "groundMesh.rotation.x = -Math.PI / 2;\n",
    "scene.add(groundMesh);\n",
    "\n",
    "/* Load duck model ---------------------------------------------- */\n",
    "const mtlURL = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.mtl';\n",
    "const objURL = 'https://raw.githubusercontent.com/v-poghosyan/v-poghosyan.github.io/refs/heads/main/posts/visualization/three_js_in_jupyter/models/rubber_duck.obj';\n",
    "\n",
    "new MTLLoader().load(mtlURL, (materials) => {\n",
    "  materials.preload();\n",
    "\n",
    "  new OBJLoader().setMaterials(materials).load(objURL, (obj) => {\n",
    "    const geos = [];\n",
    "    const mats = [];\n",
    "    obj.traverse((c) => {\n",
    "      if (c.isMesh) {\n",
    "        geos.push(c.geometry);\n",
    "        mats.push(c.material);\n",
    "      }\n",
    "    });\n",
    "\n",
    "    const N = 50; // Number of ducks\n",
    "    const dummy = new three.Object3D();\n",
    "    const meshGroup = new three.Group();\n",
    "    const duckBodies = []; // Store physics bodies\n",
    "\n",
    "    for (let p = 0; p < geos.length; p++) {\n",
    "      const mesh = new three.InstancedMesh(geos[p], mats[p], N);\n",
    "\n",
    "      for (let i = 0; i < N; i++) {\n",
    "        // Random initial positions\n",
    "        const x = Math.random() * 50 - 25;\n",
    "        const y = Math.random() * 50 + 50; // Start above the ground\n",
    "        const z = Math.random() * 50 - 25;\n",
    "\n",
    "        // Create a physics body for each duck\n",
    "        const duckBody = new cannon.Body({\n",
    "          mass: 1, // Dynamic body\n",
    "          shape: new cannon.Sphere(1), // Approximate shape\n",
    "          position: new cannon.Vec3(x, y, z),\n",
    "        });\n",
    "        world.addBody(duckBody);\n",
    "        duckBodies.push(duckBody);\n",
    "\n",
    "        // Set initial transformation for the InstancedMesh\n",
    "        dummy.position.set(x, y, z);\n",
    "        dummy.rotation.y = Math.random() * Math.PI * 2;\n",
    "        dummy.scale.set(3, 3, 3);\n",
    "        dummy.updateMatrix();\n",
    "        mesh.setMatrixAt(i, dummy.matrix);\n",
    "      }\n",
    "\n",
    "      mesh.instanceMatrix.needsUpdate = true;\n",
    "      meshGroup.add(mesh);\n",
    "    }\n",
    "\n",
    "    scene.add(meshGroup);\n",
    "\n",
    "    /* Camera / Animation ---------------------------------------------- */\n",
    "    camera.position.set(0, 50, 100);\n",
    "    camera.lookAt(0, 0, 0);\n",
    "\n",
    "    function animate() {\n",
    "      requestAnimationFrame(animate);\n",
    "\n",
    "      // Step the physics world\n",
    "      world.step(1 / 30); // 120 FPS\n",
    "\n",
    "      // Update the positions of the ducks\n",
    "      for (let i = 0; i < N; i++) {\n",
    "        const duckBody = duckBodies[i];\n",
    "        const position = duckBody.position;\n",
    "        const quaternion = duckBody.quaternion;\n",
    "\n",
    "        dummy.position.set(position.x, position.y, position.z);\n",
    "        dummy.quaternion.set(quaternion.x, quaternion.y, quaternion.z, quaternion.w);\n",
    "        dummy.updateMatrix();\n",
    "\n",
    "        meshGroup.children.forEach((mesh) => {\n",
    "          mesh.setMatrixAt(i, dummy.matrix);\n",
    "        });\n",
    "      }\n",
    "\n",
    "      meshGroup.children.forEach((mesh) => {\n",
    "        mesh.instanceMatrix.needsUpdate = true;\n",
    "      });\n",
    "\n",
    "      controls.update();\n",
    "      renderer.render(scene, camera);\n",
    "    }\n",
    "\n",
    "    animate();\n",
    "  });\n",
    "});\n",
    "\n",
    "/* Orbit Controls ---------------------------------------------- */\n",
    "const controls = new OrbitControls(camera, renderer.domElement);\n",
    "controls.enableDamping = true;\n",
    "controls.dampingFactor = 0.05;\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also added a metalic pool, feel free to see the full code [here](./javascript/three-js-many-ducks-physics-demo.js).\n",
    "\n",
    "Finally, even though the gravitational constant is set to the same value as on Earth, the ducks appear to fall very slowly due to the scale of the scene. We can speed things up using:\n",
    "\n",
    "```js\n",
    "// Step the physics world multiple times per frame\n",
    "for(let i = 0; i < 3; i++) {  // Simulate physics 3x per animation frame\n",
    "    world.step(1/60);         // Standard 60 FPS physics simulation\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the docs: \n",
    "\n",
    "`world.step(timeStep)` takes parameter:\n",
    "\n",
    "1. `timeStep` (required): The time step to simulate, in seconds. For example:\n",
    "   - `1/60` simulates physics at 60 FPS \n",
    "   - `1/120` simulates physics at 120 FPS\n",
    "   - The smaller the timestep, the more accurate but computationally expensive the simulation\n",
    "\n",
    "There are more parameters but they are optional. \n",
    "\n",
    "The crucial thing to understand is that physics steps and animation frames are decoupled. The physics world is updated independently of the rendering loop. This means we can run the physics simulation at a different rate than the rendering loop. The rendering loop is variable, and based on our monitor refresh rate (usually it's 60 FPS). The physics world can be updated at a different rate than that. The key is that the physics world should be updated at a *fixed* time step. This is important for stability and accuracy in the simulation.\n",
    "\n",
    "So when we do 3 physics steps within one animation (steps of $1/60$ seconds each in terms of time $t$ that's supplied to the physics engine), the physics simulation advances by a total of $3/60 = 1/20$ seconds. But we only show the final result after all 3 steps are done (hence why we don't need 3 corresponding animation frames). The next animation frame will start from this new state. This has the effect of speeding up our animation since each animation frame now displays the objects further along their journey (the trajectory of their motion).\n",
    "\n",
    "Running one step of $1/20$-th second instead, as below, is inappropiate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.step(1/20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While mathematically $1/20 = 3*(1/60)$, they're not equivalent for physics simulation because physics engines use *numerical integration* to calculate the motion of objects. Using larger time steps (like $1/20$) leads to less accurate results because the engine has to approximate motion over a longer period. As we know, local approximation is always available but as we move far away from the known point, methods like [Taylor Series](https://en.wikipedia.org/wiki/Taylor_series) start losing accuracy. Smaller time steps $1/60$ or $1/120$ allow the engine to calculate positions and velocities more frequently, leading to more accurate simulation. With larger time steps fast-moving objects might also experience clipping issues (because their positions are updated less frequently).\n",
    "\n",
    "In fact, the approach we used is known as [physics *sub-stepping*](https://www.unrealengine.com/es-ES/blog/physics-sub-stepping). The article goes over on how to enable sub-stepping in Unreal Engine, but the concept is the same. The idea is to run the physics simulation at a higher frequency than the rendering loop. This allows for more accurate and stable simulations, especially for fast-moving objects or complex interactions.\n",
    "\n",
    "Let's see the result.\n",
    "\n",
    "<details><summary>Click to expand</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas-7'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas-7'></canvas>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>\n",
    "\n",
    "Of course, there are several things that are still *very* wrong with our scene: \n",
    "\n",
    "- The ducks shouldn't be rolling like billiards balls. We can fix that by using a more accurate shape for the ducks (instead of a sphere). For example, we can use a `cannon.ConvexPolyhedron`, which is a more accurate representation of the duck's shape. This will make the ducks fall more realistically in the above physics simulation. \n",
    "- We need to implement *buoyancy* to the water, it would be nice if the water didn't behave like the surface of a table. However, this will have to do for now.\n",
    "- It would be nice if the walls reflected the ducks as well as the water's surface.\n",
    "\n",
    "But, we will revisit this scene later and make it more believable. For now, let's move on to the next section. A section I am very excited to introduce, [Shaders](#shaders).\n",
    "\n",
    "## Shaders\n",
    "\n",
    "From making the surface of water realistic, to rendering realistic grass, *shaders* are the backbone of modern graphics programming. They are used for ultimate control over the rendering pipeline. Think of them as functions that map a vertex or a pixel to an RGBA color.\n",
    "\n",
    "$$\n",
    "f(x,y,z) = (x,y,z) \\to (r,g,b,a)\n",
    "$$\n",
    "\n",
    "Some shaders also map a vertex to another vertex, effectively acting as a transformation function. This can help create, for example, a *displacement map* that distorts the surface of an object based on a texture (for rending things like waves in a body of water). These types of shaders look like:\n",
    "\n",
    "$$\n",
    "f(x,y,z) = (x,y,z) \\to (x',y',z')\n",
    "$$\n",
    "\n",
    "Shaders are, basically, small programs (scripts) that run on the GPU and are used to control the rendering of graphics. They are written in a language called GLSL (OpenGL Shading Language). Shaders define how vertices and pixels are processed, allowing for advanced visual effects. Shaders are typically divided into two main types: **vertex shaders** and **fragment shaders**.\n",
    "\n",
    "- **Vertex Shaders**: These shaders are responsible for processing each vertex of a 3D model. They take vertex attributes (like position, normal, and texture coordinates) and transform them into screen space. \n",
    "- **Fragment Shaders**: These shaders are responsible for processing each pixel (or fragment) of a rendered image. They determine the final color of each pixel based on various factors, such as lighting, textures, and material properties. Fragment shaders can create complex visual effects like shadows, reflections, and refractions.\n",
    "\n",
    "### How to Use Shaders from Three.js\n",
    "\n",
    "First, let's see how we can use shaders in Three.js. Three.js provides a `ShaderMaterial` class that allows us to create render vertex and fragment shaders. We can define our own GLSL code for both of these (the vertex and fragment shaders) and provide them to `ShaderMaterial`.\n",
    "\n",
    "The GLSL code is typically split into two parts. Usually it's split into `<shader_name>.frag` and `<shader_name>.vert` files: the vertex shader and the fragment shader. As mentioned before, the vertex shader is responsible for transforming the vertices of the geometry, while the fragment shader is responsible for determining the color of each pixel.\n",
    "\n",
    "First, we import the GLSL shader code into JavaScript. Importing is fancy for: creating a `waterVertexShader` and a `waterFragmentShader` string literal containing the GLSL code inside our JavaScript like so:\n",
    "\n",
    "<details><summary>Click to expand the code used to create the water shader</summary>\n",
    "\n",
    "```js\n",
    "const waterVertexShader = `\n",
    "  uniform vec3 uDepthColor;\n",
    "  uniform vec3 uSurfaceColor;\n",
    "  uniform float uColorOffset;\n",
    "  uniform float uColorMultiplier;\n",
    "\n",
    "\n",
    "  varying float vElevation;\n",
    "\n",
    "\n",
    "  void main()\n",
    "  {\n",
    "      float mixStrenght = (vElevation  + uColorOffset)* uColorMultiplier;\n",
    "      vec3 color = mix(uDepthColor,uSurfaceColor,mixStrenght) ;\n",
    "      gl_FragColor = vec4(color,1.0);\n",
    "  }\n",
    "`;\n",
    "\n",
    "const waterFragmentShader = `\n",
    "  uniform float uTime;\n",
    "  uniform float uBigWavesElevation;\n",
    "  uniform vec2 uBigWavesFrequency;\n",
    "  uniform float uBigWavesSpeed;\n",
    "\n",
    "  uniform float  uSmallWavesElevation;\n",
    "  uniform float  uSmallWavesFrequency;\n",
    "  uniform float  uSmallWavesSpeed;\n",
    "  uniform float  uSmallWavesIterations;\n",
    "\n",
    "  varying float vElevation;\n",
    "\n",
    "  //\tClassic Perlin 3D Noise \n",
    "  //\tby Stefan Gustavson\n",
    "  //\n",
    "  vec4 permute(vec4 x){return mod(((x*34.0)+1.0)*x, 289.0);}\n",
    "  vec4 taylorInvSqrt(vec4 r){return 1.79284291400159 - 0.85373472095314 * r;}\n",
    "  vec3 fade(vec3 t) {return t*t*t*(t*(t*6.0-15.0)+10.0);}\n",
    "\n",
    "  float cnoise(vec3 P){\n",
    "    vec3 Pi0 = floor(P); // Integer part for indexing\n",
    "    vec3 Pi1 = Pi0 + vec3(1.0); // Integer part + 1\n",
    "    Pi0 = mod(Pi0, 289.0);\n",
    "    Pi1 = mod(Pi1, 289.0);\n",
    "    vec3 Pf0 = fract(P); // Fractional part for interpolation\n",
    "    vec3 Pf1 = Pf0 - vec3(1.0); // Fractional part - 1.0\n",
    "    vec4 ix = vec4(Pi0.x, Pi1.x, Pi0.x, Pi1.x);\n",
    "    vec4 iy = vec4(Pi0.yy, Pi1.yy);\n",
    "    vec4 iz0 = Pi0.zzzz;\n",
    "    vec4 iz1 = Pi1.zzzz;\n",
    "\n",
    "    vec4 ixy = permute(permute(ix) + iy);\n",
    "    vec4 ixy0 = permute(ixy + iz0);\n",
    "    vec4 ixy1 = permute(ixy + iz1);\n",
    "\n",
    "    vec4 gx0 = ixy0 / 7.0;\n",
    "    vec4 gy0 = fract(floor(gx0) / 7.0) - 0.5;\n",
    "    gx0 = fract(gx0);\n",
    "    vec4 gz0 = vec4(0.5) - abs(gx0) - abs(gy0);\n",
    "    vec4 sz0 = step(gz0, vec4(0.0));\n",
    "    gx0 -= sz0 * (step(0.0, gx0) - 0.5);\n",
    "    gy0 -= sz0 * (step(0.0, gy0) - 0.5);\n",
    "\n",
    "    vec4 gx1 = ixy1 / 7.0;\n",
    "    vec4 gy1 = fract(floor(gx1) / 7.0) - 0.5;\n",
    "    gx1 = fract(gx1);\n",
    "    vec4 gz1 = vec4(0.5) - abs(gx1) - abs(gy1);\n",
    "    vec4 sz1 = step(gz1, vec4(0.0));\n",
    "    gx1 -= sz1 * (step(0.0, gx1) - 0.5);\n",
    "    gy1 -= sz1 * (step(0.0, gy1) - 0.5);\n",
    "\n",
    "    vec3 g000 = vec3(gx0.x,gy0.x,gz0.x);\n",
    "    vec3 g100 = vec3(gx0.y,gy0.y,gz0.y);\n",
    "    vec3 g010 = vec3(gx0.z,gy0.z,gz0.z);\n",
    "    vec3 g110 = vec3(gx0.w,gy0.w,gz0.w);\n",
    "    vec3 g001 = vec3(gx1.x,gy1.x,gz1.x);\n",
    "    vec3 g101 = vec3(gx1.y,gy1.y,gz1.y);\n",
    "    vec3 g011 = vec3(gx1.z,gy1.z,gz1.z);\n",
    "    vec3 g111 = vec3(gx1.w,gy1.w,gz1.w);\n",
    "\n",
    "    vec4 norm0 = taylorInvSqrt(vec4(dot(g000, g000), dot(g010, g010), dot(g100, g100), dot(g110, g110)));\n",
    "    g000 *= norm0.x;\n",
    "    g010 *= norm0.y;\n",
    "    g100 *= norm0.z;\n",
    "    g110 *= norm0.w;\n",
    "    vec4 norm1 = taylorInvSqrt(vec4(dot(g001, g001), dot(g011, g011), dot(g101, g101), dot(g111, g111)));\n",
    "    g001 *= norm1.x;\n",
    "    g011 *= norm1.y;\n",
    "    g101 *= norm1.z;\n",
    "    g111 *= norm1.w;\n",
    "\n",
    "    float n000 = dot(g000, Pf0);\n",
    "    float n100 = dot(g100, vec3(Pf1.x, Pf0.yz));\n",
    "    float n010 = dot(g010, vec3(Pf0.x, Pf1.y, Pf0.z));\n",
    "    float n110 = dot(g110, vec3(Pf1.xy, Pf0.z));\n",
    "    float n001 = dot(g001, vec3(Pf0.xy, Pf1.z));\n",
    "    float n101 = dot(g101, vec3(Pf1.x, Pf0.y, Pf1.z));\n",
    "    float n011 = dot(g011, vec3(Pf0.x, Pf1.yz));\n",
    "    float n111 = dot(g111, Pf1);\n",
    "\n",
    "    vec3 fade_xyz = fade(Pf0);\n",
    "    vec4 n_z = mix(vec4(n000, n100, n010, n110), vec4(n001, n101, n011, n111), fade_xyz.z);\n",
    "    vec2 n_yz = mix(n_z.xy, n_z.zw, fade_xyz.y);\n",
    "    float n_xyz = mix(n_yz.x, n_yz.y, fade_xyz.x); \n",
    "    return 2.2 * n_xyz;\n",
    "  }\n",
    "\n",
    "  void main()\n",
    "  {\n",
    "      vec4 modelPosition = modelMatrix * vec4(position,1.0);\n",
    "\n",
    "      //elevation \n",
    "      float elevation = sin(modelPosition.x * uBigWavesFrequency.x + uTime * uBigWavesSpeed ) \n",
    "                      * sin(modelPosition.z * uBigWavesFrequency.y + uTime * uBigWavesSpeed)\n",
    "                      * uBigWavesElevation;\n",
    "\n",
    "      for(float i = 1.0 ; i <= uSmallWavesIterations ; i++)\n",
    "      \n",
    "      {\n",
    "        elevation -= abs(\n",
    "            cnoise(\n",
    "                vec3(\n",
    "                    modelPosition.xz * uSmallWavesFrequency * i,\n",
    "                    uTime*uSmallWavesSpeed\n",
    "                    )\n",
    "                    ) * uSmallWavesElevation / i\n",
    "                    );\n",
    "      }\n",
    "\n",
    "      modelPosition.y += elevation;\n",
    "\n",
    "      vec4 viewPosition = viewMatrix * modelPosition;\n",
    "      vec4 projectedPosition = projectionMatrix * viewPosition;\n",
    "\n",
    "      gl_Position = projectedPosition;\n",
    "\n",
    "      vElevation = elevation;\n",
    "  }\n",
    "`;\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Then we can create a `ShaderMaterial` using the vertex and fragment shaders:\n",
    "\n",
    "```js\n",
    "const waterMaterial = new three.ShaderMaterial({\n",
    "  uniforms: {\n",
    "    time: { value: 0 },\n",
    "    waterColor: { value: new three.Color(0x1E90FF) }, // Water color\n",
    "    envMap: { value: scene.background }, // Environment map for reflection\n",
    "  },\n",
    "  vertexShader: waterVertexShader,\n",
    "  fragmentShader: waterFragmentShader,\n",
    "});\n",
    "```\n",
    "\n",
    "Finally, we apply the `waterMaterial` at the time of `Mesh` creation:\n",
    "\n",
    "```js\n",
    "const waterMesh = new three.Mesh(\n",
    "    new three.PlaneGeometry(200, 200),\n",
    "    waterMaterial\n",
    ");\n",
    "```\n",
    "\n",
    "Let's render the result. \n",
    "\n",
    "<details><summary>Click to expand</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<canvas id='three-d-canvas-8'></canvas>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<canvas id='three-d-canvas-8'></canvas>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how does this work? Here's a [shader post](../../game_development/computer_graphics/computer_graphics.ipynb) that goes over it in detail. For us, for now, at a *very* high level:\n",
    "\n",
    "- Vertex and fragment shaders use *uniforms* to keep track of state (between themselves as well as the outside JavaScript world)\n",
    "- We run the scene (our simulation or animation) in Three.js and pass the time (from the physics simulation) to the shader using `uniforms`. Then, the shader can be a function of time...\n",
    "- Position information can be passed into the shaders, for example, to achieve the effect of a surface appearing more reflective further away.\n",
    "\n",
    "Once again, here's the full [post on shaders and GLSL](../../game_development/computer_graphics/computer_graphics.ipynb) if you're interested to explore this topic further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this post, we explored how to create a scene with multiple ducks using Three.js. We learned how to use `InstancedMesh` to efficiently render many instances of the same geometry. We also added physics to our scene using Cannon.js, allowing the ducks to interact with the environment realistically. Finally, we introduced shaders. We used Three.js to apply a custom water shader written in GLSL. This post is part of a series on [Three.js](https://threejs.org/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
