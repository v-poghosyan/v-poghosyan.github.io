{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Build Jarvis - Your Own AI Assistant\"\n",
    "author: \"Vahram Poghosyan\"\n",
    "date: \"2023-01-13\"\n",
    "categories: [\"AI\", \"Machine Learning\", \"HuggingFace\", \"LLMs\"]\n",
    "image: \"build_jarvis_your_own_ai_assistant.png\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "include-after-body:\n",
    "  text: |\n",
    "    <script type=\"application/javascript\" src=\"../../javascript/light-dark.js\"></script>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I Solemnly Promise...\n",
    "\n",
    "To one day write this article. For now, here's the CoPilot-generated steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Open Source Language Model with Local Notes\n",
    "\n",
    "This guide will walk you through the process of training an open source Language Model (LLM) hosted on Hugging Face using your local notes. These notes can be hosted on GitHub or served as static pages.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of Python programming\n",
    "- Familiarity with Machine Learning concepts\n",
    "- An account on Hugging Face's Model Hub\n",
    "- Your notes hosted on GitHub or served as static pages\n",
    "\n",
    "## Steps\n",
    "\n",
    "### 1. Setup Your Environment\n",
    "\n",
    "First, you need to set up your Python environment. This involves installing necessary libraries and tools, including Hugging Face's Transformers library.\n",
    "\n",
    "```bash\n",
    "pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Your Training Data\n",
    "Your training data will be your local notes. If they're hosted on GitHub, you can clone the repository to your local machine. If they're served as static pages, you can use a web scraper to download the notes.\n",
    "\n",
    "### 3. Preprocess Your Data\n",
    "Before training the model, you need to preprocess your data. This involves tokenizing the text and formatting it in a way that the model can understand.\n",
    "\n",
    "### 4. Train the Model\n",
    "Now you're ready to train the model. You can use Hugging Face's `Trainer` class to do this. Here's a basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Upload the Model to Hugging Face\n",
    "After training the model, you can upload it to Hugging Face's Model Hub. This allows others to use your model for their own tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"my-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "That's it! You've now trained an open source LLM with your local notes and uploaded it to Hugging Face. Happy training!\n",
    "\n",
    "```\n",
    "\n",
    "Please note that this is a high-level guide and the actual code will depend on your specific use case and the format of your notes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
